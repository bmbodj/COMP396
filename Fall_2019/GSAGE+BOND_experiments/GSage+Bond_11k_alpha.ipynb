{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GSage+set2set_bond 11k-alpha.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BBM1XoLJyai",
        "colab_type": "code",
        "outputId": "8569f3ec-753e-45c0-8a73-51e95c032970",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!apt install gcc-5 g++-5 -y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  cpp-5 gcc-5-base libasan2 libgcc-5-dev libisl15 libmpx0 libstdc++-5-dev\n",
            "Suggested packages:\n",
            "  gcc-5-locales g++-5-multilib gcc-5-doc libstdc++6-5-dbg gcc-5-multilib\n",
            "  libgcc1-dbg libgomp1-dbg libitm1-dbg libatomic1-dbg libasan2-dbg\n",
            "  liblsan0-dbg libtsan0-dbg libubsan0-dbg libcilkrts5-dbg libmpx0-dbg\n",
            "  libquadmath0-dbg libstdc++-5-doc\n",
            "The following NEW packages will be installed:\n",
            "  cpp-5 g++-5 gcc-5 gcc-5-base libasan2 libgcc-5-dev libisl15 libmpx0\n",
            "  libstdc++-5-dev\n",
            "0 upgraded, 9 newly installed, 0 to remove and 7 not upgraded.\n",
            "Need to get 29.1 MB of archives.\n",
            "After this operation, 100 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 gcc-5-base amd64 5.5.0-12ubuntu1 [17.1 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libisl15 amd64 0.18-4 [548 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 cpp-5 amd64 5.5.0-12ubuntu1 [7,785 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libasan2 amd64 5.5.0-12ubuntu1 [264 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmpx0 amd64 5.5.0-12ubuntu1 [9,888 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgcc-5-dev amd64 5.5.0-12ubuntu1 [2,224 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 gcc-5 amd64 5.5.0-12ubuntu1 [8,357 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libstdc++-5-dev amd64 5.5.0-12ubuntu1 [1,415 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/universe amd64 g++-5 amd64 5.5.0-12ubuntu1 [8,450 kB]\n",
            "Fetched 29.1 MB in 2s (18.7 MB/s)\n",
            "Selecting previously unselected package gcc-5-base:amd64.\n",
            "(Reading database ... 145655 files and directories currently installed.)\n",
            "Preparing to unpack .../0-gcc-5-base_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking gcc-5-base:amd64 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package libisl15:amd64.\n",
            "Preparing to unpack .../1-libisl15_0.18-4_amd64.deb ...\n",
            "Unpacking libisl15:amd64 (0.18-4) ...\n",
            "Selecting previously unselected package cpp-5.\n",
            "Preparing to unpack .../2-cpp-5_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking cpp-5 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package libasan2:amd64.\n",
            "Preparing to unpack .../3-libasan2_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking libasan2:amd64 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package libmpx0:amd64.\n",
            "Preparing to unpack .../4-libmpx0_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking libmpx0:amd64 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package libgcc-5-dev:amd64.\n",
            "Preparing to unpack .../5-libgcc-5-dev_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking libgcc-5-dev:amd64 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package gcc-5.\n",
            "Preparing to unpack .../6-gcc-5_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking gcc-5 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package libstdc++-5-dev:amd64.\n",
            "Preparing to unpack .../7-libstdc++-5-dev_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking libstdc++-5-dev:amd64 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package g++-5.\n",
            "Preparing to unpack .../8-g++-5_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking g++-5 (5.5.0-12ubuntu1) ...\n",
            "Setting up libisl15:amd64 (0.18-4) ...\n",
            "Setting up gcc-5-base:amd64 (5.5.0-12ubuntu1) ...\n",
            "Setting up libmpx0:amd64 (5.5.0-12ubuntu1) ...\n",
            "Setting up libasan2:amd64 (5.5.0-12ubuntu1) ...\n",
            "Setting up libgcc-5-dev:amd64 (5.5.0-12ubuntu1) ...\n",
            "Setting up cpp-5 (5.5.0-12ubuntu1) ...\n",
            "Setting up libstdc++-5-dev:amd64 (5.5.0-12ubuntu1) ...\n",
            "Setting up gcc-5 (5.5.0-12ubuntu1) ...\n",
            "Setting up g++-5 (5.5.0-12ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXSkQprZJ-5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ln -sf /usr/bin/gcc-5 /usr/bin/gcc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65EGZX5BKCoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " !ln -sf /usr/bin/g++-5 /usr/bin/g++"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qi_9A-KpJ51q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!export CPATH=/usr/local/cuda/include:$CPATH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBK8e-n5KJmq",
        "colab_type": "code",
        "outputId": "b1e95c98-01fb-4625-bc13-4cbd1cbe6039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "!pip install torch-scatter"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch-scatter\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/c3/8bad887ffa55c86f120ef5ae252dc0e357b3bd956d9fbf45242bacc46290/torch_scatter-1.4.0.tar.gz\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-1.4.0-cp36-cp36m-linux_x86_64.whl size=3181685 sha256=84f4406714653046a178aac20878c13671335d34aa01dd32338f7bdeb1e77d79\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/00/c4/1637b4b3003f29092f4fe2ad4b40dd10906269c1ac2dc82941\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isHNOWwUK-wQ",
        "colab_type": "code",
        "outputId": "9bd8f6ec-fcd1-4553-f7ad-7c154a3fb2f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "!pip install torch-sparse"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch-sparse\n",
            "  Downloading https://files.pythonhosted.org/packages/08/4e/a268613fa6a92ffbc65b89e66fc8be5590801937185007f0f7bcb75ea21f/torch_sparse-0.4.3.tar.gz\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-sparse) (1.3.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-sparse) (1.17.4)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.4.3-cp36-cp36m-linux_x86_64.whl size=3981673 sha256=aff666169cc609247e682a881fa6cbb15a8acf1a75f4854d59dbd920b2743901\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/66/2b/befece01c2516f9fb3e7b4d150bb2b871221c73657c9cd7735\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47-LLTlmOfVI",
        "colab_type": "code",
        "outputId": "ed5d3ece-cd08-4d50-fe2e-f34f3eeeae04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "!pip install torch-cluster"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch-cluster\n",
            "  Downloading https://files.pythonhosted.org/packages/c3/70/1d827d6fd1e03bb5ae84852dd0070c6574105c37e7b935284f6e990932db/torch_cluster-1.4.5.tar.gz\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-cluster) (1.3.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-cluster) (1.17.4)\n",
            "Building wheels for collected packages: torch-cluster\n",
            "  Building wheel for torch-cluster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-cluster: filename=torch_cluster-1.4.5-cp36-cp36m-linux_x86_64.whl size=16287285 sha256=ef7990582931a446135ea72e718161efd11a8e4813c4357f34d05365a6678d6d\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/26/7e/a6d6a80eae5ca39b92bc77773f36cf433d5085de18014382b1\n",
            "Successfully built torch-cluster\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0cigFl2OuTT",
        "colab_type": "code",
        "outputId": "ae24e172-43f6-4857-cf9b-88f39b2461f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "source": [
        "!pip install torch-spline-conv "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch-spline-conv\n",
            "  Downloading https://files.pythonhosted.org/packages/5e/77/5420584cdb1514c580722ca4bc482a509105d64b7c70246e9dc4a3e6d3c5/torch_spline_conv-1.1.1.tar.gz\n",
            "Building wheels for collected packages: torch-spline-conv\n",
            "  Building wheel for torch-spline-conv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-spline-conv: filename=torch_spline_conv-1.1.1-cp36-cp36m-linux_x86_64.whl size=5482367 sha256=b0376c348d952ae665add7fbd235d180d4a14682dce393e7ab2fe6f690f3abf2\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/cf/c7/3439a98ba262c5d99b91a9c11aaeced67f583febab5a4b1566\n",
            "Successfully built torch-spline-conv\n",
            "Installing collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QhmUyy3OxSA",
        "colab_type": "code",
        "outputId": "db8f5c90-c521-45f1-f460-b77f2cb11b5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        }
      },
      "source": [
        "!pip install torch-geometric"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch-geometric\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/50/0a802f0bfa68058bf025d219ec6fbe806a5b891bba6702e28be7b83679fb/torch_geometric-1.3.2.tar.gz (126kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 27.0MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 30.9MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 30kB 36.7MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 40kB 29.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51kB 31.7MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 61kB 35.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 71kB 31.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 81kB 32.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 92kB 34.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 102kB 32.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 112kB 32.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 122kB 32.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 32.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.17.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.3.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.21.0)\n",
            "Collecting plyfile\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/15/434d1d96f9a41fea56cb3290718123d651c56c4b7e53f0249acaf1bf34b6/plyfile-0.7.1.tar.gz\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.25.3)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/fe/630bacb652680f6d481b9febbb3e2c3869194a1a5fc3401a4a41195a2f8f/rdflib-4.2.2-py3-none-any.whl (344kB)\n",
            "\u001b[K     |████████████████████████████████| 348kB 40.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.8.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch-geometric) (4.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch-geometric) (0.14.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (2.4.5)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->torch-geometric) (1.12.0)\n",
            "Building wheels for collected packages: torch-geometric, plyfile\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.3.2-cp36-none-any.whl size=203339 sha256=df618347d0c62d7c03fc03861dc7a36c774f449396d70e631f00589759f4135d\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/75/0a/56a0fd58efac6d990782523e20e61c9307fc42c31564d40348\n",
            "  Building wheel for plyfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for plyfile: filename=plyfile-0.7.1-cp36-none-any.whl size=32827 sha256=7f807a0ba8b4c429ff4ceb88ca156c32c553d8cdc117aa08e87c9247d22a0d04\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/0d/bf/6d603d81b98604d2ecfd5e99d4ab7c9af664fd5285ab82bbb0\n",
            "Successfully built torch-geometric plyfile\n",
            "Installing collected packages: plyfile, isodate, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.0 plyfile-0.7.1 rdflib-4.2.2 torch-geometric-1.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1D-3usfvRC8X",
        "colab_type": "code",
        "outputId": "25bd46bb-9457-4a28-d742-a84f2dbd4caf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Installing dependencies for RDKit\n",
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!time bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!time conda install -q -y -c conda-forge rdkit"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-18 03:48:49--  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.201.79, 104.18.200.79, 2606:4700::6812:c94f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.201.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 71785000 (68M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’\n",
            "\n",
            "\r          Miniconda   0%[                    ]       0  --.-KB/s               \r         Miniconda3  74%[=============>      ]  50.93M   255MB/s               \rMiniconda3-latest-L 100%[===================>]  68.46M   264MB/s    in 0.3s    \n",
            "\n",
            "2019-12-18 03:48:50 (264 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [71785000/71785000]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - asn1crypto==1.2.0=py37_0\n",
            "    - ca-certificates==2019.10.16=0\n",
            "    - certifi==2019.9.11=py37_0\n",
            "    - cffi==1.13.0=py37h2e261b9_0\n",
            "    - chardet==3.0.4=py37_1003\n",
            "    - conda-package-handling==1.6.0=py37h7b6447c_0\n",
            "    - conda==4.7.12=py37_0\n",
            "    - cryptography==2.8=py37h1ba5d50_0\n",
            "    - idna==2.8=py37_0\n",
            "    - libedit==3.1.20181209=hc058e9b_0\n",
            "    - libffi==3.2.1=hd88cf55_4\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - ncurses==6.1=he6710b0_1\n",
            "    - openssl==1.1.1d=h7b6447c_3\n",
            "    - pip==19.3.1=py37_0\n",
            "    - pycosat==0.6.3=py37h14c3975_0\n",
            "    - pycparser==2.19=py37_0\n",
            "    - pyopenssl==19.0.0=py37_0\n",
            "    - pysocks==1.7.1=py37_0\n",
            "    - python==3.7.4=h265db76_1\n",
            "    - readline==7.0=h7b6447c_5\n",
            "    - requests==2.22.0=py37_0\n",
            "    - ruamel_yaml==0.15.46=py37h14c3975_0\n",
            "    - setuptools==41.4.0=py37_0\n",
            "    - six==1.12.0=py37_0\n",
            "    - sqlite==3.30.0=h7b6447c_0\n",
            "    - tk==8.6.8=hbc83047_0\n",
            "    - tqdm==4.36.1=py_0\n",
            "    - urllib3==1.24.2=py37_0\n",
            "    - wheel==0.33.6=py37_0\n",
            "    - xz==5.2.4=h14c3975_4\n",
            "    - yaml==0.1.7=had09818_2\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  asn1crypto         pkgs/main/linux-64::asn1crypto-1.2.0-py37_0\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2019.10.16-0\n",
            "  certifi            pkgs/main/linux-64::certifi-2019.9.11-py37_0\n",
            "  cffi               pkgs/main/linux-64::cffi-1.13.0-py37h2e261b9_0\n",
            "  chardet            pkgs/main/linux-64::chardet-3.0.4-py37_1003\n",
            "  conda              pkgs/main/linux-64::conda-4.7.12-py37_0\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.6.0-py37h7b6447c_0\n",
            "  cryptography       pkgs/main/linux-64::cryptography-2.8-py37h1ba5d50_0\n",
            "  idna               pkgs/main/linux-64::idna-2.8-py37_0\n",
            "  libedit            pkgs/main/linux-64::libedit-3.1.20181209-hc058e9b_0\n",
            "  libffi             pkgs/main/linux-64::libffi-3.2.1-hd88cf55_4\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.1-he6710b0_1\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1d-h7b6447c_3\n",
            "  pip                pkgs/main/linux-64::pip-19.3.1-py37_0\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py37h14c3975_0\n",
            "  pycparser          pkgs/main/linux-64::pycparser-2.19-py37_0\n",
            "  pyopenssl          pkgs/main/linux-64::pyopenssl-19.0.0-py37_0\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py37_0\n",
            "  python             pkgs/main/linux-64::python-3.7.4-h265db76_1\n",
            "  readline           pkgs/main/linux-64::readline-7.0-h7b6447c_5\n",
            "  requests           pkgs/main/linux-64::requests-2.22.0-py37_0\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.46-py37h14c3975_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-41.4.0-py37_0\n",
            "  six                pkgs/main/linux-64::six-1.12.0-py37_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.30.0-h7b6447c_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.8-hbc83047_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.36.1-py_0\n",
            "  urllib3            pkgs/main/linux-64::urllib3-1.24.2-py37_0\n",
            "  wheel              pkgs/main/linux-64::wheel-0.33.6-py37_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.4-h14c3975_4\n",
            "  yaml               pkgs/main/linux-64::yaml-0.1.7-had09818_2\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n",
            "\n",
            "\n",
            "Preparing transaction: | \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "\n",
            "real\t0m13.232s\n",
            "user\t0m7.727s\n",
            "sys\t0m2.844s\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    boost-1.70.0               |   py37h9de70de_1         337 KB  conda-forge\n",
            "    boost-cpp-1.70.0           |       h8e57a91_2        21.1 MB  conda-forge\n",
            "    bzip2-1.0.8                |       h516909a_2         396 KB  conda-forge\n",
            "    ca-certificates-2019.11.28 |       hecc5488_0         145 KB  conda-forge\n",
            "    cairo-1.16.0               |    hfb77d84_1002         1.5 MB  conda-forge\n",
            "    certifi-2019.11.28         |           py37_0         148 KB  conda-forge\n",
            "    conda-4.8.0                |           py37_1         3.0 MB  conda-forge\n",
            "    fontconfig-2.13.1          |    h86ecdb6_1001         340 KB  conda-forge\n",
            "    freetype-2.10.0            |       he983fc9_1         884 KB  conda-forge\n",
            "    gettext-0.19.8.1           |    hc5be6a0_1002         3.6 MB  conda-forge\n",
            "    glib-2.58.3                |py37h6f030ca_1002         3.3 MB  conda-forge\n",
            "    icu-64.2                   |       he1b5a44_1        12.6 MB  conda-forge\n",
            "    jpeg-9c                    |    h14c3975_1001         251 KB  conda-forge\n",
            "    libblas-3.8.0              |      14_openblas          10 KB  conda-forge\n",
            "    libcblas-3.8.0             |      14_openblas          10 KB  conda-forge\n",
            "    libgfortran-ng-7.3.0       |       hdf63c60_2         1.7 MB  conda-forge\n",
            "    libiconv-1.15              |    h516909a_1005         2.0 MB  conda-forge\n",
            "    liblapack-3.8.0            |      14_openblas          10 KB  conda-forge\n",
            "    libopenblas-0.3.7          |       h5ec1e0e_5         7.6 MB  conda-forge\n",
            "    libpng-1.6.37              |       hed695b0_0         343 KB  conda-forge\n",
            "    libtiff-4.1.0              |       hc3755c2_1         609 KB  conda-forge\n",
            "    libuuid-2.32.1             |    h14c3975_1000          26 KB  conda-forge\n",
            "    libxcb-1.13                |    h14c3975_1002         396 KB  conda-forge\n",
            "    libxml2-2.9.10             |       hee79883_0         1.3 MB  conda-forge\n",
            "    lz4-c-1.8.3                |    he1b5a44_1001         187 KB  conda-forge\n",
            "    numpy-1.17.3               |   py37h95a1406_0         5.1 MB  conda-forge\n",
            "    olefile-0.46               |             py_0          31 KB  conda-forge\n",
            "    openssl-1.1.1d             |       h516909a_0         2.1 MB  conda-forge\n",
            "    pandas-0.25.3              |   py37hb3f55d8_0        11.4 MB  conda-forge\n",
            "    pcre-8.43                  |       he1b5a44_0         257 KB  conda-forge\n",
            "    pillow-6.2.1               |   py37h34e0f95_0         643 KB\n",
            "    pixman-0.38.0              |    h516909a_1003         594 KB  conda-forge\n",
            "    pthread-stubs-0.4          |    h14c3975_1001           5 KB  conda-forge\n",
            "    pycairo-1.18.2             |   py37h438ddbb_0          77 KB  conda-forge\n",
            "    python-dateutil-2.8.1      |             py_0         220 KB  conda-forge\n",
            "    pytz-2019.3                |             py_0         237 KB  conda-forge\n",
            "    rdkit-2019.09.2            |   py37hb31dc5d_0        23.8 MB  conda-forge\n",
            "    xorg-kbproto-1.0.7         |    h14c3975_1002          26 KB  conda-forge\n",
            "    xorg-libice-1.0.10         |       h516909a_0          57 KB  conda-forge\n",
            "    xorg-libsm-1.2.3           |    h84519dc_1000          25 KB  conda-forge\n",
            "    xorg-libx11-1.6.9          |       h516909a_0         918 KB  conda-forge\n",
            "    xorg-libxau-1.0.9          |       h14c3975_0          13 KB  conda-forge\n",
            "    xorg-libxdmcp-1.1.3        |       h516909a_0          18 KB  conda-forge\n",
            "    xorg-libxext-1.3.4         |       h516909a_0          51 KB  conda-forge\n",
            "    xorg-libxrender-0.9.10     |    h516909a_1002          31 KB  conda-forge\n",
            "    xorg-renderproto-0.11.1    |    h14c3975_1002           8 KB  conda-forge\n",
            "    xorg-xextproto-7.3.0       |    h14c3975_1002          27 KB  conda-forge\n",
            "    xorg-xproto-7.0.31         |    h14c3975_1007          72 KB  conda-forge\n",
            "    zstd-1.4.4                 |       h3b9ef0a_1         989 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       108.4 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  boost              conda-forge/linux-64::boost-1.70.0-py37h9de70de_1\n",
            "  boost-cpp          conda-forge/linux-64::boost-cpp-1.70.0-h8e57a91_2\n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h516909a_2\n",
            "  cairo              conda-forge/linux-64::cairo-1.16.0-hfb77d84_1002\n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.13.1-h86ecdb6_1001\n",
            "  freetype           conda-forge/linux-64::freetype-2.10.0-he983fc9_1\n",
            "  gettext            conda-forge/linux-64::gettext-0.19.8.1-hc5be6a0_1002\n",
            "  glib               conda-forge/linux-64::glib-2.58.3-py37h6f030ca_1002\n",
            "  icu                conda-forge/linux-64::icu-64.2-he1b5a44_1\n",
            "  jpeg               conda-forge/linux-64::jpeg-9c-h14c3975_1001\n",
            "  libblas            conda-forge/linux-64::libblas-3.8.0-14_openblas\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.8.0-14_openblas\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-7.3.0-hdf63c60_2\n",
            "  libiconv           conda-forge/linux-64::libiconv-1.15-h516909a_1005\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.8.0-14_openblas\n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.7-h5ec1e0e_5\n",
            "  libpng             conda-forge/linux-64::libpng-1.6.37-hed695b0_0\n",
            "  libtiff            conda-forge/linux-64::libtiff-4.1.0-hc3755c2_1\n",
            "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h14c3975_1000\n",
            "  libxcb             conda-forge/linux-64::libxcb-1.13-h14c3975_1002\n",
            "  libxml2            conda-forge/linux-64::libxml2-2.9.10-hee79883_0\n",
            "  lz4-c              conda-forge/linux-64::lz4-c-1.8.3-he1b5a44_1001\n",
            "  numpy              conda-forge/linux-64::numpy-1.17.3-py37h95a1406_0\n",
            "  olefile            conda-forge/noarch::olefile-0.46-py_0\n",
            "  pandas             conda-forge/linux-64::pandas-0.25.3-py37hb3f55d8_0\n",
            "  pcre               conda-forge/linux-64::pcre-8.43-he1b5a44_0\n",
            "  pillow             pkgs/main/linux-64::pillow-6.2.1-py37h34e0f95_0\n",
            "  pixman             conda-forge/linux-64::pixman-0.38.0-h516909a_1003\n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h14c3975_1001\n",
            "  pycairo            conda-forge/linux-64::pycairo-1.18.2-py37h438ddbb_0\n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.1-py_0\n",
            "  pytz               conda-forge/noarch::pytz-2019.3-py_0\n",
            "  rdkit              conda-forge/linux-64::rdkit-2019.09.2-py37hb31dc5d_0\n",
            "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-h14c3975_1002\n",
            "  xorg-libice        conda-forge/linux-64::xorg-libice-1.0.10-h516909a_0\n",
            "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.3-h84519dc_1000\n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.6.9-h516909a_0\n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.9-h14c3975_0\n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h516909a_0\n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h516909a_0\n",
            "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.10-h516909a_1002\n",
            "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-h14c3975_1002\n",
            "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-h14c3975_1002\n",
            "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-h14c3975_1007\n",
            "  zstd               conda-forge/linux-64::zstd-1.4.4-h3b9ef0a_1\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates    pkgs/main::ca-certificates-2019.10.16~ --> conda-forge::ca-certificates-2019.11.28-hecc5488_0\n",
            "  certifi               pkgs/main::certifi-2019.9.11-py37_0 --> conda-forge::certifi-2019.11.28-py37_0\n",
            "  conda                      pkgs/main::conda-4.7.12-py37_0 --> conda-forge::conda-4.8.0-py37_1\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  openssl              pkgs/main::openssl-1.1.1d-h7b6447c_3 --> conda-forge::openssl-1.1.1d-h516909a_0\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "\n",
            "real\t0m37.873s\n",
            "user\t0m31.855s\n",
            "sys\t0m3.565s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIqiCfVdRKHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Imh4PiQ-RvcI",
        "colab_type": "code",
        "outputId": "fe8f7518-4088-4a0b-e6b2-05af6f33ecbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adcjwaHnT3LR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root = \"/content/drive\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz2GKCVNRLv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Sequential, Linear, ReLU, GRU\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import QM9\n",
        "from torch_geometric.nn import NNConv, Set2Set\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.utils import remove_self_loops\n",
        "\n",
        "target = 0\n",
        "dim = 64\n",
        "\n",
        "\n",
        "class MyTransform(object):\n",
        "    def __call__(self, data):\n",
        "        # Specify target.\n",
        "        data.y = data.y[:, target]\n",
        "        return data\n",
        "\n",
        "\n",
        "class Complete(object):\n",
        "    def __call__(self, data):\n",
        "        device = data.edge_index.device\n",
        "\n",
        "        row = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
        "        col = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
        "\n",
        "        row = row.view(-1, 1).repeat(1, data.num_nodes).view(-1)\n",
        "        col = col.repeat(data.num_nodes)\n",
        "        edge_index = torch.stack([row, col], dim=0)\n",
        "\n",
        "        edge_attr = None\n",
        "        if data.edge_attr is not None:\n",
        "            idx = data.edge_index[0] * data.num_nodes + data.edge_index[1]\n",
        "            size = list(data.edge_attr.size())\n",
        "            size[0] = data.num_nodes * data.num_nodes\n",
        "            edge_attr = data.edge_attr.new_zeros(size)\n",
        "            edge_attr[idx] = data.edge_attr\n",
        "\n",
        "        edge_index, edge_attr = remove_self_loops(edge_index, edge_attr)\n",
        "        data.edge_attr = edge_attr\n",
        "        data.edge_index = edge_index\n",
        "\n",
        "        return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPUmXngCuxs9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_sparse import coalesce\n",
        "from torch_geometric.data import (InMemoryDataset, download_url, extract_zip,\n",
        "                                  Data)\n",
        "\n",
        "try:\n",
        "    import rdkit\n",
        "    from rdkit import Chem\n",
        "    from rdkit import rdBase\n",
        "    from rdkit.Chem.rdchem import HybridizationType\n",
        "    from rdkit import RDConfig\n",
        "    from rdkit.Chem import ChemicalFeatures\n",
        "    from rdkit.Chem.rdchem import BondType as BT\n",
        "    rdBase.DisableLog('rdApp.error')\n",
        "except ImportError:\n",
        "    rdkit = None\n",
        "\n",
        "\n",
        "class QM9(InMemoryDataset):\n",
        "    r\"\"\"The QM9 dataset from the `\"MoleculeNet: A Benchmark for Molecular\n",
        "    Machine Learning\" <https://arxiv.org/abs/1703.00564>`_ paper, consisting of\n",
        "    about 130,000 molecules with 16 regression targets.\n",
        "    Each molecule includes complete spatial information for the single low\n",
        "    energy conformation of the atoms in the molecule.\n",
        "    In addition, we provide the atom features from the `\"Neural Message\n",
        "    Passing for Quantum Chemistry\" <https://arxiv.org/abs/1704.01212>`_ paper.\n",
        "\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | Target | Property                         | Description                                                                       | Unit                                        |\n",
        "    +========+==================================+===================================================================================+=============================================+\n",
        "    | 0      | :math:`\\mu`                      | Dipole moment                                                                     | :math:`\\textrm{D}`                          |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 1      | :math:`\\alpha`                   | Isotropic polarizability                                                          | :math:`{a_0}^3`                             |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 2      | :math:`\\epsilon_{\\textrm{HOMO}}` | Highest occupied molecular orbital energy                                         | :math:`E_{\\textrm{h}}`                      |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 3      | :math:`\\epsilon_{\\textrm{LUMO}}` | Lowest unoccupied molecular orbital energy                                        | :math:`E_{\\textrm{h}}`                      |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 4      | :math:`\\Delta \\epsilon`          | Gap between :math:`\\epsilon_{\\textrm{HOMO}}` and :math:`\\epsilon_{\\textrm{LUMO}}` | :math:`E_{\\textrm{h}}`                      |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 5      | :math:`\\langle R^2 \\rangle`      | Electronic spatial extent                                                         | :math:`{a_0}^2`                             |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 6      | :math:`\\textrm{ZPVE}`            | Zero point vibrational energy                                                     | :math:`E_{\\textrm{h}}`                      |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 7      | :math:`U_0`                      | Internal energy at 0K                                                             | :math:`E_{\\textrm{h}}`                      |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 8      | :math:`U`                        | Internal energy at 298.15K                                                        | :math:`E_{\\textrm{h}}`                      |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 9      | :math:`H`                        | Enthalpy at 298.15K                                                               | :math:`E_{\\textrm{h}}`                      |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 10     | :math:`G`                        | Free energy at 298.15K                                                            | :math:`E_{\\textrm{h}}`                      |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 11     | :math:`c_{\\textrm{v}}`           | Heat capavity at 298.15K                                                          | :math:`\\frac{\\textrm{cal}}{\\textrm{mol K}}` |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 12     | :math:`U_0^{\\textrm{ATOM}}`      | Atomization energy at 0K                                                          | :math:`\\frac{\\textrm{kcal}}{\\textrm{mol}}`  |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 13     | :math:`U^{\\textrm{ATOM}}`        | Atomization energy at 298.15K                                                     | :math:`\\frac{\\textrm{kcal}}{\\textrm{mol}}`  |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 14     | :math:`H^{\\textrm{ATOM}}`        | Atomization enthalpy at 298.15K                                                   | :math:`\\frac{\\textrm{kcal}}{\\textrm{mol}}`  |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 15     | :math:`G^{\\textrm{ATOM}}`        | Atomization free energy at 298.15K                                                | :math:`\\frac{\\textrm{kcal}}{\\textrm{mol}}`  |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "\n",
        "    Args:\n",
        "        root (string): Root directory where the dataset should be saved.\n",
        "        transform (callable, optional): A function/transform that takes in an\n",
        "            :obj:`torch_geometric.data.Data` object and returns a transformed\n",
        "            version. The data object will be transformed before every access.\n",
        "            (default: :obj:`None`)\n",
        "        pre_transform (callable, optional): A function/transform that takes in\n",
        "            an :obj:`torch_geometric.data.Data` object and returns a\n",
        "            transformed version. The data object will be transformed before\n",
        "            being saved to disk. (default: :obj:`None`)\n",
        "        pre_filter (callable, optional): A function that takes in an\n",
        "            :obj:`torch_geometric.data.Data` object and returns a boolean\n",
        "            value, indicating whether the data object should be included in the\n",
        "            final dataset. (default: :obj:`None`)\n",
        "    \"\"\"  # noqa: E501\n",
        "\n",
        "    raw_url = ('https://s3-us-west-1.amazonaws.com/deepchem.io/datasets/'\n",
        "               'molnet_publish/qm9.zip')\n",
        "    processed_url = 'http://www.roemisch-drei.de/qm9.zip'\n",
        "\n",
        "    if rdkit is not None:\n",
        "        types = {'H': 0, 'C': 1, 'N': 2, 'O': 3, 'F': 4}\n",
        "        bonds = {BT.SINGLE: 0, BT.DOUBLE: 1, BT.TRIPLE: 2, BT.AROMATIC: 3}\n",
        "\n",
        "    def __init__(self, root, transform=None, pre_transform=None,\n",
        "                 pre_filter=None):\n",
        "        super(QM9, self).__init__(root, transform, pre_transform, pre_filter)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return 'qm9.pt' if rdkit is None else ['gdb9.sdf', 'gdb9.sdf.csv']\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return 'data.pt'\n",
        "\n",
        "    def download(self):\n",
        "        url = self.processed_url if rdkit is None else self.raw_url\n",
        "        file_path = download_url(url, self.raw_dir)\n",
        "        extract_zip(file_path, self.raw_dir)\n",
        "        os.unlink(file_path)\n",
        "\n",
        "    def process(self):\n",
        "        if rdkit is None:\n",
        "            print('Using a pre-processed version of the dataset. Please '\n",
        "                  'install `rdkit` to alternatively process the raw data.')\n",
        "\n",
        "            self.data, self.slices = torch.load(self.raw_paths[0])\n",
        "            data_list = [data for data in self]\n",
        "\n",
        "            if self.pre_filter is not None:\n",
        "                data_list = [d for d in data_list if self.pre_filter(d)]\n",
        "\n",
        "            if self.pre_transform is not None:\n",
        "                data_list = [self.pre_transform(d) for d in data_list]\n",
        "\n",
        "            data, slices = self.collate(data_list)\n",
        "            torch.save((data, slices), self.processed_paths[0])\n",
        "            return\n",
        "   #Change configuration for just one target\n",
        "        with open(self.raw_paths[1], 'r') as f:\n",
        "            target = f.read().split('\\n')[1:-1]\n",
        "            target = [[float(x) for x in line.split(',')[5:6]]\n",
        "                      for line in target]\n",
        "            target = torch.tensor(target, dtype=torch.float)\n",
        "\n",
        "        suppl = Chem.SDMolSupplier(self.raw_paths[0], removeHs=False)\n",
        "        fdef_name = osp.join(RDConfig.RDDataDir, 'BaseFeatures.fdef')\n",
        "        factory = ChemicalFeatures.BuildFeatureFactory(fdef_name)\n",
        "\n",
        "        data_list = []\n",
        "        count=0\n",
        "        for i, mol in enumerate(suppl):\n",
        "          if ( count<13000):\n",
        "            if mol is None:\n",
        "                continue\n",
        "\n",
        "            text = suppl.GetItemText(i)\n",
        "            N = mol.GetNumAtoms()\n",
        "\n",
        "            pos = text.split('\\n')[4:4 + N]\n",
        "            pos = [[float(x) for x in line.split()[:3]] for line in pos]\n",
        "            pos = torch.tensor(pos, dtype=torch.float)\n",
        "\n",
        "            type_idx = []\n",
        "            atomic_number = []\n",
        "            acceptor = []\n",
        "            donor = []\n",
        "            aromatic = []\n",
        "            sp = []\n",
        "            sp2 = []\n",
        "            sp3 = []\n",
        "            num_hs = []\n",
        "            for atom in mol.GetAtoms():\n",
        "                type_idx.append(self.types[atom.GetSymbol()])\n",
        "                atomic_number.append(atom.GetAtomicNum())\n",
        "                donor.append(0)\n",
        "                acceptor.append(0)\n",
        "                aromatic.append(1 if atom.GetIsAromatic() else 0)\n",
        "                hybridization = atom.GetHybridization()\n",
        "                sp.append(1 if hybridization == HybridizationType.SP else 0)\n",
        "                sp2.append(1 if hybridization == HybridizationType.SP2 else 0)\n",
        "                sp3.append(1 if hybridization == HybridizationType.SP3 else 0)\n",
        "                num_hs.append(atom.GetTotalNumHs(includeNeighbors=True))\n",
        "\n",
        "            feats = factory.GetFeaturesForMol(mol)\n",
        "            for j in range(0, len(feats)):\n",
        "                if feats[j].GetFamily() == 'Donor':\n",
        "                    node_list = feats[j].GetAtomIds()\n",
        "                    for k in node_list:\n",
        "                        donor[k] = 1\n",
        "                elif feats[j].GetFamily() == 'Acceptor':\n",
        "                    node_list = feats[j].GetAtomIds()\n",
        "                    for k in node_list:\n",
        "                        acceptor[k] = 1\n",
        "\n",
        "\n",
        "            row, col, bond_idx = [], [], []\n",
        "            bond_type= [0] * N\n",
        "            i=0\n",
        "            for bond in mol.GetBonds():\n",
        "                start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
        "                row += [start, end]\n",
        "                col += [end, start]\n",
        "                bond_idx += 2 * [self.bonds[bond.GetBondType()]]\n",
        "                if i<N:\n",
        "                  bond_type[i]=2 *self.bonds[bond.GetBondType()]\n",
        "                  i=i+1    \n",
        "            \n",
        "            x1 = F.one_hot(torch.tensor(type_idx), num_classes=len(self.types))\n",
        "            x2 = torch.tensor([\n",
        "                atomic_number, acceptor, donor, aromatic, sp, sp2, sp3, num_hs, bond_type\n",
        "            ], dtype=torch.float).t().contiguous()\n",
        "            x = torch.cat([x1.to(torch.float), x2], dim=-1)    \n",
        "\n",
        "            edge_index = torch.tensor([row, col], dtype=torch.long)\n",
        "            edge_attr = F.one_hot(torch.tensor(bond_idx),\n",
        "                                  num_classes=len(self.bonds)).to(torch.float)\n",
        "            edge_index, edge_attr = coalesce(edge_index, edge_attr, N, N)\n",
        "\n",
        "            y = target[i].unsqueeze(0)\n",
        "\n",
        "            data = Data(x=x, pos=pos, edge_index=edge_index,\n",
        "                        edge_attr=edge_attr, y=y)\n",
        "\n",
        "            if self.pre_filter is not None and not self.pre_filter(data):\n",
        "                continue\n",
        "            if self.pre_transform is not None:\n",
        "                data = self.pre_transform(data)\n",
        "\n",
        "            data_list.append(data)\n",
        "          count=count+1\n",
        "        torch.save(self.collate(data_list), self.processed_paths[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPDz9Ax0T0H0",
        "colab_type": "code",
        "outputId": "5090c6fb-0308-4842-e244-5dd12d2e70e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "import os\n",
        "path = osp.join(osp.dirname(osp.realpath(root)), '..', 'data', 'QM9')\n",
        "transform = T.Compose([MyTransform(), Complete(), T.Distance(norm=False)])\n",
        "dataset = QM9(path, transform=transform).shuffle()\n",
        "\n",
        "# Normalize targets to mean = 0 and std = 1.\n",
        "mean = dataset.data.y.mean(dim=0, keepdim=True)\n",
        "std = dataset.data.y.std(dim=0, keepdim=True)\n",
        "dataset.data.y = (dataset.data.y - mean) / std\n",
        "mean, std = mean[:, target].item(), std[:, target].item()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://s3-us-west-1.amazonaws.com/deepchem.io/datasets/molnet_publish/qm9.zip\n",
            "Extracting /data/QM9/raw/qm9.zip\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E20IouBDdtop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split datasets.\n",
        "test_dataset = dataset[:1000]\n",
        "val_dataset = dataset[1000:2000]\n",
        "train_dataset = dataset[2000:13000]\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG6NlrlSUIti",
        "colab_type": "code",
        "outputId": "defd80c2-b112-4eb2-da80-bc9bcafbd6c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import SAGEConv\n",
        "\n",
        "class Set2SetNet(torch.nn.Module):\n",
        "    def __init__(self, dataset, num_layers=2, hidden=128):\n",
        "        super(Set2SetNet, self).__init__()\n",
        "        self.conv1 = SAGEConv(dataset.num_features, hidden)\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for i in range(num_layers - 1):\n",
        "            self.convs.append(SAGEConv(hidden, hidden))\n",
        "        self.set2set = Set2Set(hidden, processing_steps=3)\n",
        "        self.lin1 = Linear(2 * hidden, hidden)\n",
        "        self.lin2 = Linear(hidden, 1)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.conv1.reset_parameters()\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "        self.set2set.reset_parameters()\n",
        "        self.lin1.reset_parameters()\n",
        "        self.lin2.reset_parameters()\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        for conv in self.convs:\n",
        "            x = F.relu(conv(x, edge_index))\n",
        "        x = self.set2set(x, batch)\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = self.lin2(x)\n",
        "        return x.view(-1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = Set2SetNet(dataset=dataset, ).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
        "                                                       factor=0.7, patience=5,\n",
        "                                                       min_lr=0.00001)\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    loss_all = 0\n",
        "\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss = F.mse_loss(model(data), data.y)\n",
        "        loss.backward()\n",
        "        loss_all += loss.item() * data.num_graphs\n",
        "        optimizer.step()\n",
        "    return loss_all / len(train_loader.dataset)\n",
        "\n",
        "\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "    error = 0\n",
        "\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        error += (model(data) * std - data.y * std).abs().sum().item()  # MAE\n",
        "    return error / len(loader.dataset)\n",
        "\n",
        "\n",
        "best_val_error = None\n",
        "for epoch in range(1, 301):\n",
        "    lr = scheduler.optimizer.param_groups[0]['lr']\n",
        "    loss = train(epoch)\n",
        "    val_error = test(val_loader)\n",
        "    scheduler.step(val_error)\n",
        "\n",
        "    if best_val_error is None or val_error <= best_val_error:\n",
        "        test_error = test(test_loader)\n",
        "        best_val_error = val_error\n",
        "\n",
        "    print('Epoch: {:03d}, LR: {:7f}, Loss: {:.7f}, Validation MAE: {:.7f}, '\n",
        "          'Test MAE: {:.7f}'.format(epoch, lr, loss, val_error, test_error))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 001, LR: 0.001000, Loss: 0.8123433, Validation MAE: 3.7281152, Test MAE: 3.7841714\n",
            "Epoch: 002, LR: 0.001000, Loss: 0.7449810, Validation MAE: 3.5987376, Test MAE: 3.6468473\n",
            "Epoch: 003, LR: 0.001000, Loss: 0.7156896, Validation MAE: 3.5719919, Test MAE: 3.6217625\n",
            "Epoch: 004, LR: 0.001000, Loss: 0.6764029, Validation MAE: 3.9808730, Test MAE: 3.6217625\n",
            "Epoch: 005, LR: 0.001000, Loss: 0.6317126, Validation MAE: 3.5549599, Test MAE: 3.5353976\n",
            "Epoch: 006, LR: 0.001000, Loss: 0.5725024, Validation MAE: 3.3182623, Test MAE: 3.2452231\n",
            "Epoch: 007, LR: 0.001000, Loss: 0.5345017, Validation MAE: 3.2614482, Test MAE: 3.1732632\n",
            "Epoch: 008, LR: 0.001000, Loss: 0.4931718, Validation MAE: 2.9782604, Test MAE: 2.8924472\n",
            "Epoch: 009, LR: 0.001000, Loss: 0.4735701, Validation MAE: 2.9015823, Test MAE: 2.7970236\n",
            "Epoch: 010, LR: 0.001000, Loss: 0.4528103, Validation MAE: 2.8222365, Test MAE: 2.7023795\n",
            "Epoch: 011, LR: 0.001000, Loss: 0.4220067, Validation MAE: 2.9944924, Test MAE: 2.7023795\n",
            "Epoch: 012, LR: 0.001000, Loss: 0.4160197, Validation MAE: 3.0334511, Test MAE: 2.7023795\n",
            "Epoch: 013, LR: 0.001000, Loss: 0.3966854, Validation MAE: 2.6879565, Test MAE: 2.5353231\n",
            "Epoch: 014, LR: 0.001000, Loss: 0.4018911, Validation MAE: 3.0950038, Test MAE: 2.5353231\n",
            "Epoch: 015, LR: 0.001000, Loss: 0.3991346, Validation MAE: 2.9547668, Test MAE: 2.5353231\n",
            "Epoch: 016, LR: 0.001000, Loss: 0.3812571, Validation MAE: 2.5771637, Test MAE: 2.4632616\n",
            "Epoch: 017, LR: 0.001000, Loss: 0.3761163, Validation MAE: 2.8153865, Test MAE: 2.4632616\n",
            "Epoch: 018, LR: 0.001000, Loss: 0.3784182, Validation MAE: 2.5654213, Test MAE: 2.4442722\n",
            "Epoch: 019, LR: 0.001000, Loss: 0.3679018, Validation MAE: 2.6095855, Test MAE: 2.4442722\n",
            "Epoch: 020, LR: 0.001000, Loss: 0.3680978, Validation MAE: 2.6475887, Test MAE: 2.4442722\n",
            "Epoch: 021, LR: 0.001000, Loss: 0.3576210, Validation MAE: 2.5140024, Test MAE: 2.4420123\n",
            "Epoch: 022, LR: 0.001000, Loss: 0.3613730, Validation MAE: 2.6264975, Test MAE: 2.4420123\n",
            "Epoch: 023, LR: 0.001000, Loss: 0.3575919, Validation MAE: 2.6169122, Test MAE: 2.4420123\n",
            "Epoch: 024, LR: 0.001000, Loss: 0.3604423, Validation MAE: 2.5383742, Test MAE: 2.4420123\n",
            "Epoch: 025, LR: 0.001000, Loss: 0.3471332, Validation MAE: 2.5620339, Test MAE: 2.4420123\n",
            "Epoch: 026, LR: 0.001000, Loss: 0.3461625, Validation MAE: 2.6121105, Test MAE: 2.4420123\n",
            "Epoch: 027, LR: 0.001000, Loss: 0.3485402, Validation MAE: 2.3365286, Test MAE: 2.2552750\n",
            "Epoch: 028, LR: 0.001000, Loss: 0.3359528, Validation MAE: 2.3975345, Test MAE: 2.2552750\n",
            "Epoch: 029, LR: 0.001000, Loss: 0.3523840, Validation MAE: 2.3632643, Test MAE: 2.2552750\n",
            "Epoch: 030, LR: 0.001000, Loss: 0.3171314, Validation MAE: 2.4078058, Test MAE: 2.2552750\n",
            "Epoch: 031, LR: 0.001000, Loss: 0.3177253, Validation MAE: 2.4132649, Test MAE: 2.2552750\n",
            "Epoch: 032, LR: 0.001000, Loss: 0.3476063, Validation MAE: 2.2690954, Test MAE: 2.2556205\n",
            "Epoch: 033, LR: 0.001000, Loss: 0.3030635, Validation MAE: 2.2104108, Test MAE: 2.1431144\n",
            "Epoch: 034, LR: 0.001000, Loss: 0.2963176, Validation MAE: 2.1648746, Test MAE: 2.1353347\n",
            "Epoch: 035, LR: 0.001000, Loss: 0.2795933, Validation MAE: 2.1162559, Test MAE: 2.1069171\n",
            "Epoch: 036, LR: 0.001000, Loss: 0.2910264, Validation MAE: 2.0172796, Test MAE: 2.0222163\n",
            "Epoch: 037, LR: 0.001000, Loss: 0.2884335, Validation MAE: 2.2085061, Test MAE: 2.0222163\n",
            "Epoch: 038, LR: 0.001000, Loss: 0.2647941, Validation MAE: 1.9712963, Test MAE: 1.9975009\n",
            "Epoch: 039, LR: 0.001000, Loss: 0.2619189, Validation MAE: 2.0715595, Test MAE: 1.9975009\n",
            "Epoch: 040, LR: 0.001000, Loss: 0.2644903, Validation MAE: 1.9065077, Test MAE: 1.9072099\n",
            "Epoch: 041, LR: 0.001000, Loss: 0.2574841, Validation MAE: 1.9403929, Test MAE: 1.9072099\n",
            "Epoch: 042, LR: 0.001000, Loss: 0.2580846, Validation MAE: 1.8910733, Test MAE: 1.9514162\n",
            "Epoch: 043, LR: 0.001000, Loss: 0.2471946, Validation MAE: 1.9755025, Test MAE: 1.9514162\n",
            "Epoch: 044, LR: 0.001000, Loss: 0.2782569, Validation MAE: 1.9444630, Test MAE: 1.9514162\n",
            "Epoch: 045, LR: 0.001000, Loss: 0.2398698, Validation MAE: 2.1365197, Test MAE: 1.9514162\n",
            "Epoch: 046, LR: 0.001000, Loss: 0.2801100, Validation MAE: 1.8129765, Test MAE: 1.8760603\n",
            "Epoch: 047, LR: 0.001000, Loss: 0.2317594, Validation MAE: 1.7475764, Test MAE: 1.8032584\n",
            "Epoch: 048, LR: 0.001000, Loss: 0.2257202, Validation MAE: 1.7896986, Test MAE: 1.8032584\n",
            "Epoch: 049, LR: 0.001000, Loss: 0.2148097, Validation MAE: 1.6736051, Test MAE: 1.7617456\n",
            "Epoch: 050, LR: 0.001000, Loss: 0.2260125, Validation MAE: 1.9552777, Test MAE: 1.7617456\n",
            "Epoch: 051, LR: 0.001000, Loss: 0.2174602, Validation MAE: 1.6581368, Test MAE: 1.7456354\n",
            "Epoch: 052, LR: 0.001000, Loss: 0.2034363, Validation MAE: 1.6336975, Test MAE: 1.6531683\n",
            "Epoch: 053, LR: 0.001000, Loss: 0.2237679, Validation MAE: 1.5884958, Test MAE: 1.6456924\n",
            "Epoch: 054, LR: 0.001000, Loss: 0.2034086, Validation MAE: 1.5899025, Test MAE: 1.6456924\n",
            "Epoch: 055, LR: 0.001000, Loss: 0.2011665, Validation MAE: 1.5136485, Test MAE: 1.6230685\n",
            "Epoch: 056, LR: 0.001000, Loss: 0.1862828, Validation MAE: 1.5228907, Test MAE: 1.6230685\n",
            "Epoch: 057, LR: 0.001000, Loss: 0.1872922, Validation MAE: 1.7532015, Test MAE: 1.6230685\n",
            "Epoch: 058, LR: 0.001000, Loss: 0.1857057, Validation MAE: 1.4988394, Test MAE: 1.5845475\n",
            "Epoch: 059, LR: 0.001000, Loss: 0.1956766, Validation MAE: 1.5462861, Test MAE: 1.5845475\n",
            "Epoch: 060, LR: 0.001000, Loss: 0.1908958, Validation MAE: 1.5546864, Test MAE: 1.5845475\n",
            "Epoch: 061, LR: 0.001000, Loss: 0.1809246, Validation MAE: 1.3806484, Test MAE: 1.4159322\n",
            "Epoch: 062, LR: 0.001000, Loss: 0.1777636, Validation MAE: 1.3892506, Test MAE: 1.4159322\n",
            "Epoch: 063, LR: 0.001000, Loss: 0.1743365, Validation MAE: 1.5246727, Test MAE: 1.4159322\n",
            "Epoch: 064, LR: 0.001000, Loss: 0.1845400, Validation MAE: 1.3304538, Test MAE: 1.4237806\n",
            "Epoch: 065, LR: 0.001000, Loss: 0.1766589, Validation MAE: 1.4522497, Test MAE: 1.4237806\n",
            "Epoch: 066, LR: 0.001000, Loss: 0.1638307, Validation MAE: 1.4132857, Test MAE: 1.4237806\n",
            "Epoch: 067, LR: 0.001000, Loss: 0.1831847, Validation MAE: 1.3928788, Test MAE: 1.4237806\n",
            "Epoch: 068, LR: 0.001000, Loss: 0.1558776, Validation MAE: 1.3744193, Test MAE: 1.4237806\n",
            "Epoch: 069, LR: 0.001000, Loss: 0.1724488, Validation MAE: 1.4085385, Test MAE: 1.4237806\n",
            "Epoch: 070, LR: 0.001000, Loss: 0.1903441, Validation MAE: 1.3734386, Test MAE: 1.4237806\n",
            "Epoch: 071, LR: 0.000700, Loss: 0.1539957, Validation MAE: 1.2144256, Test MAE: 1.3136265\n",
            "Epoch: 072, LR: 0.000700, Loss: 0.1457698, Validation MAE: 1.2058325, Test MAE: 1.3147165\n",
            "Epoch: 073, LR: 0.000700, Loss: 0.1410142, Validation MAE: 1.1502919, Test MAE: 1.2737986\n",
            "Epoch: 074, LR: 0.000700, Loss: 0.1369236, Validation MAE: 1.1542737, Test MAE: 1.2737986\n",
            "Epoch: 075, LR: 0.000700, Loss: 0.1378337, Validation MAE: 1.1709120, Test MAE: 1.2737986\n",
            "Epoch: 076, LR: 0.000700, Loss: 0.1365268, Validation MAE: 1.0864888, Test MAE: 1.2114015\n",
            "Epoch: 077, LR: 0.000700, Loss: 0.1308588, Validation MAE: 1.1209744, Test MAE: 1.2114015\n",
            "Epoch: 078, LR: 0.000700, Loss: 0.1306545, Validation MAE: 1.1320109, Test MAE: 1.2114015\n",
            "Epoch: 079, LR: 0.000700, Loss: 0.1295930, Validation MAE: 1.1933045, Test MAE: 1.2114015\n",
            "Epoch: 080, LR: 0.000700, Loss: 0.1274297, Validation MAE: 1.0695136, Test MAE: 1.1941732\n",
            "Epoch: 081, LR: 0.000700, Loss: 0.1273670, Validation MAE: 1.2984113, Test MAE: 1.1941732\n",
            "Epoch: 082, LR: 0.000700, Loss: 0.1391219, Validation MAE: 1.0973619, Test MAE: 1.1941732\n",
            "Epoch: 083, LR: 0.000700, Loss: 0.1242103, Validation MAE: 1.2054374, Test MAE: 1.1941732\n",
            "Epoch: 084, LR: 0.000700, Loss: 0.1239337, Validation MAE: 1.2231945, Test MAE: 1.1941732\n",
            "Epoch: 085, LR: 0.000700, Loss: 0.1559439, Validation MAE: 1.3270148, Test MAE: 1.1941732\n",
            "Epoch: 086, LR: 0.000700, Loss: 0.1220296, Validation MAE: 1.0203929, Test MAE: 1.1192933\n",
            "Epoch: 087, LR: 0.000700, Loss: 0.1201864, Validation MAE: 1.1406432, Test MAE: 1.1192933\n",
            "Epoch: 088, LR: 0.000700, Loss: 0.1131081, Validation MAE: 1.1285603, Test MAE: 1.1192933\n",
            "Epoch: 089, LR: 0.000700, Loss: 0.1189701, Validation MAE: 1.0688048, Test MAE: 1.1192933\n",
            "Epoch: 090, LR: 0.000700, Loss: 0.1120398, Validation MAE: 0.9112013, Test MAE: 1.0385752\n",
            "Epoch: 091, LR: 0.000700, Loss: 0.1087338, Validation MAE: 1.1096346, Test MAE: 1.0385752\n",
            "Epoch: 092, LR: 0.000700, Loss: 0.1103470, Validation MAE: 1.0616302, Test MAE: 1.0385752\n",
            "Epoch: 093, LR: 0.000700, Loss: 0.1130727, Validation MAE: 1.6117684, Test MAE: 1.0385752\n",
            "Epoch: 094, LR: 0.000700, Loss: 0.1155779, Validation MAE: 1.1055955, Test MAE: 1.0385752\n",
            "Epoch: 095, LR: 0.000700, Loss: 0.1081226, Validation MAE: 1.1857556, Test MAE: 1.0385752\n",
            "Epoch: 096, LR: 0.000700, Loss: 0.1057372, Validation MAE: 1.0735898, Test MAE: 1.0385752\n",
            "Epoch: 097, LR: 0.000490, Loss: 0.1108536, Validation MAE: 1.3109490, Test MAE: 1.0385752\n",
            "Epoch: 098, LR: 0.000490, Loss: 0.0989673, Validation MAE: 0.9232723, Test MAE: 1.0385752\n",
            "Epoch: 099, LR: 0.000490, Loss: 0.0928624, Validation MAE: 0.9214071, Test MAE: 1.0385752\n",
            "Epoch: 100, LR: 0.000490, Loss: 0.0916295, Validation MAE: 0.9867608, Test MAE: 1.0385752\n",
            "Epoch: 101, LR: 0.000490, Loss: 0.0925464, Validation MAE: 0.8850095, Test MAE: 0.9914441\n",
            "Epoch: 102, LR: 0.000490, Loss: 0.0925077, Validation MAE: 0.8284672, Test MAE: 0.9347761\n",
            "Epoch: 103, LR: 0.000490, Loss: 0.0891260, Validation MAE: 0.8536436, Test MAE: 0.9347761\n",
            "Epoch: 104, LR: 0.000490, Loss: 0.0869443, Validation MAE: 0.8842557, Test MAE: 0.9347761\n",
            "Epoch: 105, LR: 0.000490, Loss: 0.0894302, Validation MAE: 0.9169162, Test MAE: 0.9347761\n",
            "Epoch: 106, LR: 0.000490, Loss: 0.0901510, Validation MAE: 0.9559127, Test MAE: 0.9347761\n",
            "Epoch: 107, LR: 0.000490, Loss: 0.0866130, Validation MAE: 0.8457260, Test MAE: 0.9347761\n",
            "Epoch: 108, LR: 0.000490, Loss: 0.0855271, Validation MAE: 0.8550786, Test MAE: 0.9347761\n",
            "Epoch: 109, LR: 0.000343, Loss: 0.0808763, Validation MAE: 0.8723689, Test MAE: 0.9347761\n",
            "Epoch: 110, LR: 0.000343, Loss: 0.0796922, Validation MAE: 0.7849299, Test MAE: 0.8975510\n",
            "Epoch: 111, LR: 0.000343, Loss: 0.0797159, Validation MAE: 0.8995713, Test MAE: 0.8975510\n",
            "Epoch: 112, LR: 0.000343, Loss: 0.0800484, Validation MAE: 0.7563113, Test MAE: 0.8561416\n",
            "Epoch: 113, LR: 0.000343, Loss: 0.0786989, Validation MAE: 0.7816692, Test MAE: 0.8561416\n",
            "Epoch: 114, LR: 0.000343, Loss: 0.0772486, Validation MAE: 0.8394885, Test MAE: 0.8561416\n",
            "Epoch: 115, LR: 0.000343, Loss: 0.0773988, Validation MAE: 0.7601961, Test MAE: 0.8561416\n",
            "Epoch: 116, LR: 0.000343, Loss: 0.0760725, Validation MAE: 0.7802386, Test MAE: 0.8561416\n",
            "Epoch: 117, LR: 0.000343, Loss: 0.0765177, Validation MAE: 0.7445111, Test MAE: 0.8546933\n",
            "Epoch: 118, LR: 0.000343, Loss: 0.0750986, Validation MAE: 0.7822949, Test MAE: 0.8546933\n",
            "Epoch: 119, LR: 0.000343, Loss: 0.0743597, Validation MAE: 0.7730619, Test MAE: 0.8546933\n",
            "Epoch: 120, LR: 0.000343, Loss: 0.0750197, Validation MAE: 0.8034885, Test MAE: 0.8546933\n",
            "Epoch: 121, LR: 0.000343, Loss: 0.0750295, Validation MAE: 0.7790041, Test MAE: 0.8546933\n",
            "Epoch: 122, LR: 0.000343, Loss: 0.0748483, Validation MAE: 0.7714947, Test MAE: 0.8546933\n",
            "Epoch: 123, LR: 0.000343, Loss: 0.0743102, Validation MAE: 0.7602738, Test MAE: 0.8546933\n",
            "Epoch: 124, LR: 0.000240, Loss: 0.0709305, Validation MAE: 0.7740108, Test MAE: 0.8546933\n",
            "Epoch: 125, LR: 0.000240, Loss: 0.0703465, Validation MAE: 0.7186618, Test MAE: 0.8212814\n",
            "Epoch: 126, LR: 0.000240, Loss: 0.0695961, Validation MAE: 0.7537570, Test MAE: 0.8212814\n",
            "Epoch: 127, LR: 0.000240, Loss: 0.0687308, Validation MAE: 0.6978370, Test MAE: 0.7882823\n",
            "Epoch: 128, LR: 0.000240, Loss: 0.0690664, Validation MAE: 0.7632758, Test MAE: 0.7882823\n",
            "Epoch: 129, LR: 0.000240, Loss: 0.0697510, Validation MAE: 0.7130024, Test MAE: 0.7882823\n",
            "Epoch: 130, LR: 0.000240, Loss: 0.0679033, Validation MAE: 0.7815574, Test MAE: 0.7882823\n",
            "Epoch: 131, LR: 0.000240, Loss: 0.0674351, Validation MAE: 0.7294272, Test MAE: 0.7882823\n",
            "Epoch: 132, LR: 0.000240, Loss: 0.0678359, Validation MAE: 0.7270937, Test MAE: 0.7882823\n",
            "Epoch: 133, LR: 0.000240, Loss: 0.0681699, Validation MAE: 0.7524390, Test MAE: 0.7882823\n",
            "Epoch: 134, LR: 0.000168, Loss: 0.0661840, Validation MAE: 0.7361769, Test MAE: 0.7882823\n",
            "Epoch: 135, LR: 0.000168, Loss: 0.0648053, Validation MAE: 0.6900642, Test MAE: 0.7673510\n",
            "Epoch: 136, LR: 0.000168, Loss: 0.0654495, Validation MAE: 0.7451233, Test MAE: 0.7673510\n",
            "Epoch: 137, LR: 0.000168, Loss: 0.0647000, Validation MAE: 0.6829568, Test MAE: 0.7753160\n",
            "Epoch: 138, LR: 0.000168, Loss: 0.0636782, Validation MAE: 0.6874629, Test MAE: 0.7753160\n",
            "Epoch: 139, LR: 0.000168, Loss: 0.0645209, Validation MAE: 0.6978674, Test MAE: 0.7753160\n",
            "Epoch: 140, LR: 0.000168, Loss: 0.0641481, Validation MAE: 0.6745031, Test MAE: 0.7668538\n",
            "Epoch: 141, LR: 0.000168, Loss: 0.0632721, Validation MAE: 0.7677138, Test MAE: 0.7668538\n",
            "Epoch: 142, LR: 0.000168, Loss: 0.0630621, Validation MAE: 0.7159679, Test MAE: 0.7668538\n",
            "Epoch: 143, LR: 0.000168, Loss: 0.0639388, Validation MAE: 0.7006086, Test MAE: 0.7668538\n",
            "Epoch: 144, LR: 0.000168, Loss: 0.0637952, Validation MAE: 0.6881616, Test MAE: 0.7668538\n",
            "Epoch: 145, LR: 0.000168, Loss: 0.0631687, Validation MAE: 0.6497562, Test MAE: 0.7454924\n",
            "Epoch: 146, LR: 0.000168, Loss: 0.0618290, Validation MAE: 0.6751883, Test MAE: 0.7454924\n",
            "Epoch: 147, LR: 0.000168, Loss: 0.0620725, Validation MAE: 0.7629627, Test MAE: 0.7454924\n",
            "Epoch: 148, LR: 0.000168, Loss: 0.0625268, Validation MAE: 0.7073453, Test MAE: 0.7454924\n",
            "Epoch: 149, LR: 0.000168, Loss: 0.0624354, Validation MAE: 0.6922832, Test MAE: 0.7454924\n",
            "Epoch: 150, LR: 0.000168, Loss: 0.0612048, Validation MAE: 0.7821209, Test MAE: 0.7454924\n",
            "Epoch: 151, LR: 0.000168, Loss: 0.0626106, Validation MAE: 0.7242172, Test MAE: 0.7454924\n",
            "Epoch: 152, LR: 0.000118, Loss: 0.0596933, Validation MAE: 0.6450233, Test MAE: 0.7321134\n",
            "Epoch: 153, LR: 0.000118, Loss: 0.0592151, Validation MAE: 0.6600341, Test MAE: 0.7321134\n",
            "Epoch: 154, LR: 0.000118, Loss: 0.0597519, Validation MAE: 0.6502012, Test MAE: 0.7321134\n",
            "Epoch: 155, LR: 0.000118, Loss: 0.0590272, Validation MAE: 0.7138910, Test MAE: 0.7321134\n",
            "Epoch: 156, LR: 0.000118, Loss: 0.0587137, Validation MAE: 0.6221635, Test MAE: 0.6931411\n",
            "Epoch: 157, LR: 0.000118, Loss: 0.0586249, Validation MAE: 0.6624262, Test MAE: 0.6931411\n",
            "Epoch: 158, LR: 0.000118, Loss: 0.0584592, Validation MAE: 0.6549830, Test MAE: 0.6931411\n",
            "Epoch: 159, LR: 0.000118, Loss: 0.0580915, Validation MAE: 0.6440112, Test MAE: 0.6931411\n",
            "Epoch: 160, LR: 0.000118, Loss: 0.0584964, Validation MAE: 0.6991410, Test MAE: 0.6931411\n",
            "Epoch: 161, LR: 0.000118, Loss: 0.0588558, Validation MAE: 0.6537365, Test MAE: 0.6931411\n",
            "Epoch: 162, LR: 0.000118, Loss: 0.0582366, Validation MAE: 0.6901720, Test MAE: 0.6931411\n",
            "Epoch: 163, LR: 0.000082, Loss: 0.0572372, Validation MAE: 0.6392437, Test MAE: 0.6931411\n",
            "Epoch: 164, LR: 0.000082, Loss: 0.0566699, Validation MAE: 0.6389686, Test MAE: 0.6931411\n",
            "Epoch: 165, LR: 0.000082, Loss: 0.0570363, Validation MAE: 0.6336343, Test MAE: 0.6931411\n",
            "Epoch: 166, LR: 0.000082, Loss: 0.0564763, Validation MAE: 0.6201063, Test MAE: 0.7001434\n",
            "Epoch: 167, LR: 0.000082, Loss: 0.0558835, Validation MAE: 0.6499612, Test MAE: 0.7001434\n",
            "Epoch: 168, LR: 0.000082, Loss: 0.0569501, Validation MAE: 0.6419168, Test MAE: 0.7001434\n",
            "Epoch: 169, LR: 0.000082, Loss: 0.0560599, Validation MAE: 0.6671914, Test MAE: 0.7001434\n",
            "Epoch: 170, LR: 0.000082, Loss: 0.0562693, Validation MAE: 0.6124397, Test MAE: 0.7107300\n",
            "Epoch: 171, LR: 0.000082, Loss: 0.0559473, Validation MAE: 0.6056522, Test MAE: 0.7024757\n",
            "Epoch: 172, LR: 0.000082, Loss: 0.0557010, Validation MAE: 0.6462777, Test MAE: 0.7024757\n",
            "Epoch: 173, LR: 0.000082, Loss: 0.0558564, Validation MAE: 0.6415542, Test MAE: 0.7024757\n",
            "Epoch: 174, LR: 0.000082, Loss: 0.0556136, Validation MAE: 0.6137860, Test MAE: 0.7024757\n",
            "Epoch: 175, LR: 0.000082, Loss: 0.0551036, Validation MAE: 0.6183542, Test MAE: 0.7024757\n",
            "Epoch: 176, LR: 0.000082, Loss: 0.0554238, Validation MAE: 0.6423370, Test MAE: 0.7024757\n",
            "Epoch: 177, LR: 0.000082, Loss: 0.0549618, Validation MAE: 0.6100013, Test MAE: 0.7024757\n",
            "Epoch: 178, LR: 0.000058, Loss: 0.0543803, Validation MAE: 0.6236165, Test MAE: 0.7024757\n",
            "Epoch: 179, LR: 0.000058, Loss: 0.0546559, Validation MAE: 0.6002421, Test MAE: 0.6830195\n",
            "Epoch: 180, LR: 0.000058, Loss: 0.0540884, Validation MAE: 0.6222164, Test MAE: 0.6830195\n",
            "Epoch: 181, LR: 0.000058, Loss: 0.0539440, Validation MAE: 0.6052712, Test MAE: 0.6830195\n",
            "Epoch: 182, LR: 0.000058, Loss: 0.0537651, Validation MAE: 0.6374875, Test MAE: 0.6830195\n",
            "Epoch: 183, LR: 0.000058, Loss: 0.0542372, Validation MAE: 0.6135048, Test MAE: 0.6830195\n",
            "Epoch: 184, LR: 0.000058, Loss: 0.0540453, Validation MAE: 0.6510038, Test MAE: 0.6830195\n",
            "Epoch: 185, LR: 0.000058, Loss: 0.0543335, Validation MAE: 0.6077638, Test MAE: 0.6830195\n",
            "Epoch: 186, LR: 0.000040, Loss: 0.0531212, Validation MAE: 0.5932262, Test MAE: 0.6699420\n",
            "Epoch: 187, LR: 0.000040, Loss: 0.0529910, Validation MAE: 0.5900943, Test MAE: 0.6670917\n",
            "Epoch: 188, LR: 0.000040, Loss: 0.0532887, Validation MAE: 0.6238290, Test MAE: 0.6670917\n",
            "Epoch: 189, LR: 0.000040, Loss: 0.0534297, Validation MAE: 0.6108380, Test MAE: 0.6670917\n",
            "Epoch: 190, LR: 0.000040, Loss: 0.0530700, Validation MAE: 0.6032738, Test MAE: 0.6670917\n",
            "Epoch: 191, LR: 0.000040, Loss: 0.0528122, Validation MAE: 0.6116033, Test MAE: 0.6670917\n",
            "Epoch: 192, LR: 0.000040, Loss: 0.0528798, Validation MAE: 0.5891240, Test MAE: 0.6674776\n",
            "Epoch: 193, LR: 0.000040, Loss: 0.0531172, Validation MAE: 0.5986189, Test MAE: 0.6674776\n",
            "Epoch: 194, LR: 0.000040, Loss: 0.0527557, Validation MAE: 0.6000486, Test MAE: 0.6674776\n",
            "Epoch: 195, LR: 0.000040, Loss: 0.0524081, Validation MAE: 0.5944135, Test MAE: 0.6674776\n",
            "Epoch: 196, LR: 0.000040, Loss: 0.0527154, Validation MAE: 0.5887150, Test MAE: 0.6696008\n",
            "Epoch: 197, LR: 0.000040, Loss: 0.0524047, Validation MAE: 0.5972046, Test MAE: 0.6696008\n",
            "Epoch: 198, LR: 0.000040, Loss: 0.0523886, Validation MAE: 0.5922919, Test MAE: 0.6696008\n",
            "Epoch: 199, LR: 0.000040, Loss: 0.0525049, Validation MAE: 0.6009475, Test MAE: 0.6696008\n",
            "Epoch: 200, LR: 0.000040, Loss: 0.0523482, Validation MAE: 0.6173480, Test MAE: 0.6696008\n",
            "Epoch: 201, LR: 0.000040, Loss: 0.0525356, Validation MAE: 0.6038381, Test MAE: 0.6696008\n",
            "Epoch: 202, LR: 0.000040, Loss: 0.0524326, Validation MAE: 0.6256877, Test MAE: 0.6696008\n",
            "Epoch: 203, LR: 0.000028, Loss: 0.0517999, Validation MAE: 0.5807787, Test MAE: 0.6555949\n",
            "Epoch: 204, LR: 0.000028, Loss: 0.0517942, Validation MAE: 0.5753755, Test MAE: 0.6630626\n",
            "Epoch: 205, LR: 0.000028, Loss: 0.0517224, Validation MAE: 0.5737193, Test MAE: 0.6541624\n",
            "Epoch: 206, LR: 0.000028, Loss: 0.0516546, Validation MAE: 0.6052362, Test MAE: 0.6541624\n",
            "Epoch: 207, LR: 0.000028, Loss: 0.0519175, Validation MAE: 0.5750260, Test MAE: 0.6541624\n",
            "Epoch: 208, LR: 0.000028, Loss: 0.0515832, Validation MAE: 0.5873550, Test MAE: 0.6541624\n",
            "Epoch: 209, LR: 0.000028, Loss: 0.0514427, Validation MAE: 0.5743515, Test MAE: 0.6541624\n",
            "Epoch: 210, LR: 0.000028, Loss: 0.0513728, Validation MAE: 0.5817825, Test MAE: 0.6541624\n",
            "Epoch: 211, LR: 0.000028, Loss: 0.0514461, Validation MAE: 0.5853817, Test MAE: 0.6541624\n",
            "Epoch: 212, LR: 0.000020, Loss: 0.0511751, Validation MAE: 0.5790585, Test MAE: 0.6541624\n",
            "Epoch: 213, LR: 0.000020, Loss: 0.0510488, Validation MAE: 0.5806033, Test MAE: 0.6541624\n",
            "Epoch: 214, LR: 0.000020, Loss: 0.0509892, Validation MAE: 0.5780266, Test MAE: 0.6541624\n",
            "Epoch: 215, LR: 0.000020, Loss: 0.0509501, Validation MAE: 0.5807024, Test MAE: 0.6541624\n",
            "Epoch: 216, LR: 0.000020, Loss: 0.0510557, Validation MAE: 0.5827753, Test MAE: 0.6541624\n",
            "Epoch: 217, LR: 0.000020, Loss: 0.0510072, Validation MAE: 0.5769079, Test MAE: 0.6541624\n",
            "Epoch: 218, LR: 0.000014, Loss: 0.0507653, Validation MAE: 0.5761682, Test MAE: 0.6541624\n",
            "Epoch: 219, LR: 0.000014, Loss: 0.0508179, Validation MAE: 0.5805973, Test MAE: 0.6541624\n",
            "Epoch: 220, LR: 0.000014, Loss: 0.0507478, Validation MAE: 0.5768810, Test MAE: 0.6541624\n",
            "Epoch: 221, LR: 0.000014, Loss: 0.0507223, Validation MAE: 0.5775815, Test MAE: 0.6541624\n",
            "Epoch: 222, LR: 0.000014, Loss: 0.0506489, Validation MAE: 0.5720799, Test MAE: 0.6475705\n",
            "Epoch: 223, LR: 0.000014, Loss: 0.0506579, Validation MAE: 0.5708872, Test MAE: 0.6495451\n",
            "Epoch: 224, LR: 0.000014, Loss: 0.0506124, Validation MAE: 0.5741992, Test MAE: 0.6495451\n",
            "Epoch: 225, LR: 0.000014, Loss: 0.0505256, Validation MAE: 0.5748499, Test MAE: 0.6495451\n",
            "Epoch: 226, LR: 0.000014, Loss: 0.0505384, Validation MAE: 0.5687473, Test MAE: 0.6459420\n",
            "Epoch: 227, LR: 0.000014, Loss: 0.0504459, Validation MAE: 0.5710967, Test MAE: 0.6459420\n",
            "Epoch: 228, LR: 0.000014, Loss: 0.0505291, Validation MAE: 0.5702338, Test MAE: 0.6459420\n",
            "Epoch: 229, LR: 0.000014, Loss: 0.0504302, Validation MAE: 0.5707431, Test MAE: 0.6459420\n",
            "Epoch: 230, LR: 0.000014, Loss: 0.0505863, Validation MAE: 0.5834773, Test MAE: 0.6459420\n",
            "Epoch: 231, LR: 0.000014, Loss: 0.0505371, Validation MAE: 0.5740192, Test MAE: 0.6459420\n",
            "Epoch: 232, LR: 0.000014, Loss: 0.0505770, Validation MAE: 0.5729763, Test MAE: 0.6459420\n",
            "Epoch: 233, LR: 0.000010, Loss: 0.0502933, Validation MAE: 0.5680533, Test MAE: 0.6445968\n",
            "Epoch: 234, LR: 0.000010, Loss: 0.0503184, Validation MAE: 0.5682181, Test MAE: 0.6445968\n",
            "Epoch: 235, LR: 0.000010, Loss: 0.0503423, Validation MAE: 0.5731183, Test MAE: 0.6445968\n",
            "Epoch: 236, LR: 0.000010, Loss: 0.0503117, Validation MAE: 0.5696344, Test MAE: 0.6445968\n",
            "Epoch: 237, LR: 0.000010, Loss: 0.0502617, Validation MAE: 0.5685870, Test MAE: 0.6445968\n",
            "Epoch: 238, LR: 0.000010, Loss: 0.0502200, Validation MAE: 0.5672697, Test MAE: 0.6456205\n",
            "Epoch: 239, LR: 0.000010, Loss: 0.0503553, Validation MAE: 0.5716712, Test MAE: 0.6456205\n",
            "Epoch: 240, LR: 0.000010, Loss: 0.0501340, Validation MAE: 0.5668858, Test MAE: 0.6509317\n",
            "Epoch: 241, LR: 0.000010, Loss: 0.0502283, Validation MAE: 0.5793495, Test MAE: 0.6509317\n",
            "Epoch: 242, LR: 0.000010, Loss: 0.0502729, Validation MAE: 0.5692220, Test MAE: 0.6509317\n",
            "Epoch: 243, LR: 0.000010, Loss: 0.0501968, Validation MAE: 0.5644858, Test MAE: 0.6460916\n",
            "Epoch: 244, LR: 0.000010, Loss: 0.0500384, Validation MAE: 0.5782986, Test MAE: 0.6460916\n",
            "Epoch: 245, LR: 0.000010, Loss: 0.0501159, Validation MAE: 0.5709425, Test MAE: 0.6460916\n",
            "Epoch: 246, LR: 0.000010, Loss: 0.0501186, Validation MAE: 0.5708922, Test MAE: 0.6460916\n",
            "Epoch: 247, LR: 0.000010, Loss: 0.0500361, Validation MAE: 0.5672737, Test MAE: 0.6460916\n",
            "Epoch: 248, LR: 0.000010, Loss: 0.0501683, Validation MAE: 0.5679948, Test MAE: 0.6460916\n",
            "Epoch: 249, LR: 0.000010, Loss: 0.0500583, Validation MAE: 0.5688521, Test MAE: 0.6460916\n",
            "Epoch: 250, LR: 0.000010, Loss: 0.0500784, Validation MAE: 0.5670686, Test MAE: 0.6460916\n",
            "Epoch: 251, LR: 0.000010, Loss: 0.0499708, Validation MAE: 0.5681892, Test MAE: 0.6460916\n",
            "Epoch: 252, LR: 0.000010, Loss: 0.0500057, Validation MAE: 0.5654969, Test MAE: 0.6460916\n",
            "Epoch: 253, LR: 0.000010, Loss: 0.0500010, Validation MAE: 0.5660399, Test MAE: 0.6460916\n",
            "Epoch: 254, LR: 0.000010, Loss: 0.0499827, Validation MAE: 0.5714566, Test MAE: 0.6460916\n",
            "Epoch: 255, LR: 0.000010, Loss: 0.0499468, Validation MAE: 0.5727996, Test MAE: 0.6460916\n",
            "Epoch: 256, LR: 0.000010, Loss: 0.0500518, Validation MAE: 0.5656435, Test MAE: 0.6460916\n",
            "Epoch: 257, LR: 0.000010, Loss: 0.0499183, Validation MAE: 0.5696436, Test MAE: 0.6460916\n",
            "Epoch: 258, LR: 0.000010, Loss: 0.0499487, Validation MAE: 0.5695838, Test MAE: 0.6460916\n",
            "Epoch: 259, LR: 0.000010, Loss: 0.0498559, Validation MAE: 0.5699792, Test MAE: 0.6460916\n",
            "Epoch: 260, LR: 0.000010, Loss: 0.0498154, Validation MAE: 0.5642237, Test MAE: 0.6441264\n",
            "Epoch: 261, LR: 0.000010, Loss: 0.0499179, Validation MAE: 0.5669007, Test MAE: 0.6441264\n",
            "Epoch: 262, LR: 0.000010, Loss: 0.0498524, Validation MAE: 0.5786983, Test MAE: 0.6441264\n",
            "Epoch: 263, LR: 0.000010, Loss: 0.0498719, Validation MAE: 0.5796909, Test MAE: 0.6441264\n",
            "Epoch: 264, LR: 0.000010, Loss: 0.0498856, Validation MAE: 0.5790719, Test MAE: 0.6441264\n",
            "Epoch: 265, LR: 0.000010, Loss: 0.0497698, Validation MAE: 0.5676785, Test MAE: 0.6441264\n",
            "Epoch: 266, LR: 0.000010, Loss: 0.0497956, Validation MAE: 0.5730858, Test MAE: 0.6441264\n",
            "Epoch: 267, LR: 0.000010, Loss: 0.0498246, Validation MAE: 0.5681798, Test MAE: 0.6441264\n",
            "Epoch: 268, LR: 0.000010, Loss: 0.0497650, Validation MAE: 0.5667482, Test MAE: 0.6441264\n",
            "Epoch: 269, LR: 0.000010, Loss: 0.0497259, Validation MAE: 0.5711991, Test MAE: 0.6441264\n",
            "Epoch: 270, LR: 0.000010, Loss: 0.0496744, Validation MAE: 0.5634959, Test MAE: 0.6443005\n",
            "Epoch: 271, LR: 0.000010, Loss: 0.0497899, Validation MAE: 0.5725107, Test MAE: 0.6443005\n",
            "Epoch: 272, LR: 0.000010, Loss: 0.0497152, Validation MAE: 0.5742089, Test MAE: 0.6443005\n",
            "Epoch: 273, LR: 0.000010, Loss: 0.0496010, Validation MAE: 0.5711582, Test MAE: 0.6443005\n",
            "Epoch: 274, LR: 0.000010, Loss: 0.0496409, Validation MAE: 0.5713240, Test MAE: 0.6443005\n",
            "Epoch: 275, LR: 0.000010, Loss: 0.0495855, Validation MAE: 0.5670515, Test MAE: 0.6443005\n",
            "Epoch: 276, LR: 0.000010, Loss: 0.0495672, Validation MAE: 0.5665381, Test MAE: 0.6443005\n",
            "Epoch: 277, LR: 0.000010, Loss: 0.0494853, Validation MAE: 0.5630492, Test MAE: 0.6412630\n",
            "Epoch: 278, LR: 0.000010, Loss: 0.0497561, Validation MAE: 0.5658593, Test MAE: 0.6412630\n",
            "Epoch: 279, LR: 0.000010, Loss: 0.0496124, Validation MAE: 0.5683793, Test MAE: 0.6412630\n",
            "Epoch: 280, LR: 0.000010, Loss: 0.0494840, Validation MAE: 0.5741180, Test MAE: 0.6412630\n",
            "Epoch: 281, LR: 0.000010, Loss: 0.0495650, Validation MAE: 0.5636468, Test MAE: 0.6412630\n",
            "Epoch: 282, LR: 0.000010, Loss: 0.0495660, Validation MAE: 0.5751035, Test MAE: 0.6412630\n",
            "Epoch: 283, LR: 0.000010, Loss: 0.0495189, Validation MAE: 0.5703099, Test MAE: 0.6412630\n",
            "Epoch: 284, LR: 0.000010, Loss: 0.0495266, Validation MAE: 0.5653558, Test MAE: 0.6412630\n",
            "Epoch: 285, LR: 0.000010, Loss: 0.0494987, Validation MAE: 0.5691752, Test MAE: 0.6412630\n",
            "Epoch: 286, LR: 0.000010, Loss: 0.0494872, Validation MAE: 0.5616614, Test MAE: 0.6428365\n",
            "Epoch: 287, LR: 0.000010, Loss: 0.0494994, Validation MAE: 0.5681835, Test MAE: 0.6428365\n",
            "Epoch: 288, LR: 0.000010, Loss: 0.0494264, Validation MAE: 0.5670854, Test MAE: 0.6428365\n",
            "Epoch: 289, LR: 0.000010, Loss: 0.0494212, Validation MAE: 0.5681522, Test MAE: 0.6428365\n",
            "Epoch: 290, LR: 0.000010, Loss: 0.0494040, Validation MAE: 0.5722580, Test MAE: 0.6428365\n",
            "Epoch: 291, LR: 0.000010, Loss: 0.0493790, Validation MAE: 0.5647536, Test MAE: 0.6428365\n",
            "Epoch: 292, LR: 0.000010, Loss: 0.0493244, Validation MAE: 0.5763941, Test MAE: 0.6428365\n",
            "Epoch: 293, LR: 0.000010, Loss: 0.0493925, Validation MAE: 0.5681084, Test MAE: 0.6428365\n",
            "Epoch: 294, LR: 0.000010, Loss: 0.0493646, Validation MAE: 0.5677882, Test MAE: 0.6428365\n",
            "Epoch: 295, LR: 0.000010, Loss: 0.0493768, Validation MAE: 0.5608594, Test MAE: 0.6388881\n",
            "Epoch: 296, LR: 0.000010, Loss: 0.0493988, Validation MAE: 0.5644989, Test MAE: 0.6388881\n",
            "Epoch: 297, LR: 0.000010, Loss: 0.0494214, Validation MAE: 0.5629813, Test MAE: 0.6388881\n",
            "Epoch: 298, LR: 0.000010, Loss: 0.0493046, Validation MAE: 0.5672129, Test MAE: 0.6388881\n",
            "Epoch: 299, LR: 0.000010, Loss: 0.0492397, Validation MAE: 0.5626149, Test MAE: 0.6388881\n",
            "Epoch: 300, LR: 0.000010, Loss: 0.0491998, Validation MAE: 0.5645338, Test MAE: 0.6388881\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}