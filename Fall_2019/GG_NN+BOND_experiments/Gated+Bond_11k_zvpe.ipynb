{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Gated+set2set_bond 11k-zvpe.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BBM1XoLJyai",
        "colab_type": "code",
        "outputId": "5f5e4dc2-81bc-4f51-daec-d2697d419b71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!apt install gcc-5 g++-5 -y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-430\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  cpp-5 gcc-5-base libasan2 libgcc-5-dev libisl15 libmpx0 libstdc++-5-dev\n",
            "Suggested packages:\n",
            "  gcc-5-locales g++-5-multilib gcc-5-doc libstdc++6-5-dbg gcc-5-multilib\n",
            "  libgcc1-dbg libgomp1-dbg libitm1-dbg libatomic1-dbg libasan2-dbg\n",
            "  liblsan0-dbg libtsan0-dbg libubsan0-dbg libcilkrts5-dbg libmpx0-dbg\n",
            "  libquadmath0-dbg libstdc++-5-doc\n",
            "The following NEW packages will be installed:\n",
            "  cpp-5 g++-5 gcc-5 gcc-5-base libasan2 libgcc-5-dev libisl15 libmpx0\n",
            "  libstdc++-5-dev\n",
            "0 upgraded, 9 newly installed, 0 to remove and 7 not upgraded.\n",
            "Need to get 29.1 MB of archives.\n",
            "After this operation, 100 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 gcc-5-base amd64 5.5.0-12ubuntu1 [17.1 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libisl15 amd64 0.18-4 [548 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 cpp-5 amd64 5.5.0-12ubuntu1 [7,785 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libasan2 amd64 5.5.0-12ubuntu1 [264 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmpx0 amd64 5.5.0-12ubuntu1 [9,888 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgcc-5-dev amd64 5.5.0-12ubuntu1 [2,224 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 gcc-5 amd64 5.5.0-12ubuntu1 [8,357 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libstdc++-5-dev amd64 5.5.0-12ubuntu1 [1,415 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/universe amd64 g++-5 amd64 5.5.0-12ubuntu1 [8,450 kB]\n",
            "Fetched 29.1 MB in 3s (10.8 MB/s)\n",
            "Selecting previously unselected package gcc-5-base:amd64.\n",
            "(Reading database ... 145655 files and directories currently installed.)\n",
            "Preparing to unpack .../0-gcc-5-base_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking gcc-5-base:amd64 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package libisl15:amd64.\n",
            "Preparing to unpack .../1-libisl15_0.18-4_amd64.deb ...\n",
            "Unpacking libisl15:amd64 (0.18-4) ...\n",
            "Selecting previously unselected package cpp-5.\n",
            "Preparing to unpack .../2-cpp-5_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking cpp-5 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package libasan2:amd64.\n",
            "Preparing to unpack .../3-libasan2_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking libasan2:amd64 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package libmpx0:amd64.\n",
            "Preparing to unpack .../4-libmpx0_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking libmpx0:amd64 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package libgcc-5-dev:amd64.\n",
            "Preparing to unpack .../5-libgcc-5-dev_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking libgcc-5-dev:amd64 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package gcc-5.\n",
            "Preparing to unpack .../6-gcc-5_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking gcc-5 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package libstdc++-5-dev:amd64.\n",
            "Preparing to unpack .../7-libstdc++-5-dev_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking libstdc++-5-dev:amd64 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package g++-5.\n",
            "Preparing to unpack .../8-g++-5_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking g++-5 (5.5.0-12ubuntu1) ...\n",
            "Setting up libisl15:amd64 (0.18-4) ...\n",
            "Setting up gcc-5-base:amd64 (5.5.0-12ubuntu1) ...\n",
            "Setting up libmpx0:amd64 (5.5.0-12ubuntu1) ...\n",
            "Setting up libasan2:amd64 (5.5.0-12ubuntu1) ...\n",
            "Setting up libgcc-5-dev:amd64 (5.5.0-12ubuntu1) ...\n",
            "Setting up cpp-5 (5.5.0-12ubuntu1) ...\n",
            "Setting up libstdc++-5-dev:amd64 (5.5.0-12ubuntu1) ...\n",
            "Setting up gcc-5 (5.5.0-12ubuntu1) ...\n",
            "Setting up g++-5 (5.5.0-12ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXSkQprZJ-5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ln -sf /usr/bin/gcc-5 /usr/bin/gcc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65EGZX5BKCoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " !ln -sf /usr/bin/g++-5 /usr/bin/g++"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qi_9A-KpJ51q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!export CPATH=/usr/local/cuda/include:$CPATH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBK8e-n5KJmq",
        "colab_type": "code",
        "outputId": "33cd035c-d9e7-46fa-8ca8-6ce3158080d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!pip install torch-scatter"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch-scatter\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/c3/8bad887ffa55c86f120ef5ae252dc0e357b3bd956d9fbf45242bacc46290/torch_scatter-1.4.0.tar.gz\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-1.4.0-cp36-cp36m-linux_x86_64.whl size=3172395 sha256=c402d677833ec7cf8747c799a9044e3d80389dd9c9e487b88290190861d14f40\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/00/c4/1637b4b3003f29092f4fe2ad4b40dd10906269c1ac2dc82941\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isHNOWwUK-wQ",
        "colab_type": "code",
        "outputId": "6fb04d8d-4cec-48f2-df18-734e92682a7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!pip install torch-sparse"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch-sparse\n",
            "  Downloading https://files.pythonhosted.org/packages/08/4e/a268613fa6a92ffbc65b89e66fc8be5590801937185007f0f7bcb75ea21f/torch_sparse-0.4.3.tar.gz\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-sparse) (1.3.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-sparse) (1.17.4)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.4.3-cp36-cp36m-linux_x86_64.whl size=3981650 sha256=9d12c9029f88e20f1e618ffd9df59287c7dd74b6c9d378e6b5acb855be55c63b\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/66/2b/befece01c2516f9fb3e7b4d150bb2b871221c73657c9cd7735\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47-LLTlmOfVI",
        "colab_type": "code",
        "outputId": "f9213c57-0074-48d2-801f-28976c50101c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "!pip install torch-cluster"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch-cluster\n",
            "  Downloading https://files.pythonhosted.org/packages/c3/70/1d827d6fd1e03bb5ae84852dd0070c6574105c37e7b935284f6e990932db/torch_cluster-1.4.5.tar.gz\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-cluster) (1.3.3)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-cluster) (1.17.4)\n",
            "Building wheels for collected packages: torch-cluster\n",
            "  Building wheel for torch-cluster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-cluster: filename=torch_cluster-1.4.5-cp36-cp36m-linux_x86_64.whl size=16287332 sha256=75f29367c78abf5fa6a8c8b7b2a2ea939bb5b594888101c9b6215d7f0b8918a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/26/7e/a6d6a80eae5ca39b92bc77773f36cf433d5085de18014382b1\n",
            "Successfully built torch-cluster\n",
            "Installing collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0cigFl2OuTT",
        "colab_type": "code",
        "outputId": "3efe63d2-99a2-4e2c-f713-e281bf0e8faf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "!pip install torch-spline-conv "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch-spline-conv\n",
            "  Downloading https://files.pythonhosted.org/packages/5e/77/5420584cdb1514c580722ca4bc482a509105d64b7c70246e9dc4a3e6d3c5/torch_spline_conv-1.1.1.tar.gz\n",
            "Building wheels for collected packages: torch-spline-conv\n",
            "  Building wheel for torch-spline-conv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-spline-conv: filename=torch_spline_conv-1.1.1-cp36-cp36m-linux_x86_64.whl size=5481620 sha256=f1e4da025a7b276e9060040a99e9f7ade6e1ecbb59d8794fd4ab28787109c6f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/cf/c7/3439a98ba262c5d99b91a9c11aaeced67f583febab5a4b1566\n",
            "Successfully built torch-spline-conv\n",
            "Installing collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QhmUyy3OxSA",
        "colab_type": "code",
        "outputId": "a84ca4b6-e098-441e-8377-18f0b2bb200f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        }
      },
      "source": [
        "!pip install torch-geometric"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch-geometric\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/50/0a802f0bfa68058bf025d219ec6fbe806a5b891bba6702e28be7b83679fb/torch_geometric-1.3.2.tar.gz (126kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 27.0MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 30kB 4.3MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 40kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 61kB 4.2MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 71kB 4.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 81kB 5.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 92kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 102kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 112kB 4.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 122kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.17.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.3.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.21.0)\n",
            "Collecting plyfile\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/15/434d1d96f9a41fea56cb3290718123d651c56c4b7e53f0249acaf1bf34b6/plyfile-0.7.1.tar.gz\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.25.3)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/fe/630bacb652680f6d481b9febbb3e2c3869194a1a5fc3401a4a41195a2f8f/rdflib-4.2.2-py3-none-any.whl (344kB)\n",
            "\u001b[K     |████████████████████████████████| 348kB 63.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.8.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch-geometric) (4.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch-geometric) (0.14.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (2.4.5)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->torch-geometric) (1.12.0)\n",
            "Building wheels for collected packages: torch-geometric, plyfile\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.3.2-cp36-none-any.whl size=203339 sha256=8b8abaa0e736311cb2295e5ae92b2b94eec93de57d068fcebc8ffc85ea057f19\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/75/0a/56a0fd58efac6d990782523e20e61c9307fc42c31564d40348\n",
            "  Building wheel for plyfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for plyfile: filename=plyfile-0.7.1-cp36-none-any.whl size=32827 sha256=0325fb221b6d27f81da0334599a5f5ead692b588400fafd4c92075f2d79f0f42\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/0d/bf/6d603d81b98604d2ecfd5e99d4ab7c9af664fd5285ab82bbb0\n",
            "Successfully built torch-geometric plyfile\n",
            "Installing collected packages: plyfile, isodate, rdflib, torch-geometric\n",
            "Successfully installed isodate-0.6.0 plyfile-0.7.1 rdflib-4.2.2 torch-geometric-1.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1D-3usfvRC8X",
        "colab_type": "code",
        "outputId": "23242586-10f2-4c0b-8485-8d3a6509bed0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Installing dependencies for RDKit\n",
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!time bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!time conda install -q -y -c conda-forge rdkit"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-18 23:48:30--  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.200.79, 104.18.201.79, 2606:4700::6812:c84f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.200.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 71785000 (68M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’\n",
            "\n",
            "\r          Miniconda   0%[                    ]       0  --.-KB/s               \r         Miniconda3  74%[=============>      ]  50.76M   254MB/s               \rMiniconda3-latest-L 100%[===================>]  68.46M   278MB/s    in 0.2s    \n",
            "\n",
            "2019-12-18 23:48:31 (278 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [71785000/71785000]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - asn1crypto==1.2.0=py37_0\n",
            "    - ca-certificates==2019.10.16=0\n",
            "    - certifi==2019.9.11=py37_0\n",
            "    - cffi==1.13.0=py37h2e261b9_0\n",
            "    - chardet==3.0.4=py37_1003\n",
            "    - conda-package-handling==1.6.0=py37h7b6447c_0\n",
            "    - conda==4.7.12=py37_0\n",
            "    - cryptography==2.8=py37h1ba5d50_0\n",
            "    - idna==2.8=py37_0\n",
            "    - libedit==3.1.20181209=hc058e9b_0\n",
            "    - libffi==3.2.1=hd88cf55_4\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - ncurses==6.1=he6710b0_1\n",
            "    - openssl==1.1.1d=h7b6447c_3\n",
            "    - pip==19.3.1=py37_0\n",
            "    - pycosat==0.6.3=py37h14c3975_0\n",
            "    - pycparser==2.19=py37_0\n",
            "    - pyopenssl==19.0.0=py37_0\n",
            "    - pysocks==1.7.1=py37_0\n",
            "    - python==3.7.4=h265db76_1\n",
            "    - readline==7.0=h7b6447c_5\n",
            "    - requests==2.22.0=py37_0\n",
            "    - ruamel_yaml==0.15.46=py37h14c3975_0\n",
            "    - setuptools==41.4.0=py37_0\n",
            "    - six==1.12.0=py37_0\n",
            "    - sqlite==3.30.0=h7b6447c_0\n",
            "    - tk==8.6.8=hbc83047_0\n",
            "    - tqdm==4.36.1=py_0\n",
            "    - urllib3==1.24.2=py37_0\n",
            "    - wheel==0.33.6=py37_0\n",
            "    - xz==5.2.4=h14c3975_4\n",
            "    - yaml==0.1.7=had09818_2\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  asn1crypto         pkgs/main/linux-64::asn1crypto-1.2.0-py37_0\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2019.10.16-0\n",
            "  certifi            pkgs/main/linux-64::certifi-2019.9.11-py37_0\n",
            "  cffi               pkgs/main/linux-64::cffi-1.13.0-py37h2e261b9_0\n",
            "  chardet            pkgs/main/linux-64::chardet-3.0.4-py37_1003\n",
            "  conda              pkgs/main/linux-64::conda-4.7.12-py37_0\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.6.0-py37h7b6447c_0\n",
            "  cryptography       pkgs/main/linux-64::cryptography-2.8-py37h1ba5d50_0\n",
            "  idna               pkgs/main/linux-64::idna-2.8-py37_0\n",
            "  libedit            pkgs/main/linux-64::libedit-3.1.20181209-hc058e9b_0\n",
            "  libffi             pkgs/main/linux-64::libffi-3.2.1-hd88cf55_4\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.1-he6710b0_1\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1d-h7b6447c_3\n",
            "  pip                pkgs/main/linux-64::pip-19.3.1-py37_0\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py37h14c3975_0\n",
            "  pycparser          pkgs/main/linux-64::pycparser-2.19-py37_0\n",
            "  pyopenssl          pkgs/main/linux-64::pyopenssl-19.0.0-py37_0\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py37_0\n",
            "  python             pkgs/main/linux-64::python-3.7.4-h265db76_1\n",
            "  readline           pkgs/main/linux-64::readline-7.0-h7b6447c_5\n",
            "  requests           pkgs/main/linux-64::requests-2.22.0-py37_0\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.46-py37h14c3975_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-41.4.0-py37_0\n",
            "  six                pkgs/main/linux-64::six-1.12.0-py37_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.30.0-h7b6447c_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.8-hbc83047_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.36.1-py_0\n",
            "  urllib3            pkgs/main/linux-64::urllib3-1.24.2-py37_0\n",
            "  wheel              pkgs/main/linux-64::wheel-0.33.6-py37_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.4-h14c3975_4\n",
            "  yaml               pkgs/main/linux-64::yaml-0.1.7-had09818_2\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n",
            "\n",
            "\n",
            "Preparing transaction: | \b\b/ \b\b- \b\bdone\n",
            "Executing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "\n",
            "real\t0m12.434s\n",
            "user\t0m7.118s\n",
            "sys\t0m2.655s\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    boost-1.70.0               |   py37h9de70de_1         337 KB  conda-forge\n",
            "    boost-cpp-1.70.0           |       h8e57a91_2        21.1 MB  conda-forge\n",
            "    bzip2-1.0.8                |       h516909a_2         396 KB  conda-forge\n",
            "    ca-certificates-2019.11.28 |       hecc5488_0         145 KB  conda-forge\n",
            "    cairo-1.16.0               |    hfb77d84_1002         1.5 MB  conda-forge\n",
            "    certifi-2019.11.28         |           py37_0         148 KB  conda-forge\n",
            "    conda-4.8.0                |           py37_1         3.0 MB  conda-forge\n",
            "    fontconfig-2.13.1          |    h86ecdb6_1001         340 KB  conda-forge\n",
            "    freetype-2.10.0            |       he983fc9_1         884 KB  conda-forge\n",
            "    gettext-0.19.8.1           |    hc5be6a0_1002         3.6 MB  conda-forge\n",
            "    glib-2.58.3                |py37h6f030ca_1002         3.3 MB  conda-forge\n",
            "    icu-64.2                   |       he1b5a44_1        12.6 MB  conda-forge\n",
            "    jpeg-9c                    |    h14c3975_1001         251 KB  conda-forge\n",
            "    libblas-3.8.0              |      14_openblas          10 KB  conda-forge\n",
            "    libcblas-3.8.0             |      14_openblas          10 KB  conda-forge\n",
            "    libgfortran-ng-7.3.0       |       hdf63c60_2         1.7 MB  conda-forge\n",
            "    libiconv-1.15              |    h516909a_1005         2.0 MB  conda-forge\n",
            "    liblapack-3.8.0            |      14_openblas          10 KB  conda-forge\n",
            "    libopenblas-0.3.7          |       h5ec1e0e_5         7.6 MB  conda-forge\n",
            "    libpng-1.6.37              |       hed695b0_0         343 KB  conda-forge\n",
            "    libtiff-4.1.0              |       hc3755c2_1         609 KB  conda-forge\n",
            "    libuuid-2.32.1             |    h14c3975_1000          26 KB  conda-forge\n",
            "    libxcb-1.13                |    h14c3975_1002         396 KB  conda-forge\n",
            "    libxml2-2.9.10             |       hee79883_0         1.3 MB  conda-forge\n",
            "    lz4-c-1.8.3                |    he1b5a44_1001         187 KB  conda-forge\n",
            "    numpy-1.17.3               |   py37h95a1406_0         5.1 MB  conda-forge\n",
            "    olefile-0.46               |             py_0          31 KB  conda-forge\n",
            "    openssl-1.1.1d             |       h516909a_0         2.1 MB  conda-forge\n",
            "    pandas-0.25.3              |   py37hb3f55d8_0        11.4 MB  conda-forge\n",
            "    pcre-8.43                  |       he1b5a44_0         257 KB  conda-forge\n",
            "    pillow-6.2.1               |   py37h34e0f95_0         643 KB\n",
            "    pixman-0.38.0              |    h516909a_1003         594 KB  conda-forge\n",
            "    pthread-stubs-0.4          |    h14c3975_1001           5 KB  conda-forge\n",
            "    pycairo-1.18.2             |   py37h438ddbb_0          77 KB  conda-forge\n",
            "    python-dateutil-2.8.1      |             py_0         220 KB  conda-forge\n",
            "    pytz-2019.3                |             py_0         237 KB  conda-forge\n",
            "    rdkit-2019.09.2            |   py37hb31dc5d_0        23.8 MB  conda-forge\n",
            "    xorg-kbproto-1.0.7         |    h14c3975_1002          26 KB  conda-forge\n",
            "    xorg-libice-1.0.10         |       h516909a_0          57 KB  conda-forge\n",
            "    xorg-libsm-1.2.3           |    h84519dc_1000          25 KB  conda-forge\n",
            "    xorg-libx11-1.6.9          |       h516909a_0         918 KB  conda-forge\n",
            "    xorg-libxau-1.0.9          |       h14c3975_0          13 KB  conda-forge\n",
            "    xorg-libxdmcp-1.1.3        |       h516909a_0          18 KB  conda-forge\n",
            "    xorg-libxext-1.3.4         |       h516909a_0          51 KB  conda-forge\n",
            "    xorg-libxrender-0.9.10     |    h516909a_1002          31 KB  conda-forge\n",
            "    xorg-renderproto-0.11.1    |    h14c3975_1002           8 KB  conda-forge\n",
            "    xorg-xextproto-7.3.0       |    h14c3975_1002          27 KB  conda-forge\n",
            "    xorg-xproto-7.0.31         |    h14c3975_1007          72 KB  conda-forge\n",
            "    zstd-1.4.4                 |       h3b9ef0a_1         989 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       108.4 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  boost              conda-forge/linux-64::boost-1.70.0-py37h9de70de_1\n",
            "  boost-cpp          conda-forge/linux-64::boost-cpp-1.70.0-h8e57a91_2\n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h516909a_2\n",
            "  cairo              conda-forge/linux-64::cairo-1.16.0-hfb77d84_1002\n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.13.1-h86ecdb6_1001\n",
            "  freetype           conda-forge/linux-64::freetype-2.10.0-he983fc9_1\n",
            "  gettext            conda-forge/linux-64::gettext-0.19.8.1-hc5be6a0_1002\n",
            "  glib               conda-forge/linux-64::glib-2.58.3-py37h6f030ca_1002\n",
            "  icu                conda-forge/linux-64::icu-64.2-he1b5a44_1\n",
            "  jpeg               conda-forge/linux-64::jpeg-9c-h14c3975_1001\n",
            "  libblas            conda-forge/linux-64::libblas-3.8.0-14_openblas\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.8.0-14_openblas\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-7.3.0-hdf63c60_2\n",
            "  libiconv           conda-forge/linux-64::libiconv-1.15-h516909a_1005\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.8.0-14_openblas\n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.7-h5ec1e0e_5\n",
            "  libpng             conda-forge/linux-64::libpng-1.6.37-hed695b0_0\n",
            "  libtiff            conda-forge/linux-64::libtiff-4.1.0-hc3755c2_1\n",
            "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h14c3975_1000\n",
            "  libxcb             conda-forge/linux-64::libxcb-1.13-h14c3975_1002\n",
            "  libxml2            conda-forge/linux-64::libxml2-2.9.10-hee79883_0\n",
            "  lz4-c              conda-forge/linux-64::lz4-c-1.8.3-he1b5a44_1001\n",
            "  numpy              conda-forge/linux-64::numpy-1.17.3-py37h95a1406_0\n",
            "  olefile            conda-forge/noarch::olefile-0.46-py_0\n",
            "  pandas             conda-forge/linux-64::pandas-0.25.3-py37hb3f55d8_0\n",
            "  pcre               conda-forge/linux-64::pcre-8.43-he1b5a44_0\n",
            "  pillow             pkgs/main/linux-64::pillow-6.2.1-py37h34e0f95_0\n",
            "  pixman             conda-forge/linux-64::pixman-0.38.0-h516909a_1003\n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h14c3975_1001\n",
            "  pycairo            conda-forge/linux-64::pycairo-1.18.2-py37h438ddbb_0\n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.1-py_0\n",
            "  pytz               conda-forge/noarch::pytz-2019.3-py_0\n",
            "  rdkit              conda-forge/linux-64::rdkit-2019.09.2-py37hb31dc5d_0\n",
            "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-h14c3975_1002\n",
            "  xorg-libice        conda-forge/linux-64::xorg-libice-1.0.10-h516909a_0\n",
            "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.3-h84519dc_1000\n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.6.9-h516909a_0\n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.9-h14c3975_0\n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h516909a_0\n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h516909a_0\n",
            "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.10-h516909a_1002\n",
            "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-h14c3975_1002\n",
            "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-h14c3975_1002\n",
            "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-h14c3975_1007\n",
            "  zstd               conda-forge/linux-64::zstd-1.4.4-h3b9ef0a_1\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates    pkgs/main::ca-certificates-2019.10.16~ --> conda-forge::ca-certificates-2019.11.28-hecc5488_0\n",
            "  certifi               pkgs/main::certifi-2019.9.11-py37_0 --> conda-forge::certifi-2019.11.28-py37_0\n",
            "  conda                      pkgs/main::conda-4.7.12-py37_0 --> conda-forge::conda-4.8.0-py37_1\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  openssl              pkgs/main::openssl-1.1.1d-h7b6447c_3 --> conda-forge::openssl-1.1.1d-h516909a_0\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "\n",
            "real\t0m35.802s\n",
            "user\t0m29.206s\n",
            "sys\t0m3.134s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIqiCfVdRKHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Imh4PiQ-RvcI",
        "colab_type": "code",
        "outputId": "a809a985-c09f-4fba-cb6a-920525a54706",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adcjwaHnT3LR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root = \"/content/drive\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz2GKCVNRLv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Sequential, Linear, ReLU, GRU\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import QM9\n",
        "from torch_geometric.nn import NNConv, Set2Set\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.utils import remove_self_loops\n",
        "\n",
        "target = 0\n",
        "dim = 64\n",
        "\n",
        "\n",
        "class MyTransform(object):\n",
        "    def __call__(self, data):\n",
        "        # Specify target.\n",
        "        data.y = data.y[:, target]\n",
        "        return data\n",
        "\n",
        "\n",
        "class Complete(object):\n",
        "    def __call__(self, data):\n",
        "        device = data.edge_index.device\n",
        "\n",
        "        row = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
        "        col = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
        "\n",
        "        row = row.view(-1, 1).repeat(1, data.num_nodes).view(-1)\n",
        "        col = col.repeat(data.num_nodes)\n",
        "        edge_index = torch.stack([row, col], dim=0)\n",
        "\n",
        "        edge_attr = None\n",
        "        if data.edge_attr is not None:\n",
        "            idx = data.edge_index[0] * data.num_nodes + data.edge_index[1]\n",
        "            size = list(data.edge_attr.size())\n",
        "            size[0] = data.num_nodes * data.num_nodes\n",
        "            edge_attr = data.edge_attr.new_zeros(size)\n",
        "            edge_attr[idx] = data.edge_attr\n",
        "\n",
        "        edge_index, edge_attr = remove_self_loops(edge_index, edge_attr)\n",
        "        data.edge_attr = edge_attr\n",
        "        data.edge_index = edge_index\n",
        "\n",
        "        return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPUmXngCuxs9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_sparse import coalesce\n",
        "from torch_geometric.data import (InMemoryDataset, download_url, extract_zip,\n",
        "                                  Data)\n",
        "\n",
        "try:\n",
        "    import rdkit\n",
        "    from rdkit import Chem\n",
        "    from rdkit import rdBase\n",
        "    from rdkit.Chem.rdchem import HybridizationType\n",
        "    from rdkit import RDConfig\n",
        "    from rdkit.Chem import ChemicalFeatures\n",
        "    from rdkit.Chem.rdchem import BondType as BT\n",
        "    rdBase.DisableLog('rdApp.error')\n",
        "except ImportError:\n",
        "    rdkit = None\n",
        "\n",
        "\n",
        "class QM9(InMemoryDataset):\n",
        "    r\"\"\"The QM9 dataset from the `\"MoleculeNet: A Benchmark for Molecular\n",
        "    Machine Learning\" <https://arxiv.org/abs/1703.00564>`_ paper, consisting of\n",
        "    about 130,000 molecules with 16 regression targets.\n",
        "    Each molecule includes complete spatial information for the single low\n",
        "    energy conformation of the atoms in the molecule.\n",
        "    In addition, we provide the atom features from the `\"Neural Message\n",
        "    Passing for Quantum Chemistry\" <https://arxiv.org/abs/1704.01212>`_ paper.\n",
        "\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | Target | Property                         | Description                                                                       | Unit                                        |\n",
        "    +========+==================================+===================================================================================+=============================================+\n",
        "    | 0      | :math:`\\mu`                      | Dipole moment                                                                     | :math:`\\textrm{D}`                          |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 1      | :math:`\\alpha`                   | Isotropic polarizability                                                          | :math:`{a_0}^3`                             |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 2      | :math:`\\epsilon_{\\textrm{HOMO}}` | Highest occupied molecular orbital energy                                         | :math:`E_{\\textrm{h}}`                      |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 3      | :math:`\\epsilon_{\\textrm{LUMO}}` | Lowest unoccupied molecular orbital energy                                        | :math:`E_{\\textrm{h}}`                      |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 4      | :math:`\\Delta \\epsilon`          | Gap between :math:`\\epsilon_{\\textrm{HOMO}}` and :math:`\\epsilon_{\\textrm{LUMO}}` | :math:`E_{\\textrm{h}}`                      |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 5      | :math:`\\langle R^2 \\rangle`      | Electronic spatial extent                                                         | :math:`{a_0}^2`                             |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 6      | :math:`\\textrm{ZPVE}`            | Zero point vibrational energy                                                     | :math:`E_{\\textrm{h}}`                      |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 7      | :math:`U_0`                      | Internal energy at 0K                                                             | :math:`E_{\\textrm{h}}`                      |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 8      | :math:`U`                        | Internal energy at 298.15K                                                        | :math:`E_{\\textrm{h}}`                      |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 9      | :math:`H`                        | Enthalpy at 298.15K                                                               | :math:`E_{\\textrm{h}}`                      |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 10     | :math:`G`                        | Free energy at 298.15K                                                            | :math:`E_{\\textrm{h}}`                      |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 11     | :math:`c_{\\textrm{v}}`           | Heat capavity at 298.15K                                                          | :math:`\\frac{\\textrm{cal}}{\\textrm{mol K}}` |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 12     | :math:`U_0^{\\textrm{ATOM}}`      | Atomization energy at 0K                                                          | :math:`\\frac{\\textrm{kcal}}{\\textrm{mol}}`  |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 13     | :math:`U^{\\textrm{ATOM}}`        | Atomization energy at 298.15K                                                     | :math:`\\frac{\\textrm{kcal}}{\\textrm{mol}}`  |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 14     | :math:`H^{\\textrm{ATOM}}`        | Atomization enthalpy at 298.15K                                                   | :math:`\\frac{\\textrm{kcal}}{\\textrm{mol}}`  |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 15     | :math:`G^{\\textrm{ATOM}}`        | Atomization free energy at 298.15K                                                | :math:`\\frac{\\textrm{kcal}}{\\textrm{mol}}`  |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "\n",
        "    Args:\n",
        "        root (string): Root directory where the dataset should be saved.\n",
        "        transform (callable, optional): A function/transform that takes in an\n",
        "            :obj:`torch_geometric.data.Data` object and returns a transformed\n",
        "            version. The data object will be transformed before every access.\n",
        "            (default: :obj:`None`)\n",
        "        pre_transform (callable, optional): A function/transform that takes in\n",
        "            an :obj:`torch_geometric.data.Data` object and returns a\n",
        "            transformed version. The data object will be transformed before\n",
        "            being saved to disk. (default: :obj:`None`)\n",
        "        pre_filter (callable, optional): A function that takes in an\n",
        "            :obj:`torch_geometric.data.Data` object and returns a boolean\n",
        "            value, indicating whether the data object should be included in the\n",
        "            final dataset. (default: :obj:`None`)\n",
        "    \"\"\"  # noqa: E501\n",
        "\n",
        "    raw_url = ('https://s3-us-west-1.amazonaws.com/deepchem.io/datasets/'\n",
        "               'molnet_publish/qm9.zip')\n",
        "    processed_url = 'http://www.roemisch-drei.de/qm9.zip'\n",
        "\n",
        "    if rdkit is not None:\n",
        "        types = {'H': 0, 'C': 1, 'N': 2, 'O': 3, 'F': 4}\n",
        "        bonds = {BT.SINGLE: 0, BT.DOUBLE: 1, BT.TRIPLE: 2, BT.AROMATIC: 3}\n",
        "\n",
        "    def __init__(self, root, transform=None, pre_transform=None,\n",
        "                 pre_filter=None):\n",
        "        super(QM9, self).__init__(root, transform, pre_transform, pre_filter)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return 'qm9.pt' if rdkit is None else ['gdb9.sdf', 'gdb9.sdf.csv']\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return 'data.pt'\n",
        "\n",
        "    def download(self):\n",
        "        url = self.processed_url if rdkit is None else self.raw_url\n",
        "        file_path = download_url(url, self.raw_dir)\n",
        "        extract_zip(file_path, self.raw_dir)\n",
        "        os.unlink(file_path)\n",
        "\n",
        "    def process(self):\n",
        "        if rdkit is None:\n",
        "            print('Using a pre-processed version of the dataset. Please '\n",
        "                  'install `rdkit` to alternatively process the raw data.')\n",
        "\n",
        "            self.data, self.slices = torch.load(self.raw_paths[0])\n",
        "            data_list = [data for data in self]\n",
        "\n",
        "            if self.pre_filter is not None:\n",
        "                data_list = [d for d in data_list if self.pre_filter(d)]\n",
        "\n",
        "            if self.pre_transform is not None:\n",
        "                data_list = [self.pre_transform(d) for d in data_list]\n",
        "\n",
        "            data, slices = self.collate(data_list)\n",
        "            torch.save((data, slices), self.processed_paths[0])\n",
        "            return\n",
        "   #Change configuration for just one target\n",
        "        with open(self.raw_paths[1], 'r') as f:\n",
        "            target = f.read().split('\\n')[1:-1]\n",
        "            target = [[float(x) for x in line.split(',')[10:11]]\n",
        "                      for line in target]\n",
        "            target = torch.tensor(target, dtype=torch.float)\n",
        "\n",
        "        suppl = Chem.SDMolSupplier(self.raw_paths[0], removeHs=False)\n",
        "        fdef_name = osp.join(RDConfig.RDDataDir, 'BaseFeatures.fdef')\n",
        "        factory = ChemicalFeatures.BuildFeatureFactory(fdef_name)\n",
        "\n",
        "        data_list = []\n",
        "        count=0\n",
        "        for i, mol in enumerate(suppl):\n",
        "          if ( count<13000):\n",
        "            if mol is None:\n",
        "                continue\n",
        "\n",
        "            text = suppl.GetItemText(i)\n",
        "            N = mol.GetNumAtoms()\n",
        "\n",
        "            pos = text.split('\\n')[4:4 + N]\n",
        "            pos = [[float(x) for x in line.split()[:3]] for line in pos]\n",
        "            pos = torch.tensor(pos, dtype=torch.float)\n",
        "\n",
        "            type_idx = []\n",
        "            atomic_number = []\n",
        "            acceptor = []\n",
        "            donor = []\n",
        "            aromatic = []\n",
        "            sp = []\n",
        "            sp2 = []\n",
        "            sp3 = []\n",
        "            num_hs = []\n",
        "            for atom in mol.GetAtoms():\n",
        "                type_idx.append(self.types[atom.GetSymbol()])\n",
        "                atomic_number.append(atom.GetAtomicNum())\n",
        "                donor.append(0)\n",
        "                acceptor.append(0)\n",
        "                aromatic.append(1 if atom.GetIsAromatic() else 0)\n",
        "                hybridization = atom.GetHybridization()\n",
        "                sp.append(1 if hybridization == HybridizationType.SP else 0)\n",
        "                sp2.append(1 if hybridization == HybridizationType.SP2 else 0)\n",
        "                sp3.append(1 if hybridization == HybridizationType.SP3 else 0)\n",
        "                num_hs.append(atom.GetTotalNumHs(includeNeighbors=True))\n",
        "\n",
        "            feats = factory.GetFeaturesForMol(mol)\n",
        "            for j in range(0, len(feats)):\n",
        "                if feats[j].GetFamily() == 'Donor':\n",
        "                    node_list = feats[j].GetAtomIds()\n",
        "                    for k in node_list:\n",
        "                        donor[k] = 1\n",
        "                elif feats[j].GetFamily() == 'Acceptor':\n",
        "                    node_list = feats[j].GetAtomIds()\n",
        "                    for k in node_list:\n",
        "                        acceptor[k] = 1\n",
        "\n",
        "\n",
        "            row, col, bond_idx = [], [], []\n",
        "            bond_type= [0] * N\n",
        "            i=0\n",
        "            for bond in mol.GetBonds():\n",
        "                start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
        "                row += [start, end]\n",
        "                col += [end, start]\n",
        "                bond_idx += 2 * [self.bonds[bond.GetBondType()]]\n",
        "                if i<N:\n",
        "                  bond_type[i]=2 *self.bonds[bond.GetBondType()]\n",
        "                  i=i+1    \n",
        "            \n",
        "            x1 = F.one_hot(torch.tensor(type_idx), num_classes=len(self.types))\n",
        "            x2 = torch.tensor([\n",
        "                atomic_number, acceptor, donor, aromatic, sp, sp2, sp3, num_hs, bond_type\n",
        "            ], dtype=torch.float).t().contiguous()\n",
        "            x = torch.cat([x1.to(torch.float), x2], dim=-1)    \n",
        "\n",
        "            edge_index = torch.tensor([row, col], dtype=torch.long)\n",
        "            edge_attr = F.one_hot(torch.tensor(bond_idx),\n",
        "                                  num_classes=len(self.bonds)).to(torch.float)\n",
        "            edge_index, edge_attr = coalesce(edge_index, edge_attr, N, N)\n",
        "\n",
        "            y = target[i].unsqueeze(0)\n",
        "\n",
        "            data = Data(x=x, pos=pos, edge_index=edge_index,\n",
        "                        edge_attr=edge_attr, y=y)\n",
        "\n",
        "            if self.pre_filter is not None and not self.pre_filter(data):\n",
        "                continue\n",
        "            if self.pre_transform is not None:\n",
        "                data = self.pre_transform(data)\n",
        "\n",
        "            data_list.append(data)\n",
        "          count=count+1\n",
        "        torch.save(self.collate(data_list), self.processed_paths[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPDz9Ax0T0H0",
        "colab_type": "code",
        "outputId": "44c30e4f-6361-4c17-810b-3cfb200411cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "import os\n",
        "path = osp.join(osp.dirname(osp.realpath(root)), '..', 'data', 'QM9')\n",
        "transform = T.Compose([MyTransform(), Complete(), T.Distance(norm=False)])\n",
        "dataset = QM9(path, transform=transform).shuffle()\n",
        "\n",
        "# Normalize targets to mean = 0 and std = 1.\n",
        "mean = dataset.data.y.mean(dim=0, keepdim=True)\n",
        "std = dataset.data.y.std(dim=0, keepdim=True)\n",
        "dataset.data.y = (dataset.data.y - mean) / std\n",
        "mean, std = mean[:, target].item(), std[:, target].item()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://s3-us-west-1.amazonaws.com/deepchem.io/datasets/molnet_publish/qm9.zip\n",
            "Extracting /data/QM9/raw/qm9.zip\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E20IouBDdtop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split datasets.\n",
        "test_dataset = dataset[:1000]\n",
        "val_dataset = dataset[1000:2000]\n",
        "train_dataset = dataset[2000:13000]\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aG6NlrlSUIti",
        "colab_type": "code",
        "outputId": "7c8c64b5-ff04-4816-c27e-0e0bd7dd63cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GatedGraphConv\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "dim = 64\n",
        "class GGNNet(torch.nn.Module):\n",
        "     def __init__(self):\n",
        "        super(GGNNet, self).__init__()\n",
        "        self.gg = GatedGraphConv(dataset.num_features, 3)\n",
        "\n",
        "        self.set2set = Set2Set(dataset.num_features, processing_steps=3)\n",
        "        self.lin1 = torch.nn.Linear(2 * dataset.num_features, dataset.num_features)\n",
        "        self.lin2 = torch.nn.Linear(dataset.num_features, 1)\n",
        "\n",
        "     def forward(self, data):\n",
        "        out = self.gg(x = data.x, edge_index = data.edge_index) \n",
        "\n",
        "        out = self.set2set(out, data.batch)\n",
        "        out = F.relu(self.lin1(out))\n",
        "        out = self.lin2(out)\n",
        "        return out.view(-1)\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = GGNNet( ).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
        "                                                       factor=0.7, patience=5,\n",
        "                                                       min_lr=0.00001)\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    loss_all = 0\n",
        "\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss = F.mse_loss(model(data), data.y)\n",
        "        loss.backward()\n",
        "        loss_all += loss.item() * data.num_graphs\n",
        "        optimizer.step()\n",
        "    return loss_all / len(train_loader.dataset)\n",
        "\n",
        "\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "    error = 0\n",
        "\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        error += (model(data) * std - data.y * std).abs().sum().item()  # MAE\n",
        "    return error / len(loader.dataset)\n",
        "\n",
        "\n",
        "best_val_error = None\n",
        "for epoch in range(1, 301):\n",
        "    lr = scheduler.optimizer.param_groups[0]['lr']\n",
        "    loss = train(epoch)\n",
        "    val_error = test(val_loader)\n",
        "    scheduler.step(val_error)\n",
        "\n",
        "    if best_val_error is None or val_error <= best_val_error:\n",
        "        test_error = test(test_loader)\n",
        "        best_val_error = val_error\n",
        "\n",
        "    print('Epoch: {:03d}, LR: {:7f}, Loss: {:.7f}, Validation MAE: {:.7f}, '\n",
        "          'Test MAE: {:.7f}'.format(epoch, lr, loss, val_error, test_error))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 001, LR: 0.001000, Loss: 0.9538520, Validation MAE: 0.0153576, Test MAE: 0.0155306\n",
            "Epoch: 002, LR: 0.001000, Loss: 0.8076563, Validation MAE: 0.0138603, Test MAE: 0.0139381\n",
            "Epoch: 003, LR: 0.001000, Loss: 0.6433622, Validation MAE: 0.0113364, Test MAE: 0.0114518\n",
            "Epoch: 004, LR: 0.001000, Loss: 0.4515402, Validation MAE: 0.0094967, Test MAE: 0.0097866\n",
            "Epoch: 005, LR: 0.001000, Loss: 0.2942441, Validation MAE: 0.0082409, Test MAE: 0.0083643\n",
            "Epoch: 006, LR: 0.001000, Loss: 0.2544777, Validation MAE: 0.0079756, Test MAE: 0.0083942\n",
            "Epoch: 007, LR: 0.001000, Loss: 0.3272695, Validation MAE: 0.0076761, Test MAE: 0.0078687\n",
            "Epoch: 008, LR: 0.001000, Loss: 0.2089311, Validation MAE: 0.0069525, Test MAE: 0.0072672\n",
            "Epoch: 009, LR: 0.001000, Loss: 0.1928212, Validation MAE: 0.0068693, Test MAE: 0.0071718\n",
            "Epoch: 010, LR: 0.001000, Loss: 0.1843081, Validation MAE: 0.0066916, Test MAE: 0.0070235\n",
            "Epoch: 011, LR: 0.001000, Loss: 0.1817635, Validation MAE: 0.0064932, Test MAE: 0.0068376\n",
            "Epoch: 012, LR: 0.001000, Loss: 0.1711475, Validation MAE: 0.0067258, Test MAE: 0.0068376\n",
            "Epoch: 013, LR: 0.001000, Loss: 0.2060393, Validation MAE: 0.0061658, Test MAE: 0.0063755\n",
            "Epoch: 014, LR: 0.001000, Loss: 0.1872577, Validation MAE: 0.0062018, Test MAE: 0.0063755\n",
            "Epoch: 015, LR: 0.001000, Loss: 0.1915036, Validation MAE: 0.0086600, Test MAE: 0.0063755\n",
            "Epoch: 016, LR: 0.001000, Loss: 0.1973422, Validation MAE: 0.0057865, Test MAE: 0.0060904\n",
            "Epoch: 017, LR: 0.001000, Loss: 0.1231016, Validation MAE: 0.0050105, Test MAE: 0.0051174\n",
            "Epoch: 018, LR: 0.001000, Loss: 0.0984282, Validation MAE: 0.0047641, Test MAE: 0.0048276\n",
            "Epoch: 019, LR: 0.001000, Loss: 0.0972357, Validation MAE: 0.0041192, Test MAE: 0.0041374\n",
            "Epoch: 020, LR: 0.001000, Loss: 0.0809493, Validation MAE: 0.0042157, Test MAE: 0.0041374\n",
            "Epoch: 021, LR: 0.001000, Loss: 0.0758548, Validation MAE: 0.0038596, Test MAE: 0.0038777\n",
            "Epoch: 022, LR: 0.001000, Loss: 0.0726541, Validation MAE: 0.0035681, Test MAE: 0.0036583\n",
            "Epoch: 023, LR: 0.001000, Loss: 0.0813010, Validation MAE: 0.0034162, Test MAE: 0.0033314\n",
            "Epoch: 024, LR: 0.001000, Loss: 0.0672930, Validation MAE: 0.0032738, Test MAE: 0.0032885\n",
            "Epoch: 025, LR: 0.001000, Loss: 0.3795559, Validation MAE: 0.0110319, Test MAE: 0.0032885\n",
            "Epoch: 026, LR: 0.001000, Loss: 0.5015906, Validation MAE: 0.0088751, Test MAE: 0.0032885\n",
            "Epoch: 027, LR: 0.001000, Loss: 0.1901409, Validation MAE: 0.0057520, Test MAE: 0.0032885\n",
            "Epoch: 028, LR: 0.001000, Loss: 0.0988973, Validation MAE: 0.0044479, Test MAE: 0.0032885\n",
            "Epoch: 029, LR: 0.001000, Loss: 0.0707791, Validation MAE: 0.0033560, Test MAE: 0.0032885\n",
            "Epoch: 030, LR: 0.001000, Loss: 0.0670919, Validation MAE: 0.0052667, Test MAE: 0.0032885\n",
            "Epoch: 031, LR: 0.000700, Loss: 0.0559456, Validation MAE: 0.0027170, Test MAE: 0.0028019\n",
            "Epoch: 032, LR: 0.000700, Loss: 0.0439464, Validation MAE: 0.0025611, Test MAE: 0.0026657\n",
            "Epoch: 033, LR: 0.000700, Loss: 0.0402854, Validation MAE: 0.0024258, Test MAE: 0.0024698\n",
            "Epoch: 034, LR: 0.000700, Loss: 0.0392719, Validation MAE: 0.0027858, Test MAE: 0.0024698\n",
            "Epoch: 035, LR: 0.000700, Loss: 0.0387005, Validation MAE: 0.0025240, Test MAE: 0.0024698\n",
            "Epoch: 036, LR: 0.000700, Loss: 0.0410527, Validation MAE: 0.0033411, Test MAE: 0.0024698\n",
            "Epoch: 037, LR: 0.000700, Loss: 0.0391725, Validation MAE: 0.0032273, Test MAE: 0.0024698\n",
            "Epoch: 038, LR: 0.000700, Loss: 0.2177409, Validation MAE: 0.0037104, Test MAE: 0.0024698\n",
            "Epoch: 039, LR: 0.000700, Loss: 0.1795839, Validation MAE: 0.0031938, Test MAE: 0.0024698\n",
            "Epoch: 040, LR: 0.000490, Loss: 0.0399538, Validation MAE: 0.0026020, Test MAE: 0.0024698\n",
            "Epoch: 041, LR: 0.000490, Loss: 0.0335364, Validation MAE: 0.0024445, Test MAE: 0.0024698\n",
            "Epoch: 042, LR: 0.000490, Loss: 0.0378272, Validation MAE: 0.0027922, Test MAE: 0.0024698\n",
            "Epoch: 043, LR: 0.000490, Loss: 0.0337199, Validation MAE: 0.0022586, Test MAE: 0.0022441\n",
            "Epoch: 044, LR: 0.000490, Loss: 0.0299892, Validation MAE: 0.0022486, Test MAE: 0.0022003\n",
            "Epoch: 045, LR: 0.000490, Loss: 0.0318360, Validation MAE: 0.0021854, Test MAE: 0.0022710\n",
            "Epoch: 046, LR: 0.000490, Loss: 0.0298836, Validation MAE: 0.0021019, Test MAE: 0.0021142\n",
            "Epoch: 047, LR: 0.000490, Loss: 0.0270587, Validation MAE: 0.0020817, Test MAE: 0.0020455\n",
            "Epoch: 048, LR: 0.000490, Loss: 0.0302562, Validation MAE: 0.0025426, Test MAE: 0.0020455\n",
            "Epoch: 049, LR: 0.000490, Loss: 0.0263683, Validation MAE: 0.0020443, Test MAE: 0.0020892\n",
            "Epoch: 050, LR: 0.000490, Loss: 0.0249182, Validation MAE: 0.0021678, Test MAE: 0.0020892\n",
            "Epoch: 051, LR: 0.000490, Loss: 0.0280602, Validation MAE: 0.0020934, Test MAE: 0.0020892\n",
            "Epoch: 052, LR: 0.000490, Loss: 0.0255467, Validation MAE: 0.0025465, Test MAE: 0.0020892\n",
            "Epoch: 053, LR: 0.000490, Loss: 0.0277575, Validation MAE: 0.0019637, Test MAE: 0.0018887\n",
            "Epoch: 054, LR: 0.000490, Loss: 0.0265729, Validation MAE: 0.0019998, Test MAE: 0.0018887\n",
            "Epoch: 055, LR: 0.000490, Loss: 0.0215656, Validation MAE: 0.0021176, Test MAE: 0.0018887\n",
            "Epoch: 056, LR: 0.000490, Loss: 0.0271612, Validation MAE: 0.0019660, Test MAE: 0.0018887\n",
            "Epoch: 057, LR: 0.000490, Loss: 0.0247845, Validation MAE: 0.0019454, Test MAE: 0.0018499\n",
            "Epoch: 058, LR: 0.000490, Loss: 0.0334380, Validation MAE: 0.0023727, Test MAE: 0.0018499\n",
            "Epoch: 059, LR: 0.000490, Loss: 0.0241618, Validation MAE: 0.0019289, Test MAE: 0.0018191\n",
            "Epoch: 060, LR: 0.000490, Loss: 0.0191450, Validation MAE: 0.0024536, Test MAE: 0.0018191\n",
            "Epoch: 061, LR: 0.000490, Loss: 0.0217762, Validation MAE: 0.0021262, Test MAE: 0.0018191\n",
            "Epoch: 062, LR: 0.000490, Loss: 0.0214608, Validation MAE: 0.0018675, Test MAE: 0.0018679\n",
            "Epoch: 063, LR: 0.000490, Loss: 0.0228513, Validation MAE: 0.0016452, Test MAE: 0.0018057\n",
            "Epoch: 064, LR: 0.000490, Loss: 0.0334608, Validation MAE: 0.0023974, Test MAE: 0.0018057\n",
            "Epoch: 065, LR: 0.000490, Loss: 0.0231817, Validation MAE: 0.0016570, Test MAE: 0.0018057\n",
            "Epoch: 066, LR: 0.000490, Loss: 0.0212329, Validation MAE: 0.0016511, Test MAE: 0.0018057\n",
            "Epoch: 067, LR: 0.000490, Loss: 0.0268024, Validation MAE: 0.0018629, Test MAE: 0.0018057\n",
            "Epoch: 068, LR: 0.000490, Loss: 0.0192025, Validation MAE: 0.0017025, Test MAE: 0.0018057\n",
            "Epoch: 069, LR: 0.000490, Loss: 0.0240521, Validation MAE: 0.0028322, Test MAE: 0.0018057\n",
            "Epoch: 070, LR: 0.000343, Loss: 0.0203658, Validation MAE: 0.0015272, Test MAE: 0.0014408\n",
            "Epoch: 071, LR: 0.000343, Loss: 0.0170823, Validation MAE: 0.0015843, Test MAE: 0.0014408\n",
            "Epoch: 072, LR: 0.000343, Loss: 0.0181748, Validation MAE: 0.0019426, Test MAE: 0.0014408\n",
            "Epoch: 073, LR: 0.000343, Loss: 0.0168488, Validation MAE: 0.0014091, Test MAE: 0.0014728\n",
            "Epoch: 074, LR: 0.000343, Loss: 0.0141338, Validation MAE: 0.0014361, Test MAE: 0.0014728\n",
            "Epoch: 075, LR: 0.000343, Loss: 0.0183088, Validation MAE: 0.0013999, Test MAE: 0.0014465\n",
            "Epoch: 076, LR: 0.000343, Loss: 0.0122085, Validation MAE: 0.0014256, Test MAE: 0.0014465\n",
            "Epoch: 077, LR: 0.000343, Loss: 0.0135800, Validation MAE: 0.0014866, Test MAE: 0.0014465\n",
            "Epoch: 078, LR: 0.000343, Loss: 0.0123741, Validation MAE: 0.0014641, Test MAE: 0.0014465\n",
            "Epoch: 079, LR: 0.000343, Loss: 0.0134572, Validation MAE: 0.0014863, Test MAE: 0.0014465\n",
            "Epoch: 080, LR: 0.000343, Loss: 0.0120373, Validation MAE: 0.0013876, Test MAE: 0.0014677\n",
            "Epoch: 081, LR: 0.000343, Loss: 0.0128257, Validation MAE: 0.0014518, Test MAE: 0.0014677\n",
            "Epoch: 082, LR: 0.000343, Loss: 0.0184041, Validation MAE: 0.0015722, Test MAE: 0.0014677\n",
            "Epoch: 083, LR: 0.000343, Loss: 0.0125055, Validation MAE: 0.0015478, Test MAE: 0.0014677\n",
            "Epoch: 084, LR: 0.000343, Loss: 0.0202626, Validation MAE: 0.0015419, Test MAE: 0.0014677\n",
            "Epoch: 085, LR: 0.000343, Loss: 0.0147511, Validation MAE: 0.0012902, Test MAE: 0.0012928\n",
            "Epoch: 086, LR: 0.000343, Loss: 0.0131292, Validation MAE: 0.0012663, Test MAE: 0.0012098\n",
            "Epoch: 087, LR: 0.000343, Loss: 0.0107872, Validation MAE: 0.0011788, Test MAE: 0.0011975\n",
            "Epoch: 088, LR: 0.000343, Loss: 0.0103422, Validation MAE: 0.0012503, Test MAE: 0.0011975\n",
            "Epoch: 089, LR: 0.000343, Loss: 0.0130688, Validation MAE: 0.0019792, Test MAE: 0.0011975\n",
            "Epoch: 090, LR: 0.000343, Loss: 0.0120698, Validation MAE: 0.0014564, Test MAE: 0.0011975\n",
            "Epoch: 091, LR: 0.000343, Loss: 0.0171320, Validation MAE: 0.0013277, Test MAE: 0.0011975\n",
            "Epoch: 092, LR: 0.000343, Loss: 0.0103991, Validation MAE: 0.0011183, Test MAE: 0.0011390\n",
            "Epoch: 093, LR: 0.000343, Loss: 0.0194762, Validation MAE: 0.0012726, Test MAE: 0.0011390\n",
            "Epoch: 094, LR: 0.000343, Loss: 0.0098438, Validation MAE: 0.0011871, Test MAE: 0.0011390\n",
            "Epoch: 095, LR: 0.000343, Loss: 0.0133965, Validation MAE: 0.0013929, Test MAE: 0.0011390\n",
            "Epoch: 096, LR: 0.000343, Loss: 0.0076494, Validation MAE: 0.0012277, Test MAE: 0.0011390\n",
            "Epoch: 097, LR: 0.000343, Loss: 0.0345174, Validation MAE: 0.0012710, Test MAE: 0.0011390\n",
            "Epoch: 098, LR: 0.000343, Loss: 0.0110563, Validation MAE: 0.0010958, Test MAE: 0.0010640\n",
            "Epoch: 099, LR: 0.000343, Loss: 0.0098733, Validation MAE: 0.0011195, Test MAE: 0.0010640\n",
            "Epoch: 100, LR: 0.000343, Loss: 0.0091084, Validation MAE: 0.0010551, Test MAE: 0.0010764\n",
            "Epoch: 101, LR: 0.000343, Loss: 0.0094852, Validation MAE: 0.0013626, Test MAE: 0.0010764\n",
            "Epoch: 102, LR: 0.000343, Loss: 0.0109520, Validation MAE: 0.0010896, Test MAE: 0.0010764\n",
            "Epoch: 103, LR: 0.000343, Loss: 0.0127714, Validation MAE: 0.0010728, Test MAE: 0.0010764\n",
            "Epoch: 104, LR: 0.000343, Loss: 0.0157471, Validation MAE: 0.0011007, Test MAE: 0.0010764\n",
            "Epoch: 105, LR: 0.000343, Loss: 0.0090733, Validation MAE: 0.0016385, Test MAE: 0.0010764\n",
            "Epoch: 106, LR: 0.000343, Loss: 0.0116747, Validation MAE: 0.0010665, Test MAE: 0.0010764\n",
            "Epoch: 107, LR: 0.000240, Loss: 0.0070785, Validation MAE: 0.0010508, Test MAE: 0.0011586\n",
            "Epoch: 108, LR: 0.000240, Loss: 0.0081220, Validation MAE: 0.0009867, Test MAE: 0.0010363\n",
            "Epoch: 109, LR: 0.000240, Loss: 0.0062459, Validation MAE: 0.0009284, Test MAE: 0.0009492\n",
            "Epoch: 110, LR: 0.000240, Loss: 0.0067251, Validation MAE: 0.0013504, Test MAE: 0.0009492\n",
            "Epoch: 111, LR: 0.000240, Loss: 0.0108711, Validation MAE: 0.0009427, Test MAE: 0.0009492\n",
            "Epoch: 112, LR: 0.000240, Loss: 0.0059244, Validation MAE: 0.0012028, Test MAE: 0.0009492\n",
            "Epoch: 113, LR: 0.000240, Loss: 0.0118442, Validation MAE: 0.0009449, Test MAE: 0.0009492\n",
            "Epoch: 114, LR: 0.000240, Loss: 0.0053670, Validation MAE: 0.0008895, Test MAE: 0.0008994\n",
            "Epoch: 115, LR: 0.000240, Loss: 0.0074112, Validation MAE: 0.0010711, Test MAE: 0.0008994\n",
            "Epoch: 116, LR: 0.000240, Loss: 0.0094981, Validation MAE: 0.0008964, Test MAE: 0.0008994\n",
            "Epoch: 117, LR: 0.000240, Loss: 0.0061296, Validation MAE: 0.0012214, Test MAE: 0.0008994\n",
            "Epoch: 118, LR: 0.000240, Loss: 0.0117524, Validation MAE: 0.0008976, Test MAE: 0.0008994\n",
            "Epoch: 119, LR: 0.000240, Loss: 0.0049302, Validation MAE: 0.0008394, Test MAE: 0.0008394\n",
            "Epoch: 120, LR: 0.000240, Loss: 0.0078733, Validation MAE: 0.0009219, Test MAE: 0.0008394\n",
            "Epoch: 121, LR: 0.000240, Loss: 0.0076676, Validation MAE: 0.0010278, Test MAE: 0.0008394\n",
            "Epoch: 122, LR: 0.000240, Loss: 0.0083133, Validation MAE: 0.0009846, Test MAE: 0.0008394\n",
            "Epoch: 123, LR: 0.000240, Loss: 0.0103772, Validation MAE: 0.0012300, Test MAE: 0.0008394\n",
            "Epoch: 124, LR: 0.000240, Loss: 0.0060444, Validation MAE: 0.0008073, Test MAE: 0.0008206\n",
            "Epoch: 125, LR: 0.000240, Loss: 0.0051539, Validation MAE: 0.0007726, Test MAE: 0.0007865\n",
            "Epoch: 126, LR: 0.000240, Loss: 0.0049107, Validation MAE: 0.0008384, Test MAE: 0.0007865\n",
            "Epoch: 127, LR: 0.000240, Loss: 0.0063818, Validation MAE: 0.0008895, Test MAE: 0.0007865\n",
            "Epoch: 128, LR: 0.000240, Loss: 0.0049872, Validation MAE: 0.0011153, Test MAE: 0.0007865\n",
            "Epoch: 129, LR: 0.000240, Loss: 0.0045824, Validation MAE: 0.0008021, Test MAE: 0.0007865\n",
            "Epoch: 130, LR: 0.000240, Loss: 0.0044992, Validation MAE: 0.0008486, Test MAE: 0.0007865\n",
            "Epoch: 131, LR: 0.000240, Loss: 0.0047623, Validation MAE: 0.0007691, Test MAE: 0.0007990\n",
            "Epoch: 132, LR: 0.000240, Loss: 0.0042115, Validation MAE: 0.0007844, Test MAE: 0.0007990\n",
            "Epoch: 133, LR: 0.000240, Loss: 0.0045622, Validation MAE: 0.0008386, Test MAE: 0.0007990\n",
            "Epoch: 134, LR: 0.000240, Loss: 0.0156655, Validation MAE: 0.0016448, Test MAE: 0.0007990\n",
            "Epoch: 135, LR: 0.000240, Loss: 0.0066538, Validation MAE: 0.0008306, Test MAE: 0.0007990\n",
            "Epoch: 136, LR: 0.000240, Loss: 0.0048445, Validation MAE: 0.0007353, Test MAE: 0.0007322\n",
            "Epoch: 137, LR: 0.000240, Loss: 0.0114652, Validation MAE: 0.0013341, Test MAE: 0.0007322\n",
            "Epoch: 138, LR: 0.000240, Loss: 0.0055641, Validation MAE: 0.0007302, Test MAE: 0.0007310\n",
            "Epoch: 139, LR: 0.000240, Loss: 0.0037662, Validation MAE: 0.0007023, Test MAE: 0.0007260\n",
            "Epoch: 140, LR: 0.000240, Loss: 0.0043282, Validation MAE: 0.0007012, Test MAE: 0.0007162\n",
            "Epoch: 141, LR: 0.000240, Loss: 0.0125357, Validation MAE: 0.0009320, Test MAE: 0.0007162\n",
            "Epoch: 142, LR: 0.000240, Loss: 0.0044395, Validation MAE: 0.0007840, Test MAE: 0.0007162\n",
            "Epoch: 143, LR: 0.000240, Loss: 0.0037857, Validation MAE: 0.0007179, Test MAE: 0.0007162\n",
            "Epoch: 144, LR: 0.000240, Loss: 0.0037798, Validation MAE: 0.0006724, Test MAE: 0.0006828\n",
            "Epoch: 145, LR: 0.000240, Loss: 0.0036235, Validation MAE: 0.0006958, Test MAE: 0.0006828\n",
            "Epoch: 146, LR: 0.000240, Loss: 0.0106475, Validation MAE: 0.0009409, Test MAE: 0.0006828\n",
            "Epoch: 147, LR: 0.000240, Loss: 0.0054295, Validation MAE: 0.0007173, Test MAE: 0.0006828\n",
            "Epoch: 148, LR: 0.000240, Loss: 0.0037057, Validation MAE: 0.0006955, Test MAE: 0.0006828\n",
            "Epoch: 149, LR: 0.000240, Loss: 0.0034208, Validation MAE: 0.0007462, Test MAE: 0.0006828\n",
            "Epoch: 150, LR: 0.000240, Loss: 0.0033330, Validation MAE: 0.0007504, Test MAE: 0.0006828\n",
            "Epoch: 151, LR: 0.000168, Loss: 0.0036304, Validation MAE: 0.0006409, Test MAE: 0.0006436\n",
            "Epoch: 152, LR: 0.000168, Loss: 0.0032515, Validation MAE: 0.0007410, Test MAE: 0.0006436\n",
            "Epoch: 153, LR: 0.000168, Loss: 0.0031623, Validation MAE: 0.0006514, Test MAE: 0.0006436\n",
            "Epoch: 154, LR: 0.000168, Loss: 0.0030648, Validation MAE: 0.0007201, Test MAE: 0.0006436\n",
            "Epoch: 155, LR: 0.000168, Loss: 0.0042988, Validation MAE: 0.0007306, Test MAE: 0.0006436\n",
            "Epoch: 156, LR: 0.000168, Loss: 0.0030206, Validation MAE: 0.0006360, Test MAE: 0.0006622\n",
            "Epoch: 157, LR: 0.000168, Loss: 0.0036861, Validation MAE: 0.0006506, Test MAE: 0.0006622\n",
            "Epoch: 158, LR: 0.000168, Loss: 0.0053126, Validation MAE: 0.0006455, Test MAE: 0.0006622\n",
            "Epoch: 159, LR: 0.000168, Loss: 0.0031784, Validation MAE: 0.0006196, Test MAE: 0.0006386\n",
            "Epoch: 160, LR: 0.000168, Loss: 0.0030226, Validation MAE: 0.0006365, Test MAE: 0.0006386\n",
            "Epoch: 161, LR: 0.000168, Loss: 0.0030359, Validation MAE: 0.0006199, Test MAE: 0.0006386\n",
            "Epoch: 162, LR: 0.000168, Loss: 0.0048323, Validation MAE: 0.0006790, Test MAE: 0.0006386\n",
            "Epoch: 163, LR: 0.000168, Loss: 0.0030724, Validation MAE: 0.0006425, Test MAE: 0.0006386\n",
            "Epoch: 164, LR: 0.000168, Loss: 0.0035478, Validation MAE: 0.0008863, Test MAE: 0.0006386\n",
            "Epoch: 165, LR: 0.000168, Loss: 0.0127896, Validation MAE: 0.0010934, Test MAE: 0.0006386\n",
            "Epoch: 166, LR: 0.000118, Loss: 0.0060464, Validation MAE: 0.0006998, Test MAE: 0.0006386\n",
            "Epoch: 167, LR: 0.000118, Loss: 0.0045284, Validation MAE: 0.0006403, Test MAE: 0.0006386\n",
            "Epoch: 168, LR: 0.000118, Loss: 0.0027020, Validation MAE: 0.0006033, Test MAE: 0.0006429\n",
            "Epoch: 169, LR: 0.000118, Loss: 0.0026830, Validation MAE: 0.0006647, Test MAE: 0.0006429\n",
            "Epoch: 170, LR: 0.000118, Loss: 0.0027124, Validation MAE: 0.0006198, Test MAE: 0.0006429\n",
            "Epoch: 171, LR: 0.000118, Loss: 0.0028969, Validation MAE: 0.0006542, Test MAE: 0.0006429\n",
            "Epoch: 172, LR: 0.000118, Loss: 0.0026844, Validation MAE: 0.0005848, Test MAE: 0.0006223\n",
            "Epoch: 173, LR: 0.000118, Loss: 0.0025884, Validation MAE: 0.0005739, Test MAE: 0.0005892\n",
            "Epoch: 174, LR: 0.000118, Loss: 0.0026383, Validation MAE: 0.0006124, Test MAE: 0.0005892\n",
            "Epoch: 175, LR: 0.000118, Loss: 0.0024894, Validation MAE: 0.0005932, Test MAE: 0.0005892\n",
            "Epoch: 176, LR: 0.000118, Loss: 0.0025568, Validation MAE: 0.0005768, Test MAE: 0.0005892\n",
            "Epoch: 177, LR: 0.000118, Loss: 0.0024873, Validation MAE: 0.0005852, Test MAE: 0.0005892\n",
            "Epoch: 178, LR: 0.000118, Loss: 0.0026109, Validation MAE: 0.0005966, Test MAE: 0.0005892\n",
            "Epoch: 179, LR: 0.000118, Loss: 0.0027369, Validation MAE: 0.0005814, Test MAE: 0.0005892\n",
            "Epoch: 180, LR: 0.000082, Loss: 0.0023575, Validation MAE: 0.0005548, Test MAE: 0.0005842\n",
            "Epoch: 181, LR: 0.000082, Loss: 0.0023922, Validation MAE: 0.0005723, Test MAE: 0.0005842\n",
            "Epoch: 182, LR: 0.000082, Loss: 0.0024859, Validation MAE: 0.0006948, Test MAE: 0.0005842\n",
            "Epoch: 183, LR: 0.000082, Loss: 0.0024241, Validation MAE: 0.0005845, Test MAE: 0.0005842\n",
            "Epoch: 184, LR: 0.000082, Loss: 0.0023497, Validation MAE: 0.0005654, Test MAE: 0.0005842\n",
            "Epoch: 185, LR: 0.000082, Loss: 0.0024770, Validation MAE: 0.0005705, Test MAE: 0.0005842\n",
            "Epoch: 186, LR: 0.000082, Loss: 0.0025125, Validation MAE: 0.0005577, Test MAE: 0.0005842\n",
            "Epoch: 187, LR: 0.000058, Loss: 0.0022190, Validation MAE: 0.0005575, Test MAE: 0.0005842\n",
            "Epoch: 188, LR: 0.000058, Loss: 0.0024807, Validation MAE: 0.0006041, Test MAE: 0.0005842\n",
            "Epoch: 189, LR: 0.000058, Loss: 0.0022210, Validation MAE: 0.0006138, Test MAE: 0.0005842\n",
            "Epoch: 190, LR: 0.000058, Loss: 0.0023194, Validation MAE: 0.0005911, Test MAE: 0.0005842\n",
            "Epoch: 191, LR: 0.000058, Loss: 0.0022331, Validation MAE: 0.0005809, Test MAE: 0.0005842\n",
            "Epoch: 192, LR: 0.000058, Loss: 0.0021789, Validation MAE: 0.0005585, Test MAE: 0.0005842\n",
            "Epoch: 193, LR: 0.000040, Loss: 0.0020660, Validation MAE: 0.0005286, Test MAE: 0.0005453\n",
            "Epoch: 194, LR: 0.000040, Loss: 0.0020749, Validation MAE: 0.0005327, Test MAE: 0.0005453\n",
            "Epoch: 195, LR: 0.000040, Loss: 0.0020994, Validation MAE: 0.0005592, Test MAE: 0.0005453\n",
            "Epoch: 196, LR: 0.000040, Loss: 0.0021531, Validation MAE: 0.0005398, Test MAE: 0.0005453\n",
            "Epoch: 197, LR: 0.000040, Loss: 0.0021032, Validation MAE: 0.0005475, Test MAE: 0.0005453\n",
            "Epoch: 198, LR: 0.000040, Loss: 0.0020723, Validation MAE: 0.0005329, Test MAE: 0.0005453\n",
            "Epoch: 199, LR: 0.000040, Loss: 0.0020572, Validation MAE: 0.0005278, Test MAE: 0.0005507\n",
            "Epoch: 200, LR: 0.000040, Loss: 0.0020575, Validation MAE: 0.0005525, Test MAE: 0.0005507\n",
            "Epoch: 201, LR: 0.000040, Loss: 0.0020873, Validation MAE: 0.0005729, Test MAE: 0.0005507\n",
            "Epoch: 202, LR: 0.000040, Loss: 0.0021483, Validation MAE: 0.0005275, Test MAE: 0.0005449\n",
            "Epoch: 203, LR: 0.000040, Loss: 0.0020160, Validation MAE: 0.0005349, Test MAE: 0.0005449\n",
            "Epoch: 204, LR: 0.000040, Loss: 0.0020602, Validation MAE: 0.0005702, Test MAE: 0.0005449\n",
            "Epoch: 205, LR: 0.000040, Loss: 0.0020671, Validation MAE: 0.0005203, Test MAE: 0.0005366\n",
            "Epoch: 206, LR: 0.000040, Loss: 0.0020462, Validation MAE: 0.0005231, Test MAE: 0.0005366\n",
            "Epoch: 207, LR: 0.000040, Loss: 0.0021692, Validation MAE: 0.0005268, Test MAE: 0.0005366\n",
            "Epoch: 208, LR: 0.000040, Loss: 0.0020140, Validation MAE: 0.0005137, Test MAE: 0.0005357\n",
            "Epoch: 209, LR: 0.000040, Loss: 0.0020901, Validation MAE: 0.0005185, Test MAE: 0.0005357\n",
            "Epoch: 210, LR: 0.000040, Loss: 0.0019538, Validation MAE: 0.0005196, Test MAE: 0.0005357\n",
            "Epoch: 211, LR: 0.000040, Loss: 0.0020245, Validation MAE: 0.0006081, Test MAE: 0.0005357\n",
            "Epoch: 212, LR: 0.000040, Loss: 0.0019803, Validation MAE: 0.0005248, Test MAE: 0.0005357\n",
            "Epoch: 213, LR: 0.000040, Loss: 0.0019526, Validation MAE: 0.0005096, Test MAE: 0.0005256\n",
            "Epoch: 214, LR: 0.000040, Loss: 0.0021266, Validation MAE: 0.0005139, Test MAE: 0.0005256\n",
            "Epoch: 215, LR: 0.000040, Loss: 0.0019417, Validation MAE: 0.0005522, Test MAE: 0.0005256\n",
            "Epoch: 216, LR: 0.000040, Loss: 0.0019765, Validation MAE: 0.0005121, Test MAE: 0.0005256\n",
            "Epoch: 217, LR: 0.000040, Loss: 0.0019037, Validation MAE: 0.0005382, Test MAE: 0.0005256\n",
            "Epoch: 218, LR: 0.000040, Loss: 0.0020214, Validation MAE: 0.0005206, Test MAE: 0.0005256\n",
            "Epoch: 219, LR: 0.000040, Loss: 0.0018528, Validation MAE: 0.0005276, Test MAE: 0.0005256\n",
            "Epoch: 220, LR: 0.000028, Loss: 0.0020310, Validation MAE: 0.0005258, Test MAE: 0.0005256\n",
            "Epoch: 221, LR: 0.000028, Loss: 0.0018590, Validation MAE: 0.0005060, Test MAE: 0.0005163\n",
            "Epoch: 222, LR: 0.000028, Loss: 0.0018733, Validation MAE: 0.0005088, Test MAE: 0.0005163\n",
            "Epoch: 223, LR: 0.000028, Loss: 0.0018510, Validation MAE: 0.0005239, Test MAE: 0.0005163\n",
            "Epoch: 224, LR: 0.000028, Loss: 0.0018666, Validation MAE: 0.0005108, Test MAE: 0.0005163\n",
            "Epoch: 225, LR: 0.000028, Loss: 0.0018211, Validation MAE: 0.0005001, Test MAE: 0.0005178\n",
            "Epoch: 226, LR: 0.000028, Loss: 0.0019049, Validation MAE: 0.0005712, Test MAE: 0.0005178\n",
            "Epoch: 227, LR: 0.000028, Loss: 0.0019052, Validation MAE: 0.0005157, Test MAE: 0.0005178\n",
            "Epoch: 228, LR: 0.000028, Loss: 0.0018525, Validation MAE: 0.0005157, Test MAE: 0.0005178\n",
            "Epoch: 229, LR: 0.000028, Loss: 0.0018356, Validation MAE: 0.0004965, Test MAE: 0.0005141\n",
            "Epoch: 230, LR: 0.000028, Loss: 0.0017749, Validation MAE: 0.0004985, Test MAE: 0.0005141\n",
            "Epoch: 231, LR: 0.000028, Loss: 0.0017664, Validation MAE: 0.0004947, Test MAE: 0.0005140\n",
            "Epoch: 232, LR: 0.000028, Loss: 0.0018291, Validation MAE: 0.0005009, Test MAE: 0.0005140\n",
            "Epoch: 233, LR: 0.000028, Loss: 0.0017754, Validation MAE: 0.0005144, Test MAE: 0.0005140\n",
            "Epoch: 234, LR: 0.000028, Loss: 0.0017937, Validation MAE: 0.0005187, Test MAE: 0.0005140\n",
            "Epoch: 235, LR: 0.000028, Loss: 0.0018321, Validation MAE: 0.0005328, Test MAE: 0.0005140\n",
            "Epoch: 236, LR: 0.000028, Loss: 0.0018614, Validation MAE: 0.0005547, Test MAE: 0.0005140\n",
            "Epoch: 237, LR: 0.000028, Loss: 0.0018475, Validation MAE: 0.0005012, Test MAE: 0.0005140\n",
            "Epoch: 238, LR: 0.000020, Loss: 0.0017227, Validation MAE: 0.0004957, Test MAE: 0.0005140\n",
            "Epoch: 239, LR: 0.000020, Loss: 0.0017680, Validation MAE: 0.0004942, Test MAE: 0.0005070\n",
            "Epoch: 240, LR: 0.000020, Loss: 0.0017209, Validation MAE: 0.0004896, Test MAE: 0.0005039\n",
            "Epoch: 241, LR: 0.000020, Loss: 0.0017316, Validation MAE: 0.0004893, Test MAE: 0.0005045\n",
            "Epoch: 242, LR: 0.000020, Loss: 0.0017490, Validation MAE: 0.0004976, Test MAE: 0.0005045\n",
            "Epoch: 243, LR: 0.000020, Loss: 0.0017590, Validation MAE: 0.0004846, Test MAE: 0.0005011\n",
            "Epoch: 244, LR: 0.000020, Loss: 0.0017238, Validation MAE: 0.0005004, Test MAE: 0.0005011\n",
            "Epoch: 245, LR: 0.000020, Loss: 0.0017561, Validation MAE: 0.0005162, Test MAE: 0.0005011\n",
            "Epoch: 246, LR: 0.000020, Loss: 0.0016910, Validation MAE: 0.0004889, Test MAE: 0.0005011\n",
            "Epoch: 247, LR: 0.000020, Loss: 0.0017286, Validation MAE: 0.0004871, Test MAE: 0.0005011\n",
            "Epoch: 248, LR: 0.000020, Loss: 0.0017571, Validation MAE: 0.0005032, Test MAE: 0.0005011\n",
            "Epoch: 249, LR: 0.000020, Loss: 0.0017413, Validation MAE: 0.0004949, Test MAE: 0.0005011\n",
            "Epoch: 250, LR: 0.000014, Loss: 0.0016583, Validation MAE: 0.0004874, Test MAE: 0.0005011\n",
            "Epoch: 251, LR: 0.000014, Loss: 0.0016815, Validation MAE: 0.0004835, Test MAE: 0.0004988\n",
            "Epoch: 252, LR: 0.000014, Loss: 0.0016851, Validation MAE: 0.0004840, Test MAE: 0.0004988\n",
            "Epoch: 253, LR: 0.000014, Loss: 0.0016345, Validation MAE: 0.0004850, Test MAE: 0.0004988\n",
            "Epoch: 254, LR: 0.000014, Loss: 0.0016858, Validation MAE: 0.0004804, Test MAE: 0.0004963\n",
            "Epoch: 255, LR: 0.000014, Loss: 0.0016759, Validation MAE: 0.0004865, Test MAE: 0.0004963\n",
            "Epoch: 256, LR: 0.000014, Loss: 0.0016588, Validation MAE: 0.0004803, Test MAE: 0.0004947\n",
            "Epoch: 257, LR: 0.000014, Loss: 0.0016919, Validation MAE: 0.0004804, Test MAE: 0.0004947\n",
            "Epoch: 258, LR: 0.000014, Loss: 0.0016564, Validation MAE: 0.0004856, Test MAE: 0.0004947\n",
            "Epoch: 259, LR: 0.000014, Loss: 0.0016347, Validation MAE: 0.0004823, Test MAE: 0.0004947\n",
            "Epoch: 260, LR: 0.000014, Loss: 0.0016311, Validation MAE: 0.0004847, Test MAE: 0.0004947\n",
            "Epoch: 261, LR: 0.000014, Loss: 0.0016626, Validation MAE: 0.0004787, Test MAE: 0.0004944\n",
            "Epoch: 262, LR: 0.000014, Loss: 0.0016382, Validation MAE: 0.0004931, Test MAE: 0.0004944\n",
            "Epoch: 263, LR: 0.000014, Loss: 0.0016369, Validation MAE: 0.0004809, Test MAE: 0.0004944\n",
            "Epoch: 264, LR: 0.000014, Loss: 0.0016148, Validation MAE: 0.0004809, Test MAE: 0.0004944\n",
            "Epoch: 265, LR: 0.000014, Loss: 0.0016371, Validation MAE: 0.0005013, Test MAE: 0.0004944\n",
            "Epoch: 266, LR: 0.000014, Loss: 0.0016813, Validation MAE: 0.0004772, Test MAE: 0.0004941\n",
            "Epoch: 267, LR: 0.000014, Loss: 0.0016325, Validation MAE: 0.0004790, Test MAE: 0.0004941\n",
            "Epoch: 268, LR: 0.000014, Loss: 0.0016064, Validation MAE: 0.0004734, Test MAE: 0.0004909\n",
            "Epoch: 269, LR: 0.000014, Loss: 0.0016274, Validation MAE: 0.0004904, Test MAE: 0.0004909\n",
            "Epoch: 270, LR: 0.000014, Loss: 0.0016591, Validation MAE: 0.0004813, Test MAE: 0.0004909\n",
            "Epoch: 271, LR: 0.000014, Loss: 0.0016351, Validation MAE: 0.0004805, Test MAE: 0.0004909\n",
            "Epoch: 272, LR: 0.000014, Loss: 0.0015960, Validation MAE: 0.0004805, Test MAE: 0.0004909\n",
            "Epoch: 273, LR: 0.000014, Loss: 0.0016022, Validation MAE: 0.0004830, Test MAE: 0.0004909\n",
            "Epoch: 274, LR: 0.000014, Loss: 0.0016252, Validation MAE: 0.0004776, Test MAE: 0.0004909\n",
            "Epoch: 275, LR: 0.000010, Loss: 0.0015700, Validation MAE: 0.0004785, Test MAE: 0.0004909\n",
            "Epoch: 276, LR: 0.000010, Loss: 0.0015926, Validation MAE: 0.0004718, Test MAE: 0.0004840\n",
            "Epoch: 277, LR: 0.000010, Loss: 0.0016076, Validation MAE: 0.0004760, Test MAE: 0.0004840\n",
            "Epoch: 278, LR: 0.000010, Loss: 0.0015803, Validation MAE: 0.0004745, Test MAE: 0.0004840\n",
            "Epoch: 279, LR: 0.000010, Loss: 0.0016142, Validation MAE: 0.0004725, Test MAE: 0.0004840\n",
            "Epoch: 280, LR: 0.000010, Loss: 0.0016215, Validation MAE: 0.0004768, Test MAE: 0.0004840\n",
            "Epoch: 281, LR: 0.000010, Loss: 0.0015868, Validation MAE: 0.0004765, Test MAE: 0.0004840\n",
            "Epoch: 282, LR: 0.000010, Loss: 0.0015695, Validation MAE: 0.0004693, Test MAE: 0.0004882\n",
            "Epoch: 283, LR: 0.000010, Loss: 0.0015717, Validation MAE: 0.0004738, Test MAE: 0.0004882\n",
            "Epoch: 284, LR: 0.000010, Loss: 0.0015397, Validation MAE: 0.0004689, Test MAE: 0.0004846\n",
            "Epoch: 285, LR: 0.000010, Loss: 0.0015550, Validation MAE: 0.0004735, Test MAE: 0.0004846\n",
            "Epoch: 286, LR: 0.000010, Loss: 0.0015838, Validation MAE: 0.0004751, Test MAE: 0.0004846\n",
            "Epoch: 287, LR: 0.000010, Loss: 0.0015532, Validation MAE: 0.0004713, Test MAE: 0.0004846\n",
            "Epoch: 288, LR: 0.000010, Loss: 0.0015766, Validation MAE: 0.0004778, Test MAE: 0.0004846\n",
            "Epoch: 289, LR: 0.000010, Loss: 0.0015947, Validation MAE: 0.0004782, Test MAE: 0.0004846\n",
            "Epoch: 290, LR: 0.000010, Loss: 0.0016030, Validation MAE: 0.0004733, Test MAE: 0.0004846\n",
            "Epoch: 291, LR: 0.000010, Loss: 0.0015527, Validation MAE: 0.0004698, Test MAE: 0.0004846\n",
            "Epoch: 292, LR: 0.000010, Loss: 0.0015404, Validation MAE: 0.0004732, Test MAE: 0.0004846\n",
            "Epoch: 293, LR: 0.000010, Loss: 0.0015514, Validation MAE: 0.0004770, Test MAE: 0.0004846\n",
            "Epoch: 294, LR: 0.000010, Loss: 0.0015633, Validation MAE: 0.0004683, Test MAE: 0.0004811\n",
            "Epoch: 295, LR: 0.000010, Loss: 0.0015455, Validation MAE: 0.0004724, Test MAE: 0.0004811\n",
            "Epoch: 296, LR: 0.000010, Loss: 0.0015398, Validation MAE: 0.0004684, Test MAE: 0.0004811\n",
            "Epoch: 297, LR: 0.000010, Loss: 0.0015499, Validation MAE: 0.0004798, Test MAE: 0.0004811\n",
            "Epoch: 298, LR: 0.000010, Loss: 0.0015383, Validation MAE: 0.0004647, Test MAE: 0.0004807\n",
            "Epoch: 299, LR: 0.000010, Loss: 0.0015381, Validation MAE: 0.0004684, Test MAE: 0.0004807\n",
            "Epoch: 300, LR: 0.000010, Loss: 0.0015389, Validation MAE: 0.0004702, Test MAE: 0.0004807\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}