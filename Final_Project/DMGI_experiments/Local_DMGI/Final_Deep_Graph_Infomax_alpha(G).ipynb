{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final-Deep_Graph_Infomax_alpha(G).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYNUmydJqf5s",
        "colab_type": "text"
      },
      "source": [
        "###COMP396 WINTER 2020: Deep_Molecular_Graph_Infomax\n",
        "Description: Local Global + Global Global infomax for molecular representations.\n",
        "\n",
        "Referenced code : Deep Infomax: https://github.com/rdevon/DIM,\n",
        "                  Infograph: 2019 Github repository https://github.com/fanyun-sun/InfoGraph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbhX-ayQqq59",
        "colab_type": "text"
      },
      "source": [
        "## Installations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BBM1XoLJyai",
        "colab_type": "code",
        "outputId": "3aee7ef2-ee50-4211-d062-c2dafa44c702",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!apt install gcc-5 g++-5 -y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  cpp-5 gcc-5-base libasan2 libgcc-5-dev libisl15 libmpx0 libstdc++-5-dev\n",
            "Suggested packages:\n",
            "  gcc-5-locales g++-5-multilib gcc-5-doc libstdc++6-5-dbg gcc-5-multilib\n",
            "  libgcc1-dbg libgomp1-dbg libitm1-dbg libatomic1-dbg libasan2-dbg\n",
            "  liblsan0-dbg libtsan0-dbg libubsan0-dbg libcilkrts5-dbg libmpx0-dbg\n",
            "  libquadmath0-dbg libstdc++-5-doc\n",
            "The following NEW packages will be installed:\n",
            "  cpp-5 g++-5 gcc-5 gcc-5-base libasan2 libgcc-5-dev libisl15 libmpx0\n",
            "  libstdc++-5-dev\n",
            "0 upgraded, 9 newly installed, 0 to remove and 31 not upgraded.\n",
            "Need to get 29.1 MB of archives.\n",
            "After this operation, 100 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 gcc-5-base amd64 5.5.0-12ubuntu1 [17.1 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libisl15 amd64 0.18-4 [548 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 cpp-5 amd64 5.5.0-12ubuntu1 [7,785 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libasan2 amd64 5.5.0-12ubuntu1 [264 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libmpx0 amd64 5.5.0-12ubuntu1 [9,888 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libgcc-5-dev amd64 5.5.0-12ubuntu1 [2,224 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic/universe amd64 gcc-5 amd64 5.5.0-12ubuntu1 [8,357 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libstdc++-5-dev amd64 5.5.0-12ubuntu1 [1,415 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic/universe amd64 g++-5 amd64 5.5.0-12ubuntu1 [8,450 kB]\n",
            "Fetched 29.1 MB in 2s (14.8 MB/s)\n",
            "Selecting previously unselected package gcc-5-base:amd64.\n",
            "(Reading database ... 144433 files and directories currently installed.)\n",
            "Preparing to unpack .../0-gcc-5-base_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking gcc-5-base:amd64 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package libisl15:amd64.\n",
            "Preparing to unpack .../1-libisl15_0.18-4_amd64.deb ...\n",
            "Unpacking libisl15:amd64 (0.18-4) ...\n",
            "Selecting previously unselected package cpp-5.\n",
            "Preparing to unpack .../2-cpp-5_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking cpp-5 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package libasan2:amd64.\n",
            "Preparing to unpack .../3-libasan2_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking libasan2:amd64 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package libmpx0:amd64.\n",
            "Preparing to unpack .../4-libmpx0_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking libmpx0:amd64 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package libgcc-5-dev:amd64.\n",
            "Preparing to unpack .../5-libgcc-5-dev_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking libgcc-5-dev:amd64 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package gcc-5.\n",
            "Preparing to unpack .../6-gcc-5_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking gcc-5 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package libstdc++-5-dev:amd64.\n",
            "Preparing to unpack .../7-libstdc++-5-dev_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking libstdc++-5-dev:amd64 (5.5.0-12ubuntu1) ...\n",
            "Selecting previously unselected package g++-5.\n",
            "Preparing to unpack .../8-g++-5_5.5.0-12ubuntu1_amd64.deb ...\n",
            "Unpacking g++-5 (5.5.0-12ubuntu1) ...\n",
            "Setting up libisl15:amd64 (0.18-4) ...\n",
            "Setting up gcc-5-base:amd64 (5.5.0-12ubuntu1) ...\n",
            "Setting up libmpx0:amd64 (5.5.0-12ubuntu1) ...\n",
            "Setting up libasan2:amd64 (5.5.0-12ubuntu1) ...\n",
            "Setting up libgcc-5-dev:amd64 (5.5.0-12ubuntu1) ...\n",
            "Setting up cpp-5 (5.5.0-12ubuntu1) ...\n",
            "Setting up libstdc++-5-dev:amd64 (5.5.0-12ubuntu1) ...\n",
            "Setting up gcc-5 (5.5.0-12ubuntu1) ...\n",
            "Setting up g++-5 (5.5.0-12ubuntu1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXSkQprZJ-5s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ln -sf /usr/bin/gcc-5 /usr/bin/gcc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65EGZX5BKCoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " !ln -sf /usr/bin/g++-5 /usr/bin/g++"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qi_9A-KpJ51q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!export CPATH=/usr/local/cuda/include:$CPATH"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBK8e-n5KJmq",
        "colab_type": "code",
        "outputId": "5d422322-cbf6-436e-f7a2-83908f9bcaca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "!pip install  torch-cluster==latest+cu101 torch-spline-conv==latest+cu101  torch-scatter==latest+cu101 torch-sparse==latest+cu101 -f https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.5.0.html"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://s3.eu-central-1.amazonaws.com/pytorch-geometric.com/whl/torch-1.5.0.html\n",
            "Collecting torch-cluster==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.5.0/torch_cluster-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (18.2MB)\n",
            "\u001b[K     |████████████████████████████████| 18.2MB 167kB/s \n",
            "\u001b[?25hCollecting torch-spline-conv==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.5.0/torch_spline_conv-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.3MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3MB 40.3MB/s \n",
            "\u001b[?25hCollecting torch-scatter==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.5.0/torch_scatter-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (12.2MB)\n",
            "\u001b[K     |████████████████████████████████| 12.3MB 5.4MB/s \n",
            "\u001b[?25hCollecting torch-sparse==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.5.0/torch_sparse-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (24.4MB)\n",
            "\u001b[K     |████████████████████████████████| 24.4MB 59kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-cluster==latest+cu101) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-cluster==latest+cu101) (1.18.4)\n",
            "Installing collected packages: torch-cluster, torch-spline-conv, torch-scatter, torch-sparse\n",
            "Successfully installed torch-cluster-1.5.4 torch-scatter-2.0.4 torch-sparse-0.6.4 torch-spline-conv-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QhmUyy3OxSA",
        "colab_type": "code",
        "outputId": "b7c5f02f-304f-4ebd-d735-f33f2db51542",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        }
      },
      "source": [
        "!pip install torch-geometric"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch-geometric\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/f2/26359fb7b50d54924ddd23778d4830b2653df9ffe72f85caad2b829dc778/torch_geometric-1.5.0.tar.gz (153kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.5.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.18.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (4.41.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.48.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.23.0)\n",
            "Collecting plyfile\n",
            "  Downloading https://files.pythonhosted.org/packages/93/c8/cf47848cd4d661850e4a8e7f0fc4f7298515e06d0da7255ed08e5312d4aa/plyfile-0.7.2-py3-none-any.whl\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.0.3)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 8.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.10.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.4)\n",
            "Collecting ase\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/70/a8b1a7831193aa228defd805891c534d3e4717c8988147522e673458ddce/ase-3.19.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 13.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torch-geometric) (0.16.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch-geometric) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch-geometric) (0.15.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (46.3.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (0.31.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2.8.1)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (1.12.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (2.4.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from ase->torch-geometric) (3.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->ase->torch-geometric) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->ase->torch-geometric) (1.2.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.5.0-cp36-none-any.whl size=267918 sha256=315de23c4305ec8cb91d1045414a6e2e320ba70b929663cbc9b3429bbdf68624\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/51/31/5786f2ac419ee312f22d4d2877da05f20e7f2d430e22917daf\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: plyfile, isodate, rdflib, ase, torch-geometric\n",
            "Successfully installed ase-3.19.1 isodate-0.6.0 plyfile-0.7.2 rdflib-5.0.0 torch-geometric-1.5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1D-3usfvRC8X",
        "colab_type": "code",
        "outputId": "c1758a9e-d67d-4857-f92c-90a23f565ef8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Installing dependencies for RDKit\n",
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!time bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!time conda install -q -y -c conda-forge rdkit"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-26 00:49:03--  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.200.79, 104.18.201.79, 2606:4700::6812:c84f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.200.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh [following]\n",
            "--2020-05-26 00:49:03--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.131.3, 104.16.130.3, 2606:4700::6810:8303, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.131.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 85055499 (81M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’\n",
            "\n",
            "Miniconda3-latest-L 100%[===================>]  81.12M   182MB/s    in 0.4s    \n",
            "\n",
            "2020-05-26 00:49:03 (182 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [85055499/85055499]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - asn1crypto==1.3.0=py37_0\n",
            "    - ca-certificates==2020.1.1=0\n",
            "    - certifi==2019.11.28=py37_0\n",
            "    - cffi==1.14.0=py37h2e261b9_0\n",
            "    - chardet==3.0.4=py37_1003\n",
            "    - conda-package-handling==1.6.0=py37h7b6447c_0\n",
            "    - conda==4.8.2=py37_0\n",
            "    - cryptography==2.8=py37h1ba5d50_0\n",
            "    - idna==2.8=py37_0\n",
            "    - ld_impl_linux-64==2.33.1=h53a641e_7\n",
            "    - libedit==3.1.20181209=hc058e9b_0\n",
            "    - libffi==3.2.1=hd88cf55_4\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - ncurses==6.2=he6710b0_0\n",
            "    - openssl==1.1.1d=h7b6447c_4\n",
            "    - pip==20.0.2=py37_1\n",
            "    - pycosat==0.6.3=py37h7b6447c_0\n",
            "    - pycparser==2.19=py37_0\n",
            "    - pyopenssl==19.1.0=py37_0\n",
            "    - pysocks==1.7.1=py37_0\n",
            "    - python==3.7.6=h0371630_2\n",
            "    - readline==7.0=h7b6447c_5\n",
            "    - requests==2.22.0=py37_1\n",
            "    - ruamel_yaml==0.15.87=py37h7b6447c_0\n",
            "    - setuptools==45.2.0=py37_0\n",
            "    - six==1.14.0=py37_0\n",
            "    - sqlite==3.31.1=h7b6447c_0\n",
            "    - tk==8.6.8=hbc83047_0\n",
            "    - tqdm==4.42.1=py_0\n",
            "    - urllib3==1.25.8=py37_0\n",
            "    - wheel==0.34.2=py37_0\n",
            "    - xz==5.2.4=h14c3975_4\n",
            "    - yaml==0.1.7=had09818_2\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  asn1crypto         pkgs/main/linux-64::asn1crypto-1.3.0-py37_0\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2020.1.1-0\n",
            "  certifi            pkgs/main/linux-64::certifi-2019.11.28-py37_0\n",
            "  cffi               pkgs/main/linux-64::cffi-1.14.0-py37h2e261b9_0\n",
            "  chardet            pkgs/main/linux-64::chardet-3.0.4-py37_1003\n",
            "  conda              pkgs/main/linux-64::conda-4.8.2-py37_0\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.6.0-py37h7b6447c_0\n",
            "  cryptography       pkgs/main/linux-64::cryptography-2.8-py37h1ba5d50_0\n",
            "  idna               pkgs/main/linux-64::idna-2.8-py37_0\n",
            "  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.33.1-h53a641e_7\n",
            "  libedit            pkgs/main/linux-64::libedit-3.1.20181209-hc058e9b_0\n",
            "  libffi             pkgs/main/linux-64::libffi-3.2.1-hd88cf55_4\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.2-he6710b0_0\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1d-h7b6447c_4\n",
            "  pip                pkgs/main/linux-64::pip-20.0.2-py37_1\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py37h7b6447c_0\n",
            "  pycparser          pkgs/main/linux-64::pycparser-2.19-py37_0\n",
            "  pyopenssl          pkgs/main/linux-64::pyopenssl-19.1.0-py37_0\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py37_0\n",
            "  python             pkgs/main/linux-64::python-3.7.6-h0371630_2\n",
            "  readline           pkgs/main/linux-64::readline-7.0-h7b6447c_5\n",
            "  requests           pkgs/main/linux-64::requests-2.22.0-py37_1\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.87-py37h7b6447c_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-45.2.0-py37_0\n",
            "  six                pkgs/main/linux-64::six-1.14.0-py37_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.31.1-h7b6447c_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.8-hbc83047_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.42.1-py_0\n",
            "  urllib3            pkgs/main/linux-64::urllib3-1.25.8-py37_0\n",
            "  wheel              pkgs/main/linux-64::wheel-0.34.2-py37_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.4-h14c3975_4\n",
            "  yaml               pkgs/main/linux-64::yaml-0.1.7-had09818_2\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n",
            "\n",
            "\n",
            "Preparing transaction: | \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "\n",
            "real\t0m23.411s\n",
            "user\t0m7.995s\n",
            "sys\t0m4.541s\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    boost-1.72.0               |   py37h9de70de_0         316 KB  conda-forge\n",
            "    boost-cpp-1.72.0           |       h8e57a91_0        21.8 MB  conda-forge\n",
            "    bzip2-1.0.8                |       h516909a_2         396 KB  conda-forge\n",
            "    ca-certificates-2020.4.5.1 |       hecc5488_0         146 KB  conda-forge\n",
            "    cairo-1.16.0               |    hcf35c78_1003         1.5 MB  conda-forge\n",
            "    certifi-2020.4.5.1         |   py37hc8dfbb8_0         151 KB  conda-forge\n",
            "    conda-4.8.3                |   py37hc8dfbb8_1         3.0 MB  conda-forge\n",
            "    fontconfig-2.13.1          |    h86ecdb6_1001         340 KB  conda-forge\n",
            "    freetype-2.10.2            |       he06d7ca_0         905 KB  conda-forge\n",
            "    gettext-0.19.8.1           |    hc5be6a0_1002         3.6 MB  conda-forge\n",
            "    glib-2.64.3                |       h6f030ca_0         3.4 MB  conda-forge\n",
            "    icu-64.2                   |       he1b5a44_1        12.6 MB  conda-forge\n",
            "    jpeg-9c                    |    h14c3975_1001         251 KB  conda-forge\n",
            "    libblas-3.8.0              |      14_openblas          10 KB  conda-forge\n",
            "    libcblas-3.8.0             |      14_openblas          10 KB  conda-forge\n",
            "    libgfortran-ng-7.5.0       |       hdf63c60_6         1.7 MB  conda-forge\n",
            "    libiconv-1.15              |    h516909a_1006         2.0 MB  conda-forge\n",
            "    liblapack-3.8.0            |      14_openblas          10 KB  conda-forge\n",
            "    libopenblas-0.3.7          |       h5ec1e0e_6         7.6 MB  conda-forge\n",
            "    libpng-1.6.37              |       hed695b0_1         308 KB  conda-forge\n",
            "    libtiff-4.1.0              |       hc7e4089_6         668 KB  conda-forge\n",
            "    libuuid-2.32.1             |    h14c3975_1000          26 KB  conda-forge\n",
            "    libwebp-base-1.1.0         |       h516909a_3         845 KB  conda-forge\n",
            "    libxcb-1.13                |    h14c3975_1002         396 KB  conda-forge\n",
            "    libxml2-2.9.10             |       hee79883_0         1.3 MB  conda-forge\n",
            "    lz4-c-1.8.3                |    he1b5a44_1001         187 KB  conda-forge\n",
            "    numpy-1.18.4               |   py37h8960a57_0         5.2 MB  conda-forge\n",
            "    olefile-0.46               |             py_0          31 KB  conda-forge\n",
            "    openssl-1.1.1g             |       h516909a_0         2.1 MB  conda-forge\n",
            "    pandas-1.0.3               |   py37h0da4684_1        11.1 MB  conda-forge\n",
            "    pcre-8.44                  |       he1b5a44_0         261 KB  conda-forge\n",
            "    pillow-7.1.2               |   py37hb39fc2d_0         603 KB\n",
            "    pixman-0.38.0              |    h516909a_1003         594 KB  conda-forge\n",
            "    pthread-stubs-0.4          |    h14c3975_1001           5 KB  conda-forge\n",
            "    pycairo-1.19.1             |   py37h01af8b0_3          77 KB  conda-forge\n",
            "    python-dateutil-2.8.1      |             py_0         220 KB  conda-forge\n",
            "    python_abi-3.7             |          1_cp37m           4 KB  conda-forge\n",
            "    pytz-2020.1                |     pyh9f0ad1d_0         227 KB  conda-forge\n",
            "    rdkit-2020.03.2            |   py37hdd87690_0        24.7 MB  conda-forge\n",
            "    xorg-kbproto-1.0.7         |    h14c3975_1002          26 KB  conda-forge\n",
            "    xorg-libice-1.0.10         |       h516909a_0          57 KB  conda-forge\n",
            "    xorg-libsm-1.2.3           |    h84519dc_1000          25 KB  conda-forge\n",
            "    xorg-libx11-1.6.9          |       h516909a_0         918 KB  conda-forge\n",
            "    xorg-libxau-1.0.9          |       h14c3975_0          13 KB  conda-forge\n",
            "    xorg-libxdmcp-1.1.3        |       h516909a_0          18 KB  conda-forge\n",
            "    xorg-libxext-1.3.4         |       h516909a_0          51 KB  conda-forge\n",
            "    xorg-libxrender-0.9.10     |    h516909a_1002          31 KB  conda-forge\n",
            "    xorg-renderproto-0.11.1    |    h14c3975_1002           8 KB  conda-forge\n",
            "    xorg-xextproto-7.3.0       |    h14c3975_1002          27 KB  conda-forge\n",
            "    xorg-xproto-7.0.31         |    h14c3975_1007          72 KB  conda-forge\n",
            "    zstd-1.4.4                 |       h3b9ef0a_2         982 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       110.8 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  boost              conda-forge/linux-64::boost-1.72.0-py37h9de70de_0\n",
            "  boost-cpp          conda-forge/linux-64::boost-cpp-1.72.0-h8e57a91_0\n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h516909a_2\n",
            "  cairo              conda-forge/linux-64::cairo-1.16.0-hcf35c78_1003\n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.13.1-h86ecdb6_1001\n",
            "  freetype           conda-forge/linux-64::freetype-2.10.2-he06d7ca_0\n",
            "  gettext            conda-forge/linux-64::gettext-0.19.8.1-hc5be6a0_1002\n",
            "  glib               conda-forge/linux-64::glib-2.64.3-h6f030ca_0\n",
            "  icu                conda-forge/linux-64::icu-64.2-he1b5a44_1\n",
            "  jpeg               conda-forge/linux-64::jpeg-9c-h14c3975_1001\n",
            "  libblas            conda-forge/linux-64::libblas-3.8.0-14_openblas\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.8.0-14_openblas\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-7.5.0-hdf63c60_6\n",
            "  libiconv           conda-forge/linux-64::libiconv-1.15-h516909a_1006\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.8.0-14_openblas\n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.7-h5ec1e0e_6\n",
            "  libpng             conda-forge/linux-64::libpng-1.6.37-hed695b0_1\n",
            "  libtiff            conda-forge/linux-64::libtiff-4.1.0-hc7e4089_6\n",
            "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h14c3975_1000\n",
            "  libwebp-base       conda-forge/linux-64::libwebp-base-1.1.0-h516909a_3\n",
            "  libxcb             conda-forge/linux-64::libxcb-1.13-h14c3975_1002\n",
            "  libxml2            conda-forge/linux-64::libxml2-2.9.10-hee79883_0\n",
            "  lz4-c              conda-forge/linux-64::lz4-c-1.8.3-he1b5a44_1001\n",
            "  numpy              conda-forge/linux-64::numpy-1.18.4-py37h8960a57_0\n",
            "  olefile            conda-forge/noarch::olefile-0.46-py_0\n",
            "  pandas             conda-forge/linux-64::pandas-1.0.3-py37h0da4684_1\n",
            "  pcre               conda-forge/linux-64::pcre-8.44-he1b5a44_0\n",
            "  pillow             pkgs/main/linux-64::pillow-7.1.2-py37hb39fc2d_0\n",
            "  pixman             conda-forge/linux-64::pixman-0.38.0-h516909a_1003\n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h14c3975_1001\n",
            "  pycairo            conda-forge/linux-64::pycairo-1.19.1-py37h01af8b0_3\n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.1-py_0\n",
            "  python_abi         conda-forge/linux-64::python_abi-3.7-1_cp37m\n",
            "  pytz               conda-forge/noarch::pytz-2020.1-pyh9f0ad1d_0\n",
            "  rdkit              conda-forge/linux-64::rdkit-2020.03.2-py37hdd87690_0\n",
            "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-h14c3975_1002\n",
            "  xorg-libice        conda-forge/linux-64::xorg-libice-1.0.10-h516909a_0\n",
            "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.3-h84519dc_1000\n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.6.9-h516909a_0\n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.9-h14c3975_0\n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h516909a_0\n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h516909a_0\n",
            "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.10-h516909a_1002\n",
            "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-h14c3975_1002\n",
            "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-h14c3975_1002\n",
            "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-h14c3975_1007\n",
            "  zstd               conda-forge/linux-64::zstd-1.4.4-h3b9ef0a_2\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates     pkgs/main::ca-certificates-2020.1.1-0 --> conda-forge::ca-certificates-2020.4.5.1-hecc5488_0\n",
            "  certifi              pkgs/main::certifi-2019.11.28-py37_0 --> conda-forge::certifi-2020.4.5.1-py37hc8dfbb8_0\n",
            "  conda                       pkgs/main::conda-4.8.2-py37_0 --> conda-forge::conda-4.8.3-py37hc8dfbb8_1\n",
            "  openssl              pkgs/main::openssl-1.1.1d-h7b6447c_4 --> conda-forge::openssl-1.1.1g-h516909a_0\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "\n",
            "real\t0m44.244s\n",
            "user\t0m37.270s\n",
            "sys\t0m4.999s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBHf1EeYrARY",
        "colab_type": "text"
      },
      "source": [
        "## Input retrieval "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIqiCfVdRKHI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Imh4PiQ-RvcI",
        "colab_type": "code",
        "outputId": "0ead4782-1f92-4aa8-99cc-9a0a0243d1f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adcjwaHnT3LR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root = \"/content/drive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VzXxU3TFJhsX",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "def get_data(split):\n",
        "    data_path =root +\"QM9_Smiles_sorted.csv\"\n",
        "    with open(data_path) as f:\n",
        "        data = csv.reader(f)\n",
        "    \n",
        "        # Skip header\n",
        "        next(data)\n",
        "        \n",
        "        # Get smiles and targets\n",
        "        smiles, Y = [], []\n",
        "        count=0\n",
        "        for row in data:\n",
        "            if (count<120000):\n",
        "              smiles.append(row[12])\n",
        "              Y.append(row)\n",
        "              count=count+1\n",
        "    \n",
        "    return smiles, Y\n",
        "\n",
        "AllSmiles, All = get_data('train')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G2fAhd61rJDo",
        "colab_type": "text"
      },
      "source": [
        "## Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e05y6j4U_aTX",
        "colab_type": "code",
        "outputId": "0a44e19c-d551-4b18-fb98-ff59389a5924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Define vocab\n",
        "vocab = {char for smiles in AllSmiles for char in smiles}\n",
        "\n",
        "print(f'Vocab = {vocab}')\n",
        "\n",
        "# Create word to index mapping\n",
        "padding_idx = 0\n",
        "char_to_index = {char: index + 1 for index, char in enumerate(vocab)}\n",
        "vocab_size = len(char_to_index) + 1\n",
        "\n",
        "print(f'Vocab size = {vocab_size:,}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab = {'2', 'N', ')', '+', ']', '-', '4', '=', 'C', '(', '[', '3', 'H', 'F', 'O', '#', '5', '1'}\n",
            "Vocab size = 19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ct9TWFs5BUDj",
        "colab_type": "code",
        "outputId": "8753cfa9-13e5-414d-de60-ed1813621e64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "char_to_index "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'#': 16,\n",
              " '(': 10,\n",
              " ')': 3,\n",
              " '+': 4,\n",
              " '-': 6,\n",
              " '1': 18,\n",
              " '2': 1,\n",
              " '3': 12,\n",
              " '4': 7,\n",
              " '5': 17,\n",
              " '=': 8,\n",
              " 'C': 9,\n",
              " 'F': 14,\n",
              " 'H': 13,\n",
              " 'N': 2,\n",
              " 'O': 15,\n",
              " '[': 11,\n",
              " ']': 5}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ay-EZNkOsC5l",
        "colab_type": "text"
      },
      "source": [
        "## Map Characters to Indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diYSFQaLBPEF",
        "colab_type": "code",
        "outputId": "f84cfe5e-abed-47b7-9366-e7db15e1985c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "biggest_mol_size = max([len(smiles) for smiles in AllSmiles])\n",
        "print(\"Total number of smiles= \", len(AllSmiles))\n",
        "print(\"size of largest molecule = \", biggest_mol_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of smiles=  120000\n",
            "size of largest molecule =  28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9onqBc5oC0mI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = [[char_to_index[char] for char in smiles] for smiles in AllSmiles]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCKdVTGosK0b",
        "colab_type": "text"
      },
      "source": [
        "## Add Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APZwCLc4HZm0",
        "colab_type": "code",
        "outputId": "2c82bde6-b470-4f0a-9422-b7ae17560bf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#add all elemnets the pad with os at the end so that they have the same length\n",
        "max_len = 26\n",
        "Smiles = [seq[:max_len] + [padding_idx] * (max_len - len(seq)) for seq in X]\n",
        "\n",
        "print(f'Smiles string = {AllSmiles[0]}')\n",
        "print(f'Indices of first train SMILES = {Smiles[0]}')\n",
        "print(f'Last five indices = {Smiles[0][-5:]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Smiles string = C\n",
            "Indices of first train SMILES = [9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Last five indices = [0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zchG9qCosQSO",
        "colab_type": "text"
      },
      "source": [
        "## Infomax.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0ul85-SFo8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Infomax.py\n",
        "import torch\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def log_sum_exp(x, axis=None):\n",
        "    \"\"\"Log sum exp function\n",
        "    Args:\n",
        "        x: Input.\n",
        "        axis: Axis over which to perform sum.\n",
        "    Returns:\n",
        "        torch.Tensor: log sum exp\n",
        "    \"\"\"\n",
        "    x_max = torch.max(x, axis)[0]\n",
        "    y = torch.log((torch.exp(x - x_max)).sum(axis)) + x_max\n",
        "    return y\n",
        "\n",
        "def random_permute(X):\n",
        "    \"\"\"Randomly permutes a tensor.\n",
        "    Args:\n",
        "        X: Input tensor.\n",
        "    Returns:\n",
        "        torch.Tensor\n",
        "    \"\"\"\n",
        "    X = X.transpose(1, 2)\n",
        "    b = torch.rand((X.size(0), X.size(1))).cuda()\n",
        "    idx = b.sort(0)[1]\n",
        "    adx = torch.range(0, X.size(1) - 1).long()\n",
        "    X = X[idx, adx[None, :]].transpose(1, 2)\n",
        "    return X\n",
        "\n",
        "def get_positive_expectation(p_samples, measure, average=True):\n",
        "    \"\"\"Computes the positive part of a divergence / difference.\n",
        "    Args:\n",
        "        p_samples: Positive samples.\n",
        "        measure: Measure to compute for.\n",
        "        average: Average the result over samples.\n",
        "    Returns:\n",
        "        torch.Tensor\n",
        "    \"\"\"\n",
        "    log_2 = math.log(2.)\n",
        "\n",
        "    if measure == 'GAN':\n",
        "        Ep = - F.softplus(-p_samples)\n",
        "    elif measure == 'JSD':\n",
        "        Ep = log_2 - F.softplus(- p_samples)\n",
        "    elif measure == 'X2':\n",
        "        Ep = p_samples ** 2\n",
        "    elif measure == 'KL':\n",
        "        Ep = p_samples + 1.\n",
        "    elif measure == 'RKL':\n",
        "        Ep = -torch.exp(-p_samples)\n",
        "    elif measure == 'DV':\n",
        "        Ep = p_samples\n",
        "    elif measure == 'H2':\n",
        "        Ep = 1. - torch.exp(-p_samples)\n",
        "    elif measure == 'W1':\n",
        "        Ep = p_samples\n",
        "    else:\n",
        "        raise_measure_error(measure)\n",
        "\n",
        "    if average:\n",
        "        return Ep.mean()\n",
        "    else:\n",
        "        return Ep\n",
        "\n",
        "\n",
        "def get_negative_expectation(q_samples, measure, average=True):\n",
        "    \"\"\"Computes the negative part of a divergence / difference.\n",
        "    Args:\n",
        "        q_samples: Negative samples.\n",
        "        measure: Measure to compute for.\n",
        "        average: Average the result over samples.\n",
        "    Returns:\n",
        "        torch.Tensor\n",
        "    \"\"\"\n",
        "    log_2 = math.log(2.)\n",
        "\n",
        "    if measure == 'GAN':\n",
        "        Eq = F.softplus(-q_samples) + q_samples\n",
        "    elif measure == 'JSD':\n",
        "        Eq = F.softplus(-q_samples) + q_samples - log_2\n",
        "    elif measure == 'X2':\n",
        "        Eq = -0.5 * ((torch.sqrt(q_samples ** 2) + 1.) ** 2)\n",
        "    elif measure == 'KL':\n",
        "        Eq = torch.exp(q_samples)\n",
        "    elif measure == 'RKL':\n",
        "        Eq = q_samples - 1.\n",
        "    elif measure == 'DV':\n",
        "        Eq = log_sum_exp(q_samples, 0) - math.log(q_samples.size(0))\n",
        "    elif measure == 'H2':\n",
        "        Eq = torch.exp(q_samples) - 1.\n",
        "    elif measure == 'W1':\n",
        "        Eq = q_samples\n",
        "    else:\n",
        "        raise_measure_error(measure)\n",
        "\n",
        "    if average:\n",
        "        return Eq.mean()\n",
        "    else:\n",
        "        return Eq\n",
        "\n",
        "def local_global_loss_(l_enc, g_enc, edge_index, batch, measure):\n",
        "    '''\n",
        "    Args:\n",
        "        l: Local feature map.\n",
        "        g: Global features.\n",
        "        measure: Type of f-divergence. For use with mode `fd`\n",
        "        mode: Loss mode. Fenchel-dual `fd`, NCE `nce`, or Donsker-Vadadhan `dv`.\n",
        "    Returns:\n",
        "        torch.Tensor: Loss.\n",
        "    '''\n",
        "    num_graphs = g_enc.shape[0]\n",
        "    num_nodes = l_enc.shape[0]\n",
        "\n",
        "    pos_mask = torch.zeros((num_nodes, num_graphs)).cuda()\n",
        "    neg_mask = torch.ones((num_nodes, num_graphs)).cuda()\n",
        "    for nodeidx, graphidx in enumerate(batch):\n",
        "        pos_mask[nodeidx][graphidx] = 1.\n",
        "        neg_mask[nodeidx][graphidx] = 0.\n",
        "\n",
        "    res = torch.mm(l_enc, g_enc.t())\n",
        "\n",
        "    E_pos = get_positive_expectation(res * pos_mask, measure, average=False)\n",
        "    E_pos = (E_pos * pos_mask).sum() / pos_mask.sum()\n",
        "    E_neg = get_negative_expectation(res * neg_mask, measure, average=False)\n",
        "    E_neg = (E_neg * neg_mask).sum() / neg_mask.sum()\n",
        "\n",
        "    return E_neg - E_pos\n",
        "\n",
        "def global_global_loss_(g_enc, g_enc1, edge_index, batch, measure):\n",
        "    '''\n",
        "    Args:\n",
        "        g: Global features\n",
        "        g1: Global features.\n",
        "        measure: Type of f-divergence. For use with mode `fd`\n",
        "        mode: Loss mode. Fenchel-dual `fd`, NCE `nce`, or Donsker-Vadadhan `dv`.\n",
        "    Returns:\n",
        "        torch.Tensor: Loss.\n",
        "    '''\n",
        "    num_graphs = g_enc.shape[0]\n",
        "\n",
        "    pos_mask = torch.eye(num_graphs).cuda()\n",
        "    neg_mask = 1 - pos_mask\n",
        "    res = torch.mm(g_enc, g_enc1.t())\n",
        "\n",
        "    E_pos = get_positive_expectation(res * pos_mask, measure, average=False)\n",
        "    E_pos = (E_pos * pos_mask).sum() / pos_mask.sum()\n",
        "    E_neg = get_negative_expectation(res * neg_mask, measure, average=False)\n",
        "    E_neg = (E_neg * neg_mask).sum() / neg_mask.sum()\n",
        "\n",
        "\n",
        "    return  E_neg - E_pos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P08COmYZsXxv",
        "colab_type": "text"
      },
      "source": [
        "# LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m8fruMAUUSG6",
        "colab": {}
      },
      "source": [
        "#LSTM_Model.py\n",
        "import os.path as osp\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size=vocab_size, padding_idx=padding_idx , embedding_size=1, hidden_size=64, output_size=1,max_len=26):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        \n",
        "        # Embedding layer\n",
        "        self.embed = nn.Embedding(vocab_size, embedding_size, padding_idx=padding_idx)\n",
        "        \n",
        "        # LSTM (RNN)\n",
        "        self.rnn = nn.LSTM(\n",
        "            input_size=embedding_size,\n",
        "            hidden_size=hidden_size,\n",
        "            batch_first=True\n",
        "        )\n",
        "        \n",
        "        # Fully connected layer\n",
        "        #self.output = nn.Linear(hidden_size, output_size)\n",
        " \n",
        "        \n",
        "    def forward(self, data):  # batch_size x seq_length\n",
        "      \n",
        "        input=np.asarray(data.smiles)\n",
        "        out=torch.from_numpy(input).to(device)\n",
        "\n",
        "        out=out.reshape(out.shape[0],max_len)\n",
        "        embedded = self.embed(out)\n",
        "        # Run RNN\n",
        "        o, _ = self.rnn(embedded) \n",
        "\n",
        "        # Max pooling across sequence\n",
        "        y, _ = torch.max(o, dim=1)    \n",
        "        \n",
        "        # Output layer\n",
        "       # out = self.output(o)  \n",
        "        \n",
        "        return y,o # Means return y and the feature map "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFSMQUnGsejY",
        "colab_type": "text"
      },
      "source": [
        "## Model.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBPB-lTYE8SB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model.py\n",
        "import os.path as osp\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Sequential, Linear, ReLU, GRU\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import NNConv, Set2Set\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.utils import remove_self_loops\n",
        "\n",
        "#from infomax import *\n",
        "\n",
        "class Encoder(torch.nn.Module):\n",
        "    def __init__(self, num_features, dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.lin0 = torch.nn.Linear(num_features, dim)\n",
        "\n",
        "        nn = Sequential(Linear(5, 128), ReLU(), Linear(128, dim * dim))\n",
        "        self.conv = NNConv(dim, dim, nn, aggr='mean', root_weight=False)\n",
        "        self.gru = GRU(dim, dim)\n",
        "\n",
        "        self.set2set = Set2Set(dim, processing_steps=3)\n",
        "\n",
        "\n",
        "    def forward(self, data):\n",
        "        out = F.relu(self.lin0(data.x))\n",
        "        h = out.unsqueeze(0)\n",
        "\n",
        "        feat_map = []\n",
        "        for i in range(3):\n",
        "            m = F.relu(self.conv(out, data.edge_index, data.edge_attr))\n",
        "            out, h = self.gru(m.unsqueeze(0), h)\n",
        "            out = out.squeeze(0)\n",
        "            # print(out.shape) : [num_node x dim]\n",
        "            feat_map.append(out)\n",
        "\n",
        "        out = self.set2set(out, data.batch)\n",
        "        return out, feat_map[-1]\n",
        "\n",
        "    \n",
        "    def get_embeddings(self, loader):\n",
        "\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        ret = []\n",
        "        y = []\n",
        "        with torch.no_grad():\n",
        "            for data in loader:\n",
        "                data.to(device)\n",
        "                x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "                if x is None:\n",
        "                    x = torch.ones((batch.shape[0],1)).to(device)   \n",
        "                x, _ = self.forward(data)\n",
        "                ret.append(x.cpu().numpy())\n",
        "                y.append(data.y.cpu().numpy())\n",
        "        ret = np.concatenate(ret, 0)\n",
        "        y = np.concatenate(y, 0)\n",
        "        return ret, y        \n",
        "\n",
        "\n",
        "class FF(nn.Module):\n",
        "    def __init__(self, input_dim, dim):\n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Linear(input_dim, dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(dim, dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.linear_shortcut = nn.Linear(input_dim, dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x) + self.linear_shortcut(x)\n",
        "   \n",
        "\n",
        "class FF_LSTM(nn.Module):\n",
        "    def __init__(self, input_dim, dim):\n",
        "        super().__init__()     \n",
        "        self.output = nn.Linear(input_dim, dim)\n",
        "    def forward(self, x):\n",
        "        return self.output(x)\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, num_features, dim, use_unsup_loss=False, separate_encoder=False):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.embedding_dim = dim\n",
        "\n",
        "        self.local = True\n",
        "\n",
        "        self.lstm_encoder = LSTMModel()\n",
        "        self.unsup_encoder = Encoder(num_features, dim)\n",
        "        \n",
        "        self.global_d = FF(2*dim, dim)\n",
        "        self.global_s = FF_LSTM(dim, dim)\n",
        "\n",
        "        # For local global\n",
        "        self.local_g = FF(dim, dim)\n",
        "        self.global_g = FF(2*dim, dim)\n",
        "\n",
        "        self.init_emb()\n",
        "\n",
        "    def init_emb(self):\n",
        "      initrange = -1.5 / self.embedding_dim\n",
        "      for m in self.modules():\n",
        "          if isinstance(m, nn.Linear):\n",
        "              torch.nn.init.xavier_uniform_(m.weight.data)\n",
        "              if m.bias is not None:\n",
        "                  m.bias.data.fill_(0.0)\n",
        "\n",
        "# Applied changes here\n",
        "    def forward(self, data):\n",
        "\n",
        "    # batch_size = data.num_graphs\n",
        "      if data.x is None:\n",
        "         data.x  = torch.ones(data.batch.shape[0]).to(device)\n",
        "\n",
        "      y, M = self.unsup_encoder(data)\n",
        "      y_, M_ = self.lstm_encoder(data)\n",
        "    \n",
        "      g_enc = self.global_d(y)\n",
        "      s_enc = self.global_s(y_) #smiles encoder \n",
        "\n",
        "      mode='fd'\n",
        "      measure='JSD'\n",
        "      global_global_loss = global_global_loss_(g_enc, s_enc, data.edge_index, data.batch, measure)\n",
        "    \n",
        "      return global_global_loss\n",
        "\n",
        "    def forward_local_global(self, data):\n",
        "      y, M = self.unsup_encoder(data)\n",
        "    \n",
        "      g_enc = self.global_g(y)\n",
        "      l_enc = self.local_g(M) #smiles encoder # this is wrong \n",
        "\n",
        "      mode='fd'\n",
        "      measure='JSD'\n",
        "      local_global_loss = local_global_loss_(l_enc, g_enc, data.edge_index, data.batch, measure)\n",
        "    \n",
        "      return local_global_loss      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOtnqzyDs17b",
        "colab_type": "text"
      },
      "source": [
        "## Evaluate_embeddings.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3GnCQft49pj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Evaluate embedding class \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV \n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\"\"\"Evaluates latent space quality via a linear regression downstream task.\"\"\"\n",
        "def linear_reg(X,Y,std):\n",
        "\n",
        "  X_train, X_test_validate, y_train, y_test_validate = train_test_split(X, Y, test_size=0.4, random_state=101)\n",
        "  X_valid, X_test, y_valid, y_test = train_test_split(X_test_validate, y_test_validate, test_size=0.5, random_state=101)\n",
        "  params = { 'kernel':['laplacian'],'alpha':[0.001, 0.01,0.1,1,10,100]}\n",
        "  clf = GridSearchCV(KernelRidge(), params, cv=5)\n",
        "  #clf = KernelRidge(alpha=1.0, kernel='laplacian',)\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred=clf.predict(X_test)\n",
        "  y_predv=clf.predict(X_valid)\n",
        "  maet = mean_absolute_error(y_test,y_pred)*std \n",
        "  maev = mean_absolute_error(y_valid,y_predv)*std \n",
        "  print('Kernel Ridge Regression Mae validation : {}'.format(maev))\n",
        "  print('Kernel Ridge Regression Mae testing : {}'.format(maet))\n",
        "  return maet\n",
        "\n",
        "\n",
        "def evaluate_embedding(embeddings, labels, std):\n",
        "    x, y = np.array(embeddings), np.array(labels)\n",
        "    print(x.shape, y.shape)\n",
        "\n",
        "    linreg_accuracies = [linear_reg(x, y, std) for _ in range(1)]\n",
        "    #print('LinReg', np.mean(linreg_accuracies))\n",
        "\n",
        "    return np.mean(linreg_accuracies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZbgZv1PtevZ",
        "colab_type": "text"
      },
      "source": [
        "## Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duLpcEnJg0V-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Sequential, Linear, ReLU, GRU\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import  Set2Set\n",
        "from torch_geometric.utils import remove_self_loops\n",
        "\n",
        "target = 0\n",
        "dim = 64\n",
        "\n",
        "\n",
        "class MyTransform(object):\n",
        "    def __call__(self, data):\n",
        "        # Specify target.\n",
        "        data.y = data.y[:, target]\n",
        "        return data\n",
        "\n",
        "\n",
        "class Complete(object):\n",
        "    def __call__(self, data):\n",
        "        device = data.edge_index.device\n",
        "\n",
        "        row = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
        "        col = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
        "\n",
        "        row = row.view(-1, 1).repeat(1, data.num_nodes).view(-1)\n",
        "        col = col.repeat(data.num_nodes)\n",
        "        edge_index = torch.stack([row, col], dim=0)\n",
        "\n",
        "        edge_attr = None\n",
        "        if data.edge_attr is not None:\n",
        "            idx = data.edge_index[0] * data.num_nodes + data.edge_index[1]\n",
        "            size = list(data.edge_attr.size())\n",
        "            size[0] = data.num_nodes * data.num_nodes\n",
        "            edge_attr = data.edge_attr.new_zeros(size)\n",
        "            edge_attr[idx] = data.edge_attr\n",
        "\n",
        "        edge_index, edge_attr = remove_self_loops(edge_index, edge_attr)\n",
        "        data.edge_attr = edge_attr\n",
        "        data.edge_index = edge_index\n",
        "\n",
        "        return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFQWgVbvtkBv",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## PyTorch Geometric Data class modification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaTOroga7q1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Modify to add smile strings \n",
        "import re\n",
        "import copy\n",
        "import warnings\n",
        "\n",
        "import torch\n",
        "import torch_geometric\n",
        "from torch_sparse import coalesce\n",
        "from torch_geometric.utils import (contains_isolated_nodes,\n",
        "                                   contains_self_loops, is_undirected)\n",
        "\n",
        "from torch_geometric.utils.num_nodes import maybe_num_nodes\n",
        "\n",
        "__num_nodes_warn_msg__ = (\n",
        "    'The number of nodes in your data object can only be inferred by its {} '\n",
        "    'indices, and hence may result in unexpected batch-wise behavior, e.g., '\n",
        "    'in case there exists isolated nodes. Please consider explicitly setting '\n",
        "    'the number of nodes for this data object by assigning it to '\n",
        "    'data.num_nodes.')\n",
        "\n",
        "\n",
        "def size_repr(value):\n",
        "    if torch.is_tensor(value):\n",
        "        return list(value.size())\n",
        "    elif isinstance(value, int) or isinstance(value, float):\n",
        "        return [1]\n",
        "    elif isinstance(value, list) or isinstance(value, tuple):\n",
        "        return [len(value)]\n",
        "    else:\n",
        "        return value\n",
        "\n",
        "\n",
        "class Data(object):\n",
        "    r\"\"\"A plain old python object modeling a single graph with various\n",
        "    (optional) attributes:\n",
        "    Args:\n",
        "        x (Tensor, optional): Node feature matrix with shape :obj:`[num_nodes,\n",
        "            num_node_features]`. (default: :obj:`None`)\n",
        "        edge_index (LongTensor, optional): Graph connectivity in COO format\n",
        "            with shape :obj:`[2, num_edges]`. (default: :obj:`None`)\n",
        "        edge_attr (Tensor, optional): Edge feature matrix with shape\n",
        "            :obj:`[num_edges, num_edge_features]`. (default: :obj:`None`)\n",
        "        y (Tensor, optional): Graph or node targets with arbitrary shape.\n",
        "            (default: :obj:`None`)\n",
        "        pos (Tensor, optional): Node position matrix with shape\n",
        "            :obj:`[num_nodes, num_dimensions]`. (default: :obj:`None`)\n",
        "        norm (Tensor, optional): Normal vector matrix with shape\n",
        "            :obj:`[num_nodes, num_dimensions]`. (default: :obj:`None`)\n",
        "        face (LongTensor, optional): Face adjacency matrix with shape\n",
        "            :obj:`[3, num_faces]`. (default: :obj:`None`)\n",
        "    The data object is not restricted to these attributes and can be extented\n",
        "    by any other additional data.\n",
        "    Example::\n",
        "        data = Data(x=x, edge_index=edge_index)\n",
        "        data.train_idx = torch.tensor([...], dtype=torch.long)\n",
        "        data.test_mask = torch.tensor([...], dtype=torch.bool)\n",
        "    \"\"\"\n",
        "    def __init__(self, x=None,smiles=None, edge_index=None, edge_attr=None, y=None,\n",
        "                 pos=None, norm=None, face=None, **kwargs):\n",
        "        self.x = x\n",
        "        self.smiles=smiles\n",
        "        self.edge_index = edge_index\n",
        "        self.edge_attr = edge_attr\n",
        "        self.y = y\n",
        "        self.pos = pos\n",
        "        self.norm = norm\n",
        "        self.face = face\n",
        "        for key, item in kwargs.items():\n",
        "            if key == 'num_nodes':\n",
        "                self.__num_nodes__ = item\n",
        "            else:\n",
        "                self[key] = item\n",
        "\n",
        "        if torch_geometric.is_debug_enabled():\n",
        "            self.debug()\n",
        "\n",
        "    @classmethod\n",
        "    def from_dict(cls, dictionary):\n",
        "        r\"\"\"Creates a data object from a python dictionary.\"\"\"\n",
        "        data = cls()\n",
        "\n",
        "        for key, item in dictionary.items():\n",
        "            data[key] = item\n",
        "\n",
        "        if torch_geometric.is_debug_enabled():\n",
        "            data.debug()\n",
        "\n",
        "        return data\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        r\"\"\"Gets the data of the attribute :obj:`key`.\"\"\"\n",
        "        return getattr(self, key, None)\n",
        "\n",
        "    def __setitem__(self, key, value):\n",
        "        \"\"\"Sets the attribute :obj:`key` to :obj:`value`.\"\"\"\n",
        "        setattr(self, key, value)\n",
        "\n",
        "    @property\n",
        "    def keys(self):\n",
        "        r\"\"\"Returns all names of graph attributes.\"\"\"\n",
        "        keys = [key for key in self.__dict__.keys() if self[key] is not None]\n",
        "        keys = [key for key in keys if key[:2] != '__' and key[-2:] != '__']\n",
        "        return keys\n",
        "\n",
        "    def __len__(self):\n",
        "        r\"\"\"Returns the number of all present attributes.\"\"\"\n",
        "        return len(self.keys)\n",
        "\n",
        "    def __contains__(self, key):\n",
        "        r\"\"\"Returns :obj:`True`, if the attribute :obj:`key` is present in the\n",
        "        data.\"\"\"\n",
        "        return key in self.keys\n",
        "\n",
        "    def __iter__(self):\n",
        "        r\"\"\"Iterates over all present attributes in the data, yielding their\n",
        "        attribute names and content.\"\"\"\n",
        "        for key in sorted(self.keys):\n",
        "            yield key, self[key]\n",
        "\n",
        "    def __call__(self, *keys):\n",
        "        r\"\"\"Iterates over all attributes :obj:`*keys` in the data, yielding\n",
        "        their attribute names and content.\n",
        "        If :obj:`*keys` is not given this method will iterative over all\n",
        "        present attributes.\"\"\"\n",
        "        for key in sorted(self.keys) if not keys else keys:\n",
        "            if key in self:\n",
        "                yield key, self[key]\n",
        "\n",
        "    def __cat_dim__(self, key, value):\n",
        "        r\"\"\"Returns the dimension for which :obj:`value` of attribute\n",
        "        :obj:`key` will get concatenated when creating batches.\n",
        "        .. note::\n",
        "            This method is for internal use only, and should only be overridden\n",
        "            if the batch concatenation process is corrupted for a specific data\n",
        "            attribute.\n",
        "        \"\"\"\n",
        "        # `*index*` and `*face*` should be concatenated in the last dimension,\n",
        "        # everything else in the first dimension.\n",
        "        return -1 if bool(re.search('(index|face)', key)) else 0\n",
        "\n",
        "    def __inc__(self, key, value):\n",
        "        r\"\"\"\"Returns the incremental count to cumulatively increase the value\n",
        "        of the next attribute of :obj:`key` when creating batches.\n",
        "        .. note::\n",
        "            This method is for internal use only, and should only be overridden\n",
        "            if the batch concatenation process is corrupted for a specific data\n",
        "            attribute.\n",
        "        \"\"\"\n",
        "        # Only `*index*` and `*face*` should be cumulatively summed up when\n",
        "        # creating batches.\n",
        "        return self.num_nodes if bool(re.search('(index|face)', key)) else 0\n",
        "\n",
        "    @property\n",
        "    def num_nodes(self):\n",
        "        r\"\"\"Returns or sets the number of nodes in the graph.\n",
        "        .. note::\n",
        "            The number of nodes in your data object is typically automatically\n",
        "            inferred, *e.g.*, when node features :obj:`x` are present.\n",
        "            In some cases however, a graph may only be given by its edge\n",
        "            indices :obj:`edge_index`.\n",
        "            PyTorch Geometric then *guesses* the number of nodes\n",
        "            according to :obj:`edge_index.max().item() + 1`, but in case there\n",
        "            exists isolated nodes, this number has not to be correct and can\n",
        "            therefore result in unexpected batch-wise behavior.\n",
        "            Thus, we recommend to set the number of nodes in your data object\n",
        "            explicitly via :obj:`data.num_nodes = ...`.\n",
        "            You will be given a warning that requests you to do so.\n",
        "        \"\"\"\n",
        "        if hasattr(self, '__num_nodes__'):\n",
        "            return self.__num_nodes__\n",
        "        for key, item in self('x', 'pos', 'norm', 'batch'):\n",
        "            return item.size(self.__cat_dim__(key, item))\n",
        "        if self.face is not None:\n",
        "            warnings.warn(__num_nodes_warn_msg__.format('face'))\n",
        "            return maybe_num_nodes(self.face)\n",
        "        if self.edge_index is not None:\n",
        "            warnings.warn(__num_nodes_warn_msg__.format('edge'))\n",
        "            return maybe_num_nodes(self.edge_index)\n",
        "        return None\n",
        "\n",
        "    @num_nodes.setter\n",
        "    def num_nodes(self, num_nodes):\n",
        "        self.__num_nodes__ = num_nodes\n",
        "\n",
        "    @property\n",
        "    def num_edges(self):\n",
        "        r\"\"\"Returns the number of edges in the graph.\"\"\"\n",
        "        for key, item in self('edge_index', 'edge_attr'):\n",
        "            return item.size(self.__cat_dim__(key, item))\n",
        "        return None\n",
        "\n",
        "    @property\n",
        "    def num_faces(self):\n",
        "        r\"\"\"Returns the number of faces in the mesh.\"\"\"\n",
        "        if self.face is not None:\n",
        "            return self.face.size(self.__cat_dim__('face', self.face))\n",
        "        return None\n",
        "\n",
        "    @property\n",
        "    def num_node_features(self):\n",
        "        r\"\"\"Returns the number of features per node in the graph.\"\"\"\n",
        "        if self.x is None:\n",
        "            return 0\n",
        "        return 1 if self.x.dim() == 1 else self.x.size(1)\n",
        "\n",
        "    @property\n",
        "    def num_features(self):\n",
        "        r\"\"\"Alias for :py:attr:`~num_node_features`.\"\"\"\n",
        "        return self.num_node_features\n",
        "\n",
        "    @property\n",
        "    def num_edge_features(self):\n",
        "        r\"\"\"Returns the number of features per edge in the graph.\"\"\"\n",
        "        if self.edge_attr is None:\n",
        "            return 0\n",
        "        return 1 if self.edge_attr.dim() == 1 else self.edge_attr.size(1)\n",
        "\n",
        "    def is_coalesced(self):\n",
        "        r\"\"\"Returns :obj:`True`, if edge indices are ordered and do not contain\n",
        "        duplicate entries.\"\"\"\n",
        "        edge_index, _ = coalesce(self.edge_index, None, self.num_nodes,\n",
        "                                 self.num_nodes)\n",
        "        return self.edge_index.numel() == edge_index.numel() and (\n",
        "            self.edge_index != edge_index).sum().item() == 0\n",
        "\n",
        "    def coalesce(self):\n",
        "        r\"\"\"\"Orders and removes duplicated entries from edge indices.\"\"\"\n",
        "        self.edge_index, self.edge_attr = coalesce(self.edge_index,\n",
        "                                                   self.edge_attr,\n",
        "                                                   self.num_nodes,\n",
        "                                                   self.num_nodes)\n",
        "        return self\n",
        "\n",
        "    def contains_isolated_nodes(self):\n",
        "        r\"\"\"Returns :obj:`True`, if the graph contains isolated nodes.\"\"\"\n",
        "        return contains_isolated_nodes(self.edge_index, self.num_nodes)\n",
        "\n",
        "    def contains_self_loops(self):\n",
        "        \"\"\"Returns :obj:`True`, if the graph contains self-loops.\"\"\"\n",
        "        return contains_self_loops(self.edge_index)\n",
        "\n",
        "    def is_undirected(self):\n",
        "        r\"\"\"Returns :obj:`True`, if graph edges are undirected.\"\"\"\n",
        "        return is_undirected(self.edge_index, self.edge_attr, self.num_nodes)\n",
        "\n",
        "    def is_directed(self):\n",
        "        r\"\"\"Returns :obj:`True`, if graph edges are directed.\"\"\"\n",
        "        return not self.is_undirected()\n",
        "\n",
        "    def apply(self, func, *keys):\n",
        "        r\"\"\"Applies the function :obj:`func` to all tensor attributes\n",
        "        :obj:`*keys`. If :obj:`*keys` is not given, :obj:`func` is applied to\n",
        "        all present attributes.\n",
        "        \"\"\"\n",
        "        for key, item in self(*keys):\n",
        "            if torch.is_tensor(item):\n",
        "                self[key] = func(item)\n",
        "        return self\n",
        "\n",
        "    def contiguous(self, *keys):\n",
        "        r\"\"\"Ensures a contiguous memory layout for all attributes :obj:`*keys`.\n",
        "        If :obj:`*keys` is not given, all present attributes are ensured to\n",
        "        have a contiguous memory layout.\"\"\"\n",
        "        return self.apply(lambda x: x.contiguous(), *keys)\n",
        "\n",
        "    def to(self, device, *keys):\n",
        "        r\"\"\"Performs tensor dtype and/or device conversion to all attributes\n",
        "        :obj:`*keys`.\n",
        "        If :obj:`*keys` is not given, the conversion is applied to all present\n",
        "        attributes.\"\"\"\n",
        "        return self.apply(lambda x: x.to(device), *keys)\n",
        "\n",
        "    def clone(self):\n",
        "        return self.__class__.from_dict({\n",
        "            k: v.clone() if torch.is_tensor(v) else copy.deepcopy(v)\n",
        "            for k, v in self.__dict__.items()\n",
        "        })\n",
        "\n",
        "    def debug(self):\n",
        "        if self.edge_index is not None:\n",
        "            if self.edge_index.dtype != torch.long:\n",
        "                raise RuntimeError(\n",
        "                    ('Expected edge indices of dtype {}, but found dtype '\n",
        "                     ' {}').format(torch.long, self.edge_index.dtype))\n",
        "\n",
        "        if self.face is not None:\n",
        "            if self.face.dtype != torch.long:\n",
        "                raise RuntimeError(\n",
        "                    ('Expected face indices of dtype {}, but found dtype '\n",
        "                     ' {}').format(torch.long, self.face.dtype))\n",
        "\n",
        "        if self.edge_index is not None:\n",
        "            if self.edge_index.dim() != 2 or self.edge_index.size(0) != 2:\n",
        "                raise RuntimeError(\n",
        "                    ('Edge indices should have shape [2, num_edges] but found'\n",
        "                     ' shape {}').format(self.edge_index.size()))\n",
        "\n",
        "        if self.edge_index is not None and self.num_nodes is not None:\n",
        "            if self.edge_index.numel() > 0:\n",
        "                min_index = self.edge_index.min()\n",
        "                max_index = self.edge_index.max()\n",
        "            else:\n",
        "                min_index = max_index = 0\n",
        "            if min_index < 0 or max_index > self.num_nodes - 1:\n",
        "                raise RuntimeError(\n",
        "                    ('Edge indices must lay in the interval [0, {}]'\n",
        "                     ' but found them in the interval [{}, {}]').format(\n",
        "                         self.num_nodes - 1, min_index, max_index))\n",
        "\n",
        "        if self.face is not None:\n",
        "            if self.face.dim() != 2 or self.face.size(0) != 3:\n",
        "                raise RuntimeError(\n",
        "                    ('Face indices should have shape [3, num_faces] but found'\n",
        "                     ' shape {}').format(self.face.size()))\n",
        "\n",
        "        if self.face is not None and self.num_nodes is not None:\n",
        "            if self.face.numel() > 0:\n",
        "                min_index = self.face.min()\n",
        "                max_index = self.face.max()\n",
        "            else:\n",
        "                min_index = max_index = 0\n",
        "            if min_index < 0 or max_index > self.num_nodes - 1:\n",
        "                raise RuntimeError(\n",
        "                    ('Face indices must lay in the interval [0, {}]'\n",
        "                     ' but found them in the interval [{}, {}]').format(\n",
        "                         self.num_nodes - 1, min_index, max_index))\n",
        "\n",
        "        if self.edge_index is not None and self.edge_attr is not None:\n",
        "            if self.edge_index.size(1) != self.edge_attr.size(0):\n",
        "                raise RuntimeError(\n",
        "                    ('Edge indices and edge attributes hold a differing '\n",
        "                     'number of edges, found {} and {}').format(\n",
        "                         self.edge_index.size(), self.edge_attr.size()))\n",
        "\n",
        "        if self.x is not None and self.num_nodes is not None:\n",
        "            if self.x.size(0) != self.num_nodes:\n",
        "                raise RuntimeError(\n",
        "                    ('Node features should hold {} elements in the first '\n",
        "                     'dimension but found {}').format(self.num_nodes,\n",
        "                                                      self.x.size(0)))\n",
        "        if self.smiles is not None and self.num_nodes is not None:\n",
        "            if self.smiles.size(0) != self.num_nodes:\n",
        "                raise RuntimeError(\n",
        "                    ('Node features should hold {} elements in the first '\n",
        "                     'dimension but found {}').format(self.num_nodes,\n",
        "                                                      self.smiles.size(0)))        \n",
        "\n",
        "        if self.pos is not None and self.num_nodes is not None:\n",
        "            if self.pos.size(0) != self.num_nodes:\n",
        "                raise RuntimeError(\n",
        "                    ('Node positions should hold {} elements in the first '\n",
        "                     'dimension but found {}').format(self.num_nodes,\n",
        "                                                      self.pos.size(0)))\n",
        "\n",
        "        if self.norm is not None and self.num_nodes is not None:\n",
        "            if self.norm.size(0) != self.num_nodes:\n",
        "                raise RuntimeError(\n",
        "                    ('Node normals should hold {} elements in the first '\n",
        "                     'dimension but found {}').format(self.num_nodes,\n",
        "                                                      self.norm.size(0)))\n",
        "\n",
        "    def __repr__(self):\n",
        "        info = ['{}={}'.format(key, size_repr(item)) for key, item in self]\n",
        "        return '{}({})'.format(self.__class__.__name__, ', '.join(info))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHisGJrrtvTm",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## PyTorch Geometric DataLoader class modification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMFySoZYtSRL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.utils.data\n",
        "from torch.utils.data.dataloader import default_collate\n",
        "\n",
        "from torch_geometric.data import Batch\n",
        "from torch._six import container_abcs, string_classes, int_classes\n",
        "\n",
        "\n",
        "class DataLoader(torch.utils.data.DataLoader):\n",
        "    r\"\"\"Data loader which merges data objects from a\n",
        "    :class:`torch_geometric.data.dataset` to a mini-batch.\n",
        "    Args:\n",
        "        dataset (Dataset): The dataset from which to load the data.\n",
        "        batch_size (int, optional): How many samples per batch to load.\n",
        "            (default: :obj:`1`)\n",
        "        shuffle (bool, optional): If set to :obj:`True`, the data will be\n",
        "            reshuffled at every epoch. (default: :obj:`False`)\n",
        "        follow_batch (list or tuple, optional): Creates assignment batch\n",
        "            vectors for each key in the list. (default: :obj:`[]`)\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset, batch_size=1, shuffle=False, follow_batch=[],\n",
        "                 **kwargs):\n",
        "        def collate(batch):\n",
        "            elem = batch[0]\n",
        "            if isinstance(elem, Data):\n",
        "                return Batch.from_data_list(batch, follow_batch)\n",
        "            elif isinstance(elem, torch.Tensor):\n",
        "                return default_collate(batch)\n",
        "            elif isinstance(elem, float):\n",
        "                return torch.tensor(batch, dtype=torch.float)\n",
        "            elif isinstance(elem, int_classes):\n",
        "                return torch.tensor(batch)\n",
        "            elif isinstance(elem, string_classes):\n",
        "                return batch\n",
        "            elif isinstance(elem, container_abcs.Mapping):\n",
        "                return {key: collate([d[key] for d in batch]) for key in elem}\n",
        "            elif isinstance(elem, tuple) and hasattr(elem, '_fields'):\n",
        "                return type(elem)(*(collate(s) for s in zip(*batch)))\n",
        "            elif isinstance(elem, container_abcs.Sequence):\n",
        "                return [collate(s) for s in zip(*batch)]\n",
        "\n",
        "            raise TypeError('DataLoader found invalid type: {}'.format(\n",
        "                type(elem)))\n",
        "\n",
        "        super(DataLoader,\n",
        "              self).__init__(dataset, batch_size, shuffle,\n",
        "                             collate_fn=lambda batch: collate(batch), **kwargs)\n",
        "\n",
        "\n",
        "class DataListLoader(torch.utils.data.DataLoader):\n",
        "    r\"\"\"Data loader which merges data objects from a\n",
        "    :class:`torch_geometric.data.dataset` to a python list.\n",
        "    .. note::\n",
        "        This data loader should be used for multi-gpu support via\n",
        "        :class:`torch_geometric.nn.DataParallel`.\n",
        "    Args:\n",
        "        dataset (Dataset): The dataset from which to load the data.\n",
        "        batch_size (int, optional): How many samples per batch to load.\n",
        "            (default: :obj:`1`)\n",
        "        shuffle (bool, optional): If set to :obj:`True`, the data will be\n",
        "            reshuffled at every epoch (default: :obj:`False`)\n",
        "    \"\"\"\n",
        "    def __init__(self, dataset, batch_size=1, shuffle=False, **kwargs):\n",
        "        super(DataListLoader,\n",
        "              self).__init__(dataset, batch_size, shuffle,\n",
        "                             collate_fn=lambda data_list: data_list, **kwargs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPhdFSRYt1Mb",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## PyTorch Geometric QM9 class modification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVNfMRQphNEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_sparse import coalesce\n",
        "from torch_geometric.data import (InMemoryDataset, download_url, extract_zip)\n",
        "\n",
        "try:\n",
        "    import rdkit\n",
        "    from rdkit import Chem\n",
        "    from rdkit import rdBase\n",
        "    from rdkit.Chem.rdchem import HybridizationType\n",
        "    from rdkit import RDConfig\n",
        "    from rdkit.Chem import ChemicalFeatures\n",
        "    from rdkit.Chem.rdchem import BondType as BT\n",
        "    rdBase.DisableLog('rdApp.error')\n",
        "except ImportError:\n",
        "    rdkit = None\n",
        "\n",
        "\n",
        "class QM9(InMemoryDataset):\n",
        "    r\"\"\"The QM9 dataset from the `\"MoleculeNet: A Benchmark for Molecular\n",
        "    Machine Learning\" <https://arxiv.org/abs/1703.00564>`_ paper, consisting of\n",
        "    about 130,000 molecules with 16 regression targets.\n",
        "    Each molecule includes complete spatial information for the single low\n",
        "    energy conformation of the atoms in the molecule.\n",
        "    In addition, we provide the atom features from the `\"Neural Message\n",
        "    Passing for Quantum Chemistry\" <https://arxiv.org/abs/1704.01212>`_ paper.\n",
        "\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | Target | Property                         | Description                                                                       | Unit                                        |\n",
        "    +========+==================================+===================================================================================+=============================================+\n",
        "    | 0      | :math:`\\mu`                      | Dipole moment                                                                     | :math:`\\textrm{D}`                          |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 1      | :math:`\\alpha`                   | Isotropic polarizability                                                          | :math:`{a_0}^3`                             |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 2      | :math:`\\epsilon_{\\textrm{HOMO}}` | Highest occupied molecular orbital energy                                         | :math:`E_{\\textrm{h}}`                      |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 3      | :math:`\\epsilon_{\\textrm{LUMO}}` | Lowest unoccupied molecular orbital energy                                        | :math:`E_{\\textrm{h}}`                      |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 4      | :math:`\\Delta \\epsilon`          | Gap between :math:`\\epsilon_{\\textrm{HOMO}}` and :math:`\\epsilon_{\\textrm{LUMO}}` | :math:`E_{\\textrm{h}}`                      |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 5      | :math:`\\langle R^2 \\rangle`      | Electronic spatial extent                                                         | :math:`{a_0}^2`                             |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 6      | :math:`\\textrm{ZPVE}`            | Zero point vibrational energy                                                     | :math:`E_{\\textrm{h}}`                      |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 7      | :math:`U_0`                      | Internal energy at 0K                                                             | :math:`E_{\\textrm{h}}`                      |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 8      | :math:`U`                        | Internal energy at 298.15K                                                        | :math:`E_{\\textrm{h}}`                      |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 9      | :math:`H`                        | Enthalpy at 298.15K                                                               | :math:`E_{\\textrm{h}}`                      |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 10     | :math:`G`                        | Free energy at 298.15K                                                            | :math:`E_{\\textrm{h}}`                      |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 11     | :math:`c_{\\textrm{v}}`           | Heat capavity at 298.15K                                                          | :math:`\\frac{\\textrm{cal}}{\\textrm{mol K}}` |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 12     | :math:`U_0^{\\textrm{ATOM}}`      | Atomization energy at 0K                                                          | :math:`\\frac{\\textrm{kcal}}{\\textrm{mol}}`  |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 13     | :math:`U^{\\textrm{ATOM}}`        | Atomization energy at 298.15K                                                     | :math:`\\frac{\\textrm{kcal}}{\\textrm{mol}}`  |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 14     | :math:`H^{\\textrm{ATOM}}`        | Atomization enthalpy at 298.15K                                                   | :math:`\\frac{\\textrm{kcal}}{\\textrm{mol}}`  |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "    | 15     | :math:`G^{\\textrm{ATOM}}`        | Atomization free energy at 298.15K                                                | :math:`\\frac{\\textrm{kcal}}{\\textrm{mol}}`  |\n",
        "    +--------+----------------------------------+-----------------------------------------------------------------------------------+---------------------------------------------+\n",
        "\n",
        "    Args:\n",
        "        root (string): Root directory where the dataset should be saved.\n",
        "        transform (callable, optional): A function/transform that takes in an\n",
        "            :obj:`torch_geometric.data.Data` object and returns a transformed\n",
        "            version. The data object will be transformed before every access.\n",
        "            (default: :obj:`None`)\n",
        "        pre_transform (callable, optional): A function/transform that takes in\n",
        "            an :obj:`torch_geometric.data.Data` object and returns a\n",
        "            transformed version. The data object will be transformed before\n",
        "            being saved to disk. (default: :obj:`None`)\n",
        "        pre_filter (callable, optional): A function that takes in an\n",
        "            :obj:`torch_geometric.data.Data` object and returns a boolean\n",
        "            value, indicating whether the data object should be included in the\n",
        "            final dataset. (default: :obj:`None`)\n",
        "    \"\"\"  # noqa: E501\n",
        "    \n",
        "\n",
        "    raw_url = ('https://s3-us-west-1.amazonaws.com/deepchem.io/datasets/'\n",
        "               'molnet_publish/qm9.zip')\n",
        "    processed_url = 'http://www.roemisch-drei.de/qm9.zip'\n",
        "\n",
        "    if rdkit is not None:\n",
        "        types = {'H': 0, 'C': 1, 'N': 2, 'O': 3, 'F': 4}\n",
        "        bonds = {BT.SINGLE: 0, BT.DOUBLE: 1, BT.TRIPLE: 2, BT.AROMATIC: 3}\n",
        "\n",
        "    def __init__(self, root, transform=None, pre_transform=None,\n",
        "                 pre_filter=None):\n",
        "        super(QM9, self).__init__(root, transform, pre_transform, pre_filter)\n",
        "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return 'qm9.pt' if rdkit is None else ['gdb9.sdf', 'gdb9.sdf.csv']\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return 'data.pt'\n",
        "\n",
        "    def download(self):\n",
        "        url = self.processed_url if rdkit is None else self.raw_url\n",
        "        file_path = download_url(url, self.raw_dir)\n",
        "        extract_zip(file_path, self.raw_dir)\n",
        "        os.unlink(file_path)\n",
        "\n",
        "    def process(self):\n",
        "        if rdkit is None:\n",
        "            print('Using a pre-processed version of the dataset. Please '\n",
        "                  'install `rdkit` to alternatively process the raw data.')\n",
        "\n",
        "            self.data, self.slices = torch.load(self.raw_paths[0])\n",
        "            data_list = [data for data in self]\n",
        "\n",
        "            if self.pre_filter is not None:\n",
        "                data_list = [d for d in data_list if self.pre_filter(d)]\n",
        "\n",
        "            if self.pre_transform is not None:\n",
        "                data_list = [self.pre_transform(d) for d in data_list]\n",
        "\n",
        "            data, slices = self.collate(data_list)\n",
        "            torch.save((data, slices), self.processed_paths[0])\n",
        "            return\n",
        "   #Change configuration for just one target\n",
        "        with open(self.raw_paths[1], 'r') as f:\n",
        "            target = f.read().split('\\n')[1:-1]\n",
        "            target = [[float(x) for x in line.split(',')[5:6]]\n",
        "                      for line in target]\n",
        "            target = torch.tensor(target, dtype=torch.float)\n",
        "           \n",
        "        suppl = Chem.SDMolSupplier(self.raw_paths[0], removeHs=False)\n",
        "        fdef_name = osp.join(RDConfig.RDDataDir, 'BaseFeatures.fdef')\n",
        "        factory = ChemicalFeatures.BuildFeatureFactory(fdef_name)\n",
        "\n",
        "        data_list = []\n",
        "        count=0\n",
        "        for i, mol in enumerate(suppl):\n",
        "          if ( count<120000):\n",
        "            if mol is None:\n",
        "                continue\n",
        "\n",
        "            text = suppl.GetItemText(i)\n",
        "            N = mol.GetNumAtoms()\n",
        "\n",
        "            pos = text.split('\\n')[4:4 + N]\n",
        "            pos = [[float(x) for x in line.split()[:3]] for line in pos]\n",
        "            pos = torch.tensor(pos, dtype=torch.float)\n",
        "\n",
        "            type_idx = []\n",
        "            atomic_number = []\n",
        "            acceptor = []\n",
        "            donor = []\n",
        "            aromatic = []\n",
        "            sp = []\n",
        "            sp2 = []\n",
        "            sp3 = []\n",
        "            num_hs = []\n",
        "            for atom in mol.GetAtoms():\n",
        "                type_idx.append(self.types[atom.GetSymbol()])\n",
        "                atomic_number.append(atom.GetAtomicNum())\n",
        "                donor.append(0)\n",
        "                acceptor.append(0)\n",
        "                aromatic.append(1 if atom.GetIsAromatic() else 0)\n",
        "                hybridization = atom.GetHybridization()\n",
        "                sp.append(1 if hybridization == HybridizationType.SP else 0)\n",
        "                sp2.append(1 if hybridization == HybridizationType.SP2 else 0)\n",
        "                sp3.append(1 if hybridization == HybridizationType.SP3 else 0)\n",
        "                num_hs.append(atom.GetTotalNumHs(includeNeighbors=True))\n",
        "\n",
        "            feats = factory.GetFeaturesForMol(mol)\n",
        "            for j in range(0, len(feats)):\n",
        "                if feats[j].GetFamily() == 'Donor':\n",
        "                    node_list = feats[j].GetAtomIds()\n",
        "                    for k in node_list:\n",
        "                        donor[k] = 1\n",
        "                elif feats[j].GetFamily() == 'Acceptor':\n",
        "                    node_list = feats[j].GetAtomIds()\n",
        "                    for k in node_list:\n",
        "                        acceptor[k] = 1\n",
        "\n",
        "            x1 = F.one_hot(torch.tensor(type_idx), num_classes=len(self.types))\n",
        "            x2 = torch.tensor([\n",
        "                atomic_number, acceptor, donor, aromatic, sp, sp2, sp3, num_hs\n",
        "            ], dtype=torch.float).t().contiguous()\n",
        "            x = torch.cat([x1.to(torch.float), x2], dim=-1)\n",
        "\n",
        "            row, col, bond_idx = [], [], []\n",
        "            for bond in mol.GetBonds():\n",
        "                start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
        "                row += [start, end]\n",
        "                col += [end, start]\n",
        "                bond_idx += 2 * [self.bonds[bond.GetBondType()]]\n",
        "\n",
        "            edge_index = torch.tensor([row, col], dtype=torch.long)\n",
        "            edge_attr = F.one_hot(torch.tensor(bond_idx),\n",
        "                                  num_classes=len(self.bonds)).to(torch.float)\n",
        "            edge_index, edge_attr = coalesce(edge_index, edge_attr, N, N)\n",
        "\n",
        "            y = target[i].unsqueeze(0)\n",
        "            data = Data(x=x,smiles=Smiles[count], pos=pos, edge_index=edge_index,\n",
        "                        edge_attr=edge_attr, y=y)\n",
        "\n",
        "            if self.pre_filter is not None and not self.pre_filter(data):\n",
        "                continue\n",
        "            if self.pre_transform is not None:\n",
        "                data = self.pre_transform(data)\n",
        "\n",
        "            data_list.append(data)\n",
        "          count=count+1\n",
        "        torch.save(self.collate(data_list), self.processed_paths[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3N2i1dzLp7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import Sequential, Linear, ReLU, GRU\n",
        "\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import NNConv, Set2Set\n",
        "from torch_geometric.utils import remove_self_loops"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpqNXA5yuKd8",
        "colab_type": "text"
      },
      "source": [
        "## Training Settings and Procedure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q3s4MzMLxe7",
        "colab_type": "code",
        "outputId": "3b9f5915-d08c-46a4-b16b-8f02872b22e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "source": [
        "  if __name__ == '__main__':\n",
        "    \n",
        "    target = 0\n",
        "    dim = 64\n",
        "    batch_size = 64\n",
        "    lamda =1\n",
        "    use_unsup_loss = False\n",
        "    separate_encoder = False\n",
        "    alpha=0\n",
        "    epochs = 10\n",
        "    log_interval = 1\n",
        "\n",
        "    path = osp.join(osp.dirname(osp.realpath(root)), '..', 'data', 'QM9')\n",
        "    transform = T.Compose([MyTransform(), Complete(), T.Distance(norm=False)])\n",
        "    dataset = QM9(path, transform=transform).shuffle()\n",
        "\n",
        "    # Normalize targets to mean = 0 and std = 1.\n",
        "    mean = dataset.data.y[:, target].mean().item()\n",
        "    std = dataset.data.y[:, target].std().item()\n",
        "    dataset.data.y[:, target] = (dataset.data.y[:, target] - mean) / std\n",
        "    print(dataset.data)\n",
        "\n",
        "    unsup_train_dataset = dataset[0:16000]\n",
        "    global_global_train_loader = DataLoader(unsup_train_dataset, batch_size=batch_size, shuffle=False)\n",
        "    local_global_train_loader = DataLoader(unsup_train_dataset, batch_size=batch_size, shuffle=False)\n",
        "    \n",
        "    lr=0.01\n",
        "    print(dataset.num_features)\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model = Net(dataset.num_features, dim, use_unsup_loss, separate_encoder).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "    \n",
        "    for epoch in range(1, epochs+1):\n",
        "        global_global_loss_all = 0\n",
        "        local_global_loss_all = 0\n",
        "        loss_all=0\n",
        "        model.train()\n",
        "        print(\"Training..\")\n",
        "        for data, data2 in zip(global_global_train_loader, local_global_train_loader):\n",
        "            data = data.to(device)\n",
        "            data2 = data2.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            if lamda<=0:\n",
        "              global_global_loss = model(data)\n",
        "              loss = alpha *global_global_loss \n",
        "              loss_all += loss.item() * data.num_graphs\n",
        "              loss.backward()\n",
        "              global_global_loss_all += global_global_loss.item()\n",
        "            elif alpha<=0:\n",
        "              local_global_loss = model.forward_local_global(data2)\n",
        "              loss = local_global_loss* lamda\n",
        "              loss_all += loss.item() * data.num_graphs\n",
        "              loss.backward()\n",
        "              local_global_loss_all += local_global_loss.item()\n",
        "            else:  \n",
        "              global_global_loss = model(data)\n",
        "              local_global_loss = model.forward_local_global(data2)\n",
        "              loss = alpha *global_global_loss + local_global_loss* lamda\n",
        "              loss_all += loss.item() * data.num_graphs\n",
        "              loss.backward()\n",
        "              global_global_loss_all += global_global_loss.item()\n",
        "              local_global_loss_all += local_global_loss.item()\n",
        "            optimizer.step()\n",
        "        if lamda<=0:    \n",
        "           print('Epoch {}, Loss {}'.format(epoch, loss_all / len(global_global_train_loader)))\n",
        "        else :    \n",
        "           print('Epoch {}, Loss {}'.format(epoch, loss_all / len(local_global_train_loader)))\n",
        "   \n",
        "\n",
        "        if epoch % log_interval == 0:\n",
        "            model.eval() \n",
        "            if lamda<=0:\n",
        "              emb, y = model.unsup_encoder.get_embeddings(global_global_train_loader)\n",
        "              res = evaluate_embedding(emb, y,std)\n",
        "            else :\n",
        "              emb, y = model.unsup_encoder.get_embeddings(local_global_train_loader)\n",
        "              res = evaluate_embedding(emb, y,std )   \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://s3-us-west-1.amazonaws.com/deepchem.io/datasets/molnet_publish/qm9.zip\n",
            "Extracting /content/data/QM9/raw/qm9.zip\n",
            "Processing...\n",
            "Done!\n",
            "Data(edge_attr=[4517542, 4], edge_index=[2, 4517542], pos=[2182316, 3], smiles=[120000], x=[2182316, 13], y=[120000, 1])\n",
            "13\n",
            "Training..\n",
            "Epoch 1, Loss -18.633270628273486\n",
            "(16000, 128) (16000,)\n",
            "Kernel Ridge Regression Mae validation : 2.3483770518085083\n",
            "Kernel Ridge Regression Mae testing : 2.374554974618394\n",
            "Training..\n",
            "Epoch 2, Loss -57.907932479858395\n",
            "(16000, 128) (16000,)\n",
            "Kernel Ridge Regression Mae validation : 2.171361732405196\n",
            "Kernel Ridge Regression Mae testing : 2.279367006020784\n",
            "Training..\n",
            "Epoch 3, Loss -57.41362841796875\n",
            "(16000, 128) (16000,)\n",
            "Kernel Ridge Regression Mae validation : 2.509369794295609\n",
            "Kernel Ridge Regression Mae testing : 2.485658048969205\n",
            "Training..\n",
            "Epoch 4, Loss -59.61766891479492\n",
            "(16000, 128) (16000,)\n",
            "Kernel Ridge Regression Mae validation : 2.727634027085526\n",
            "Kernel Ridge Regression Mae testing : 2.777663042720909\n",
            "Training..\n",
            "Epoch 5, Loss -61.0103112411499\n",
            "(16000, 128) (16000,)\n",
            "Kernel Ridge Regression Mae validation : 2.4974520228171886\n",
            "Kernel Ridge Regression Mae testing : 2.4571411426515604\n",
            "Training..\n",
            "Epoch 6, Loss -69.22813168334962\n",
            "(16000, 128) (16000,)\n",
            "Kernel Ridge Regression Mae validation : 2.548349523940341\n",
            "Kernel Ridge Regression Mae testing : 2.5539481276675087\n",
            "Training..\n",
            "Epoch 7, Loss -71.05747987365723\n",
            "(16000, 128) (16000,)\n",
            "Kernel Ridge Regression Mae validation : 2.3537797156885922\n",
            "Kernel Ridge Regression Mae testing : 2.476959419447541\n",
            "Training..\n",
            "Epoch 8, Loss -70.60783268737794\n",
            "(16000, 128) (16000,)\n",
            "Kernel Ridge Regression Mae validation : 2.3149589078841113\n",
            "Kernel Ridge Regression Mae testing : 2.4117950223051423\n",
            "Training..\n",
            "Epoch 9, Loss -71.7308256072998\n",
            "(16000, 128) (16000,)\n",
            "Kernel Ridge Regression Mae validation : 2.5792674468922523\n",
            "Kernel Ridge Regression Mae testing : 2.6206556869302027\n",
            "Training..\n",
            "Epoch 10, Loss -69.32471047973632\n",
            "(16000, 128) (16000,)\n",
            "Kernel Ridge Regression Mae validation : 2.440263054289731\n",
            "Kernel Ridge Regression Mae testing : 2.4231088230259514\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}