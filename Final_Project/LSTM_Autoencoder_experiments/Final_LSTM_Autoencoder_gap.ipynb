{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final-LSTM_Autoencoder_gap.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqEi1djJBmzy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import sys\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7AnuN8FwyCv",
        "colab_type": "code",
        "outputId": "b4aa7bc1-2538-4542-fade-4eccd740296e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Installing dependencies for RDKit\n",
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!time bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!time conda install -q -y -c conda-forge rdkit"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-30 08:26:03--  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.200.79, 104.18.201.79, 2606:4700::6812:c94f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.200.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh [following]\n",
            "--2020-05-30 08:26:04--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.131.3, 104.16.130.3, 2606:4700::6810:8303, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.131.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - asn1crypto==1.3.0=py37_0\n",
            "    - ca-certificates==2020.1.1=0\n",
            "    - certifi==2019.11.28=py37_0\n",
            "    - cffi==1.14.0=py37h2e261b9_0\n",
            "    - chardet==3.0.4=py37_1003\n",
            "    - conda-package-handling==1.6.0=py37h7b6447c_0\n",
            "    - conda==4.8.2=py37_0\n",
            "    - cryptography==2.8=py37h1ba5d50_0\n",
            "    - idna==2.8=py37_0\n",
            "    - ld_impl_linux-64==2.33.1=h53a641e_7\n",
            "    - libedit==3.1.20181209=hc058e9b_0\n",
            "    - libffi==3.2.1=hd88cf55_4\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - ncurses==6.2=he6710b0_0\n",
            "    - openssl==1.1.1d=h7b6447c_4\n",
            "    - pip==20.0.2=py37_1\n",
            "    - pycosat==0.6.3=py37h7b6447c_0\n",
            "    - pycparser==2.19=py37_0\n",
            "    - pyopenssl==19.1.0=py37_0\n",
            "    - pysocks==1.7.1=py37_0\n",
            "    - python==3.7.6=h0371630_2\n",
            "    - readline==7.0=h7b6447c_5\n",
            "    - requests==2.22.0=py37_1\n",
            "    - ruamel_yaml==0.15.87=py37h7b6447c_0\n",
            "    - setuptools==45.2.0=py37_0\n",
            "    - six==1.14.0=py37_0\n",
            "    - sqlite==3.31.1=h7b6447c_0\n",
            "    - tk==8.6.8=hbc83047_0\n",
            "    - tqdm==4.42.1=py_0\n",
            "    - urllib3==1.25.8=py37_0\n",
            "    - wheel==0.34.2=py37_0\n",
            "    - xz==5.2.4=h14c3975_4\n",
            "    - yaml==0.1.7=had09818_2\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  ca-certificates    conda-forge::ca-certificates-2020.4.5~ --> pkgs/main::ca-certificates-2020.1.1-0\n",
            "  certifi            conda-forge::certifi-2020.4.5.1-py37h~ --> pkgs/main::certifi-2019.11.28-py37_0\n",
            "  conda              conda-forge::conda-4.8.3-py37hc8dfbb8~ --> pkgs/main::conda-4.8.2-py37_0\n",
            "  openssl            conda-forge::openssl-1.1.1g-h516909a_0 --> pkgs/main::openssl-1.1.1d-h7b6447c_4\n",
            "\n",
            "\n",
            "Preparing transaction: \\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "\n",
            "real\t0m22.069s\n",
            "user\t0m28.537s\n",
            "sys\t0m5.027s\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates     pkgs/main::ca-certificates-2020.1.1-0 --> conda-forge::ca-certificates-2020.4.5.1-hecc5488_0\n",
            "  certifi              pkgs/main::certifi-2019.11.28-py37_0 --> conda-forge::certifi-2020.4.5.1-py37hc8dfbb8_0\n",
            "  conda                       pkgs/main::conda-4.8.2-py37_0 --> conda-forge::conda-4.8.3-py37hc8dfbb8_1\n",
            "  openssl              pkgs/main::openssl-1.1.1d-h7b6447c_4 --> conda-forge::openssl-1.1.1g-h516909a_0\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "\n",
            "real\t0m6.675s\n",
            "user\t0m5.993s\n",
            "sys\t0m0.834s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL2bcD47wN8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqt4hH9UwWe6",
        "colab_type": "code",
        "outputId": "5e02a54b-68e5-4886-9c4b-1658e8d40bbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9Vd1RE1w1L1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root = \"/content/drive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71JokDfXw5cY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "def get_data(split):\n",
        "    data_path =root +\"QM9_Smiles_.csv\"\n",
        "    with open(data_path) as f:\n",
        "        data = csv.reader(f)\n",
        "    \n",
        "        # Skip header\n",
        "        next(data)\n",
        "        \n",
        "        # Get smiles and targets\n",
        "        smiles, Y = [], []\n",
        "        count=0\n",
        "        for row in data:\n",
        "            if (count<16000):\n",
        "              smiles.append(row[0])\n",
        "              Y.append(row[1:13])\n",
        "              count=count+1\n",
        "    \n",
        "    return smiles, Y\n",
        "\n",
        "AllSmiles, All = get_data('train')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfepWCAyy1Co",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUr-FZw7zKa-",
        "colab_type": "code",
        "outputId": "931e2e28-56a9-48c9-8d24-22858dddbe21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "dtype = [('Col1','int32'), ('Col2','float32'), ('Col3','float32'),('Col4','int32'), ('Col5','float32'), ('Col6','float32'),('Col7','int32'), ('Col8','float32'), ('Col9','float32'),('Col10','int32'), ('Col11','float32'), ('Col12','float32'),('Col13','float32'), ('Col14','float32'),('Col15','float32'), ('Col16','float32'),('Col17','float32')]\n",
        "values = All\n",
        "index = ['Row'+str(i) for i in range(1, len(values)+1)]\n",
        "\n",
        "df = pd.DataFrame(values, index=index).astype(float)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Row1</th>\n",
              "      <td>5.0509</td>\n",
              "      <td>78.30</td>\n",
              "      <td>-0.2676</td>\n",
              "      <td>0.0141</td>\n",
              "      <td>0.2818</td>\n",
              "      <td>1120.8417</td>\n",
              "      <td>0.137571</td>\n",
              "      <td>-380.797809</td>\n",
              "      <td>-380.790510</td>\n",
              "      <td>-380.789566</td>\n",
              "      <td>-380.829714</td>\n",
              "      <td>28.666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row2</th>\n",
              "      <td>2.5256</td>\n",
              "      <td>55.40</td>\n",
              "      <td>-0.2868</td>\n",
              "      <td>-0.0597</td>\n",
              "      <td>0.2271</td>\n",
              "      <td>1180.5099</td>\n",
              "      <td>0.064339</td>\n",
              "      <td>-525.783370</td>\n",
              "      <td>-525.775913</td>\n",
              "      <td>-525.774969</td>\n",
              "      <td>-525.816245</td>\n",
              "      <td>25.955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row3</th>\n",
              "      <td>1.5279</td>\n",
              "      <td>83.85</td>\n",
              "      <td>-0.2229</td>\n",
              "      <td>0.0807</td>\n",
              "      <td>0.3036</td>\n",
              "      <td>1029.1179</td>\n",
              "      <td>0.196525</td>\n",
              "      <td>-367.186557</td>\n",
              "      <td>-367.178749</td>\n",
              "      <td>-367.177805</td>\n",
              "      <td>-367.218256</td>\n",
              "      <td>32.345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row4</th>\n",
              "      <td>2.1100</td>\n",
              "      <td>72.11</td>\n",
              "      <td>-0.2575</td>\n",
              "      <td>-0.0123</td>\n",
              "      <td>0.2451</td>\n",
              "      <td>1230.8475</td>\n",
              "      <td>0.136089</td>\n",
              "      <td>-455.191771</td>\n",
              "      <td>-455.182799</td>\n",
              "      <td>-455.181854</td>\n",
              "      <td>-455.226039</td>\n",
              "      <td>32.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row5</th>\n",
              "      <td>2.7860</td>\n",
              "      <td>75.68</td>\n",
              "      <td>-0.2791</td>\n",
              "      <td>0.0257</td>\n",
              "      <td>0.3048</td>\n",
              "      <td>1496.1036</td>\n",
              "      <td>0.168867</td>\n",
              "      <td>-440.291337</td>\n",
              "      <td>-440.280566</td>\n",
              "      <td>-440.279622</td>\n",
              "      <td>-440.327569</td>\n",
              "      <td>37.969</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0      1       2       3   ...          8           9           10      11\n",
              "Row1  5.0509  78.30 -0.2676  0.0141  ... -380.790510 -380.789566 -380.829714  28.666\n",
              "Row2  2.5256  55.40 -0.2868 -0.0597  ... -525.775913 -525.774969 -525.816245  25.955\n",
              "Row3  1.5279  83.85 -0.2229  0.0807  ... -367.178749 -367.177805 -367.218256  32.345\n",
              "Row4  2.1100  72.11 -0.2575 -0.0123  ... -455.182799 -455.181854 -455.226039  32.000\n",
              "Row5  2.7860  75.68 -0.2791  0.0257  ... -440.280566 -440.279622 -440.327569  37.969\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XhfilN567J5",
        "colab_type": "code",
        "outputId": "c434f372-14a4-40a3-eb67-a1e9f39eb97f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#Double check we have the right values \n",
        "s= pd.DataFrame(AllSmiles, index=index)\n",
        "\n",
        "s.head()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Row1</th>\n",
              "      <td>N#CC1NC11C2CC1C2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row2</th>\n",
              "      <td>OC1=NON=C1OC=O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row3</th>\n",
              "      <td>CC12CCC1CN1CC21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row4</th>\n",
              "      <td>CN=C1OC(=O)CC1N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row5</th>\n",
              "      <td>CC(CO)C(CO)C#N</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     0\n",
              "Row1  N#CC1NC11C2CC1C2\n",
              "Row2    OC1=NON=C1OC=O\n",
              "Row3   CC12CCC1CN1CC21\n",
              "Row4   CN=C1OC(=O)CC1N\n",
              "Row5    CC(CO)C(CO)C#N"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc7_doOnzKqh",
        "colab_type": "code",
        "outputId": "42680cf1-92c5-40ea-8a53-86d398e1bb5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsM4g122zRhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "std=df[4].std()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBYURIz-Wu_P",
        "colab_type": "code",
        "outputId": "b3968b46-6b25-418e-ebe6-55c56e0513ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "std"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.04733169752865191"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8jogAG9zYPV",
        "colab_type": "code",
        "outputId": "465b1be4-0eff-4a97-fb34-ce6b9a410787",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Normalize target values to have a mean of 0 and std of 1\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler() \n",
        "data_scaled=scaler.fit_transform(df)\n",
        "df = pd.DataFrame(data_scaled , index=index)\n",
        "df.head()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Row1</th>\n",
              "      <td>1.515532</td>\n",
              "      <td>0.376722</td>\n",
              "      <td>-1.263346</td>\n",
              "      <td>0.065564</td>\n",
              "      <td>0.650691</td>\n",
              "      <td>-0.239353</td>\n",
              "      <td>-0.329338</td>\n",
              "      <td>0.758062</td>\n",
              "      <td>0.758037</td>\n",
              "      <td>0.758037</td>\n",
              "      <td>0.758089</td>\n",
              "      <td>-0.713853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row2</th>\n",
              "      <td>-0.113146</td>\n",
              "      <td>-2.404221</td>\n",
              "      <td>-2.141010</td>\n",
              "      <td>-1.515652</td>\n",
              "      <td>-0.505019</td>\n",
              "      <td>-0.023702</td>\n",
              "      <td>-2.539103</td>\n",
              "      <td>-2.850370</td>\n",
              "      <td>-2.850411</td>\n",
              "      <td>-2.850411</td>\n",
              "      <td>-2.850322</td>\n",
              "      <td>-1.381283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row3</th>\n",
              "      <td>-0.756606</td>\n",
              "      <td>1.050706</td>\n",
              "      <td>0.779965</td>\n",
              "      <td>1.492516</td>\n",
              "      <td>1.111284</td>\n",
              "      <td>-0.570858</td>\n",
              "      <td>1.449591</td>\n",
              "      <td>1.096821</td>\n",
              "      <td>1.096811</td>\n",
              "      <td>1.096811</td>\n",
              "      <td>1.096849</td>\n",
              "      <td>0.191892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row4</th>\n",
              "      <td>-0.381184</td>\n",
              "      <td>-0.374982</td>\n",
              "      <td>-0.801658</td>\n",
              "      <td>-0.500074</td>\n",
              "      <td>-0.124713</td>\n",
              "      <td>0.158226</td>\n",
              "      <td>-0.374057</td>\n",
              "      <td>-1.093471</td>\n",
              "      <td>-1.093465</td>\n",
              "      <td>-1.093465</td>\n",
              "      <td>-1.093480</td>\n",
              "      <td>0.106955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row5</th>\n",
              "      <td>0.054798</td>\n",
              "      <td>0.058553</td>\n",
              "      <td>-1.789030</td>\n",
              "      <td>0.314102</td>\n",
              "      <td>1.136638</td>\n",
              "      <td>1.116906</td>\n",
              "      <td>0.615015</td>\n",
              "      <td>-0.722626</td>\n",
              "      <td>-0.722573</td>\n",
              "      <td>-0.722573</td>\n",
              "      <td>-0.722688</td>\n",
              "      <td>1.576482</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2   ...        9         10        11\n",
              "Row1  1.515532  0.376722 -1.263346  ...  0.758037  0.758089 -0.713853\n",
              "Row2 -0.113146 -2.404221 -2.141010  ... -2.850411 -2.850322 -1.381283\n",
              "Row3 -0.756606  1.050706  0.779965  ...  1.096811  1.096849  0.191892\n",
              "Row4 -0.381184 -0.374982 -0.801658  ... -1.093465 -1.093480  0.106955\n",
              "Row5  0.054798  0.058553 -1.789030  ... -0.722573 -0.722688  1.576482\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OptqPoWBzZDD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data(smiles_array,target_array,start, end):\n",
        "   # Get smiles and targets\n",
        "    smiles, Y = [], []\n",
        "    for i in range(start,end):\n",
        "      smiles.append(smiles_array[i])\n",
        "      Y.append(target_array[i])\n",
        "    \n",
        "    return smiles, Y\n",
        "\n",
        "trainSmiles, trainY = get_data(AllSmiles, df[4],0,16000)\n",
        "allSmiles = trainSmiles "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLlyXZxpzcSx",
        "colab_type": "code",
        "outputId": "e7aa4a36-2abd-4790-e0a9-e1cea0ab7892",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "allSmiles[0]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'N#CC1NC11C2CC1C2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDB_QD-bzekt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class QM9Dataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "      self.X, self.Y = X, Y\n",
        "      assert len(X) == len(Y)\n",
        "\n",
        "    def __len__(self):\n",
        "       return len(self.X)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "      return np.array(self.X[i]), self.Y[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDB0vpZFzhHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "lr = 1e-3\n",
        "weight_decay = 1e-4\n",
        "max_len = 25\n",
        "embedding_size = 1\n",
        "hidden_size = 64\n",
        "output_size = 1  \n",
        "dropout = 0.6\n",
        "use_cuda = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUauKXcOzjoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def param_count(model):\n",
        "    return sum(param.numel() for param in model.parameters() if param.requires_grad)\n",
        "  \n",
        "def mae(targets, preds):\n",
        "    return mean_absolute_error(targets, preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMPnwgCZxBOX",
        "colab_type": "code",
        "outputId": "7d4ebc9c-c954-4544-c732-09cf71c8a6df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Define vocab\n",
        "vocab = {char for smiles in AllSmiles for char in smiles}\n",
        "\n",
        "print(f'Vocab = {vocab}')\n",
        "\n",
        "# Create word to index mapping\n",
        "padding_idx = 0\n",
        "char_to_index = {char: index + 1 for index, char in enumerate(vocab)}\n",
        "vocab_size = len(char_to_index) + 1\n",
        "\n",
        "print(f'Vocab size = {vocab_size:,}')"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab = {'=', 'F', '-', '[', 'O', ')', '3', '5', '2', '+', ']', '1', 'H', 'C', '#', '(', 'N', '4'}\n",
            "Vocab size = 19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3VwEbzLxBxY",
        "colab_type": "code",
        "outputId": "99dcb65d-0da2-47c5-ade8-0c8eb982df73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "char_to_index "
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'#': 15,\n",
              " '(': 16,\n",
              " ')': 6,\n",
              " '+': 10,\n",
              " '-': 3,\n",
              " '1': 12,\n",
              " '2': 9,\n",
              " '3': 7,\n",
              " '4': 18,\n",
              " '5': 8,\n",
              " '=': 1,\n",
              " 'C': 14,\n",
              " 'F': 2,\n",
              " 'H': 13,\n",
              " 'N': 17,\n",
              " 'O': 5,\n",
              " '[': 4,\n",
              " ']': 11}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umRvnucoxJeT",
        "colab_type": "code",
        "outputId": "5882d9a4-0fc9-4696-c4e3-82c23348b10d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "biggest_mol_size = max([len(smiles) for smiles in allSmiles])\n",
        "print(\"Total number of smiles= \", len(AllSmiles))\n",
        "print(\"size of largest molecule = \", biggest_mol_size)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of smiles=  16000\n",
            "size of largest molecule =  27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVfCw7TKxOtf",
        "colab_type": "code",
        "outputId": "60ca5b24-26a5-4df9-857d-72e6ce6e4760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "trainX = [[char_to_index[char] for char in smiles] for smiles in trainSmiles]\n",
        "print(f'Smiles string = {trainSmiles[0]}')\n",
        "print(f'Indices of first train SMILES = {trainX[0]}')\n",
        "print(f'Last five indices = {trainX[0][-5:]}')\n",
        "\n",
        "\n",
        "print(f'Smiles string = {trainSmiles[2]}')\n",
        "print(f'Indices of second train SMILES = {trainX[2]}')\n",
        "print(f'Last five indices = {trainX[2][-5:]}')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Smiles string = N#CC1NC11C2CC1C2\n",
            "Indices of first train SMILES = [17, 15, 14, 14, 12, 17, 14, 12, 12, 14, 9, 14, 14, 12, 14, 9]\n",
            "Last five indices = [14, 14, 12, 14, 9]\n",
            "Smiles string = CC12CCC1CN1CC21\n",
            "Indices of second train SMILES = [14, 14, 12, 9, 14, 14, 14, 12, 14, 17, 12, 14, 14, 9, 12]\n",
            "Last five indices = [12, 14, 14, 9, 12]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJspcAcEJHI1",
        "colab_type": "code",
        "outputId": "ed6196e7-2b08-4b23-b13e-67046b59a5a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "trainX = [seq[:max_len] + [padding_idx] * (max_len - len(seq)) for seq in trainX]\n",
        "\n",
        "print(f'Smiles string = {trainSmiles[0]}')\n",
        "print(f'Indices of first train SMILES = {trainX[0]}')\n",
        "print(f'Last five indices = {trainX[0][-5:]}')\n",
        "\n",
        "print(f'Smiles string = {trainSmiles[2]}')\n",
        "print(f'Indices of second train SMILES = {trainX[2]}')\n",
        "print(f'Last five indices = {trainX[2][-5:]}')\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Smiles string = N#CC1NC11C2CC1C2\n",
            "Indices of first train SMILES = [17, 15, 14, 14, 12, 17, 14, 12, 12, 14, 9, 14, 14, 12, 14, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Last five indices = [0, 0, 0, 0, 0]\n",
            "Smiles string = CC12CCC1CN1CC21\n",
            "Indices of second train SMILES = [14, 14, 12, 9, 14, 14, 14, 12, 14, 17, 12, 14, 14, 9, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Last five indices = [0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5XfDHgB4Dr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build Dataset\n",
        "train = QM9Dataset(trainX, trainY)\n",
        "\n",
        "# Build DataLoader\n",
        "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN5UM5ie4J7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, padding_idx, embedding_size, hidden_size, output_size, dropout):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        \n",
        "        # Embedding layer\n",
        "        self.embed = nn.Embedding(vocab_size, embedding_size, padding_idx=padding_idx)\n",
        "        \n",
        "        # LSTM (RNN)\n",
        "        self.rnn_encoder = nn.LSTM(\n",
        "            input_size=embedding_size,\n",
        "            hidden_size=hidden_size,\n",
        "            batch_first=True\n",
        "        )\n",
        "        \n",
        "       # LSTM (RNN)\n",
        "        self.rnn_decoder = nn.LSTM(\n",
        "            input_size=hidden_size,\n",
        "            hidden_size=embedding_size,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        \n",
        "        # Fully connected layer\n",
        "        self.output = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "        # Dropout (regularization)\n",
        "      #  self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):  # batch_size x seq_length\n",
        "        # Embed\n",
        "        embedded = self.embed(x)  # batch_size x seq_length x embedding_size\n",
        "         \n",
        "        # Run RNN\n",
        "        o, _ = self.rnn_encoder(embedded)  # batch_size x seq_length x hidden_size\n",
        "        m, _ = self.rnn_decoder(o)  # batch_size x seq_length x hidden_size\n",
        "          \n",
        "        # Dropout\n",
        "       # o = self.dropout(o)  # batch_size x seq_length x hidden_size\n",
        "        \n",
        "        # Max pooling across sequence\n",
        "        n, _ = torch.max(o, dim=1)    # batch_size x hidden_size\n",
        "        \n",
        "        # Output layer\n",
        "        out = self.output(n)  # batch_size x output_size\n",
        "        \n",
        "        return embedded, m,n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpIoR5HG5U25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV, KFold, StratifiedKFold\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\"\"\"Evaluates latent space quality via a linear regression downstream task.\"\"\"\n",
        "def linear_reg(X,Y,std):\n",
        "\n",
        "  X_train, X_test_validate, y_train, y_test_validate = train_test_split(X, Y, test_size=0.4, random_state=101)\n",
        "  X_valid, X_test, y_valid, y_test = train_test_split(X_test_validate, y_test_validate, test_size=0.5, random_state=101)\n",
        "  params = { 'kernel':['laplacian'],'alpha':[0.001, 0.01,0.1,1,10,100]}\n",
        "  #clf = GridSearchCV(KernelRidge(), params, cv=5,verbose=5)\n",
        "  clf = KernelRidge(alpha=0.001, kernel='laplacian',)\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred=clf.predict(X_test)\n",
        "  y_predv=clf.predict(X_valid)\n",
        "  mae_test = mean_absolute_error(y_test,y_pred)*std \n",
        "  mae_val = mean_absolute_error(y_valid,y_predv)*std \n",
        "  return mae_val,mae_test\n",
        "\n",
        "\n",
        "def evaluate_embedding(embeddings, labels, std):\n",
        "    xa, ya= embeddings.cuda().cpu(),labels.cuda().cpu(),\n",
        "    x,y=np.array(xa.detach().numpy()),np.array(ya.detach().numpy())\n",
        "    #print(x.shape, y.shape)\n",
        "    val_accuracies,test_accuracies=linear_reg(x, y, std)\n",
        "\n",
        "    return np.mean(val_accuracies),np.mean(test_accuracies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avGyl-kUoJPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_loader, optimizer, epoch, std):\n",
        "    model.train()  # Set the nn.Module to train mode. \n",
        "    total_loss = 0\n",
        "    total_mae = 0\n",
        "    num_samples = len(train_loader.dataset)\n",
        "    num_batches = 0\n",
        "    val=[]\n",
        "    test=[]\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):  # 1) get batch\n",
        "        # Adjust dimensions of target and cast to float\n",
        "        target = target.unsqueeze(1).float()\n",
        "      \n",
        "        # Move to cuda\n",
        "        if next(model.parameters()).is_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "      \n",
        "        # Reset gradient data to 0\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Get prediction for batch\n",
        "        embed,output,n = model(data)\n",
        "        \n",
        "        # 2) Compute loss\n",
        "        loss = F.mse_loss(output, embed)\n",
        "        \n",
        "        # 3) Do backprop\n",
        "        loss.backward()\n",
        "        \n",
        "        # 4) Update model\n",
        "        optimizer.step()\n",
        "        \n",
        "        y_v,y_t=evaluate_embedding(n, target, std)\n",
        "        # Do book-keeping to track rmse and avg loss\n",
        "        total_loss += loss.detach()  # Don't keep computation graph \n",
        "        num_batches += 1\n",
        "        val.append(y_v)\n",
        "        test.append(y_t)\n",
        "    y_v=np.mean(val)\n",
        "    y_t=np.mean(test)     \n",
        "    return (y_v,y_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbbVrjVzmRSy",
        "colab_type": "code",
        "outputId": "1b144104-c477-4c16-ce96-cc89e6c173eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "model = LSTMModel(vocab_size, padding_idx, embedding_size, hidden_size, output_size, dropout)\n",
        "print(model)\n",
        "print(f'Number of parameters = {param_count(model):,}')\n",
        "epochs=10\n",
        "# Move to cuda\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "for epoch in range(1, epochs+1):\n",
        "    mae_v,mae_t = train(model, train_loader, optimizer, epoch,std)\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    print('Kernel Ridge Regression validation MAE : {}'.format(mae_v))\n",
        "    print('Kernel Ridge Regression testing MAE : {}'.format(mae_t))\n",
        "\n",
        "   "
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTMModel(\n",
            "  (embed): Embedding(19, 1, padding_idx=0)\n",
            "  (rnn_encoder): LSTM(1, 64, batch_first=True)\n",
            "  (rnn_decoder): LSTM(64, 1, batch_first=True)\n",
            "  (output): Linear(in_features=64, out_features=1, bias=True)\n",
            ")\n",
            "Number of parameters = 17,504\n",
            "Epoch: 1\n",
            "Kernel Ridge Regression validation MAE : 0.03613983680743996\n",
            "Kernel Ridge Regression testing MAE : 0.035477270422226925\n",
            "Epoch: 2\n",
            "Kernel Ridge Regression validation MAE : 0.036595072613707216\n",
            "Kernel Ridge Regression testing MAE : 0.0359847808171993\n",
            "Epoch: 3\n",
            "Kernel Ridge Regression validation MAE : 0.03600653879853418\n",
            "Kernel Ridge Regression testing MAE : 0.036097820257262964\n",
            "Epoch: 4\n",
            "Kernel Ridge Regression validation MAE : 0.03594300283035282\n",
            "Kernel Ridge Regression testing MAE : 0.035689742057628475\n",
            "Epoch: 5\n",
            "Kernel Ridge Regression validation MAE : 0.0363625536796142\n",
            "Kernel Ridge Regression testing MAE : 0.036632978033233676\n",
            "Epoch: 6\n",
            "Kernel Ridge Regression validation MAE : 0.0364464583978331\n",
            "Kernel Ridge Regression testing MAE : 0.035442921658267845\n",
            "Epoch: 7\n",
            "Kernel Ridge Regression validation MAE : 0.03641789636188714\n",
            "Kernel Ridge Regression testing MAE : 0.03661100058474554\n",
            "Epoch: 8\n",
            "Kernel Ridge Regression validation MAE : 0.03699964417459989\n",
            "Kernel Ridge Regression testing MAE : 0.03678132768746058\n",
            "Epoch: 9\n",
            "Kernel Ridge Regression validation MAE : 0.03696815114836791\n",
            "Kernel Ridge Regression testing MAE : 0.03728897059560088\n",
            "Epoch: 10\n",
            "Kernel Ridge Regression validation MAE : 0.036840296964756755\n",
            "Kernel Ridge Regression testing MAE : 0.03695457948836079\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}