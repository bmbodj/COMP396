{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "f-LSTM_Autoencoder_mu.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqEi1djJBmzy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import sys\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7AnuN8FwyCv",
        "colab_type": "code",
        "outputId": "6e91042f-510b-42a3-a67e-5253f9328b56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Installing dependencies for RDKit\n",
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!time bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!time conda install -q -y -c conda-forge rdkit"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-17 03:43:18--  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.200.79, 104.18.201.79, 2606:4700::6812:c94f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.200.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh [following]\n",
            "--2020-05-17 03:43:18--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.130.3, 104.16.131.3, 2606:4700::6810:8303, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.130.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - asn1crypto==1.3.0=py37_0\n",
            "    - ca-certificates==2020.1.1=0\n",
            "    - certifi==2019.11.28=py37_0\n",
            "    - cffi==1.14.0=py37h2e261b9_0\n",
            "    - chardet==3.0.4=py37_1003\n",
            "    - conda-package-handling==1.6.0=py37h7b6447c_0\n",
            "    - conda==4.8.2=py37_0\n",
            "    - cryptography==2.8=py37h1ba5d50_0\n",
            "    - idna==2.8=py37_0\n",
            "    - ld_impl_linux-64==2.33.1=h53a641e_7\n",
            "    - libedit==3.1.20181209=hc058e9b_0\n",
            "    - libffi==3.2.1=hd88cf55_4\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - ncurses==6.2=he6710b0_0\n",
            "    - openssl==1.1.1d=h7b6447c_4\n",
            "    - pip==20.0.2=py37_1\n",
            "    - pycosat==0.6.3=py37h7b6447c_0\n",
            "    - pycparser==2.19=py37_0\n",
            "    - pyopenssl==19.1.0=py37_0\n",
            "    - pysocks==1.7.1=py37_0\n",
            "    - python==3.7.6=h0371630_2\n",
            "    - readline==7.0=h7b6447c_5\n",
            "    - requests==2.22.0=py37_1\n",
            "    - ruamel_yaml==0.15.87=py37h7b6447c_0\n",
            "    - setuptools==45.2.0=py37_0\n",
            "    - six==1.14.0=py37_0\n",
            "    - sqlite==3.31.1=h7b6447c_0\n",
            "    - tk==8.6.8=hbc83047_0\n",
            "    - tqdm==4.42.1=py_0\n",
            "    - urllib3==1.25.8=py37_0\n",
            "    - wheel==0.34.2=py37_0\n",
            "    - xz==5.2.4=h14c3975_4\n",
            "    - yaml==0.1.7=had09818_2\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  ca-certificates    conda-forge::ca-certificates-2020.4.5~ --> pkgs/main::ca-certificates-2020.1.1-0\n",
            "  certifi            conda-forge::certifi-2020.4.5.1-py37h~ --> pkgs/main::certifi-2019.11.28-py37_0\n",
            "  conda              conda-forge::conda-4.8.3-py37hc8dfbb8~ --> pkgs/main::conda-4.8.2-py37_0\n",
            "  openssl            conda-forge::openssl-1.1.1g-h516909a_0 --> pkgs/main::openssl-1.1.1d-h7b6447c_4\n",
            "\n",
            "\n",
            "Preparing transaction: \\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "\n",
            "real\t0m22.961s\n",
            "user\t0m27.538s\n",
            "sys\t0m4.707s\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates     pkgs/main::ca-certificates-2020.1.1-0 --> conda-forge::ca-certificates-2020.4.5.1-hecc5488_0\n",
            "  certifi              pkgs/main::certifi-2019.11.28-py37_0 --> conda-forge::certifi-2020.4.5.1-py37hc8dfbb8_0\n",
            "  conda                       pkgs/main::conda-4.8.2-py37_0 --> conda-forge::conda-4.8.3-py37hc8dfbb8_1\n",
            "  openssl              pkgs/main::openssl-1.1.1d-h7b6447c_4 --> conda-forge::openssl-1.1.1g-h516909a_0\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "\n",
            "real\t0m6.618s\n",
            "user\t0m5.915s\n",
            "sys\t0m0.812s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pL2bcD47wN8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqt4hH9UwWe6",
        "colab_type": "code",
        "outputId": "ecda71d1-a479-4441-ccd9-586e6e8ecad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9Vd1RE1w1L1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root = \"/content/drive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71JokDfXw5cY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "def get_data(split):\n",
        "    data_path =root +\"QM9_Smiles_.csv\"\n",
        "    with open(data_path) as f:\n",
        "        data = csv.reader(f)\n",
        "    \n",
        "        # Skip header\n",
        "        next(data)\n",
        "        \n",
        "        # Get smiles and targets\n",
        "        smiles, Y = [], []\n",
        "        count=0\n",
        "        for row in data:\n",
        "            if (count<13000):\n",
        "              smiles.append(row[0])\n",
        "              Y.append(row[1:13])\n",
        "              count=count+1\n",
        "    \n",
        "    return smiles, Y\n",
        "\n",
        "AllSmiles, All = get_data('train')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfepWCAyy1Co",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUr-FZw7zKa-",
        "colab_type": "code",
        "outputId": "68821abb-b3f9-4186-ef29-b2365de81405",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "dtype = [('Col1','int32'), ('Col2','float32'), ('Col3','float32'),('Col4','int32'), ('Col5','float32'), ('Col6','float32'),('Col7','int32'), ('Col8','float32'), ('Col9','float32'),('Col10','int32'), ('Col11','float32'), ('Col12','float32'),('Col13','float32'), ('Col14','float32'),('Col15','float32'), ('Col16','float32'),('Col17','float32')]\n",
        "values = All\n",
        "index = ['Row'+str(i) for i in range(1, len(values)+1)]\n",
        "\n",
        "df = pd.DataFrame(values, index=index).astype(float)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Row1</th>\n",
              "      <td>5.0509</td>\n",
              "      <td>78.30</td>\n",
              "      <td>-0.2676</td>\n",
              "      <td>0.0141</td>\n",
              "      <td>0.2818</td>\n",
              "      <td>1120.8417</td>\n",
              "      <td>0.137571</td>\n",
              "      <td>-380.797809</td>\n",
              "      <td>-380.790510</td>\n",
              "      <td>-380.789566</td>\n",
              "      <td>-380.829714</td>\n",
              "      <td>28.666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row2</th>\n",
              "      <td>2.5256</td>\n",
              "      <td>55.40</td>\n",
              "      <td>-0.2868</td>\n",
              "      <td>-0.0597</td>\n",
              "      <td>0.2271</td>\n",
              "      <td>1180.5099</td>\n",
              "      <td>0.064339</td>\n",
              "      <td>-525.783370</td>\n",
              "      <td>-525.775913</td>\n",
              "      <td>-525.774969</td>\n",
              "      <td>-525.816245</td>\n",
              "      <td>25.955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row3</th>\n",
              "      <td>1.5279</td>\n",
              "      <td>83.85</td>\n",
              "      <td>-0.2229</td>\n",
              "      <td>0.0807</td>\n",
              "      <td>0.3036</td>\n",
              "      <td>1029.1179</td>\n",
              "      <td>0.196525</td>\n",
              "      <td>-367.186557</td>\n",
              "      <td>-367.178749</td>\n",
              "      <td>-367.177805</td>\n",
              "      <td>-367.218256</td>\n",
              "      <td>32.345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row4</th>\n",
              "      <td>2.1100</td>\n",
              "      <td>72.11</td>\n",
              "      <td>-0.2575</td>\n",
              "      <td>-0.0123</td>\n",
              "      <td>0.2451</td>\n",
              "      <td>1230.8475</td>\n",
              "      <td>0.136089</td>\n",
              "      <td>-455.191771</td>\n",
              "      <td>-455.182799</td>\n",
              "      <td>-455.181854</td>\n",
              "      <td>-455.226039</td>\n",
              "      <td>32.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row5</th>\n",
              "      <td>2.7860</td>\n",
              "      <td>75.68</td>\n",
              "      <td>-0.2791</td>\n",
              "      <td>0.0257</td>\n",
              "      <td>0.3048</td>\n",
              "      <td>1496.1036</td>\n",
              "      <td>0.168867</td>\n",
              "      <td>-440.291337</td>\n",
              "      <td>-440.280566</td>\n",
              "      <td>-440.279622</td>\n",
              "      <td>-440.327569</td>\n",
              "      <td>37.969</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0      1       2       3   ...          8           9           10      11\n",
              "Row1  5.0509  78.30 -0.2676  0.0141  ... -380.790510 -380.789566 -380.829714  28.666\n",
              "Row2  2.5256  55.40 -0.2868 -0.0597  ... -525.775913 -525.774969 -525.816245  25.955\n",
              "Row3  1.5279  83.85 -0.2229  0.0807  ... -367.178749 -367.177805 -367.218256  32.345\n",
              "Row4  2.1100  72.11 -0.2575 -0.0123  ... -455.182799 -455.181854 -455.226039  32.000\n",
              "Row5  2.7860  75.68 -0.2791  0.0257  ... -440.280566 -440.279622 -440.327569  37.969\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XhfilN567J5",
        "colab_type": "code",
        "outputId": "50531293-43f2-41df-841f-efccafbebf25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#Double check we have the right values \n",
        "s= pd.DataFrame(AllSmiles, index=index)\n",
        "\n",
        "s.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Row1</th>\n",
              "      <td>N#CC1NC11C2CC1C2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row2</th>\n",
              "      <td>OC1=NON=C1OC=O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row3</th>\n",
              "      <td>CC12CCC1CN1CC21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row4</th>\n",
              "      <td>CN=C1OC(=O)CC1N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row5</th>\n",
              "      <td>CC(CO)C(CO)C#N</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     0\n",
              "Row1  N#CC1NC11C2CC1C2\n",
              "Row2    OC1=NON=C1OC=O\n",
              "Row3   CC12CCC1CN1CC21\n",
              "Row4   CN=C1OC(=O)CC1N\n",
              "Row5    CC(CO)C(CO)C#N"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc7_doOnzKqh",
        "colab_type": "code",
        "outputId": "7cba17b4-bb90-4778-af15-51518d3c8b3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsM4g122zRhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "std=df[0].std()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBYURIz-Wu_P",
        "colab_type": "code",
        "outputId": "438ea87f-3895-4554-c9ff-9a592ac70eb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "std"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.5425372727835618"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8jogAG9zYPV",
        "colab_type": "code",
        "outputId": "d8693573-f1af-4a13-98ea-afda0a00a4d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Normalize target values to have a mean of 0 and std of 1\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler() \n",
        "data_scaled=scaler.fit_transform(df)\n",
        "df = pd.DataFrame(data_scaled , index=index)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Row1</th>\n",
              "      <td>1.524938</td>\n",
              "      <td>0.378979</td>\n",
              "      <td>-1.263105</td>\n",
              "      <td>0.064793</td>\n",
              "      <td>0.650760</td>\n",
              "      <td>-0.238498</td>\n",
              "      <td>-0.327196</td>\n",
              "      <td>0.758552</td>\n",
              "      <td>0.758527</td>\n",
              "      <td>0.758527</td>\n",
              "      <td>0.758579</td>\n",
              "      <td>-0.710168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row2</th>\n",
              "      <td>-0.112232</td>\n",
              "      <td>-2.392174</td>\n",
              "      <td>-2.140975</td>\n",
              "      <td>-1.514495</td>\n",
              "      <td>-0.506721</td>\n",
              "      <td>-0.023748</td>\n",
              "      <td>-2.537359</td>\n",
              "      <td>-2.850754</td>\n",
              "      <td>-2.850795</td>\n",
              "      <td>-2.850795</td>\n",
              "      <td>-2.850704</td>\n",
              "      <td>-1.376207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row3</th>\n",
              "      <td>-0.759049</td>\n",
              "      <td>1.050590</td>\n",
              "      <td>0.780687</td>\n",
              "      <td>1.490003</td>\n",
              "      <td>1.112059</td>\n",
              "      <td>-0.568618</td>\n",
              "      <td>1.452052</td>\n",
              "      <td>1.097393</td>\n",
              "      <td>1.097383</td>\n",
              "      <td>1.097383</td>\n",
              "      <td>1.097421</td>\n",
              "      <td>0.193690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row4</th>\n",
              "      <td>-0.381669</td>\n",
              "      <td>-0.370080</td>\n",
              "      <td>-0.801308</td>\n",
              "      <td>-0.500156</td>\n",
              "      <td>-0.125831</td>\n",
              "      <td>0.157421</td>\n",
              "      <td>-0.371923</td>\n",
              "      <td>-1.093429</td>\n",
              "      <td>-1.093423</td>\n",
              "      <td>-1.093423</td>\n",
              "      <td>-1.093437</td>\n",
              "      <td>0.108930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row5</th>\n",
              "      <td>0.056587</td>\n",
              "      <td>0.061930</td>\n",
              "      <td>-1.788912</td>\n",
              "      <td>0.313028</td>\n",
              "      <td>1.137452</td>\n",
              "      <td>1.112095</td>\n",
              "      <td>0.617326</td>\n",
              "      <td>-0.722495</td>\n",
              "      <td>-0.722441</td>\n",
              "      <td>-0.722441</td>\n",
              "      <td>-0.722556</td>\n",
              "      <td>1.575396</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2   ...        9         10        11\n",
              "Row1  1.524938  0.378979 -1.263105  ...  0.758527  0.758579 -0.710168\n",
              "Row2 -0.112232 -2.392174 -2.140975  ... -2.850795 -2.850704 -1.376207\n",
              "Row3 -0.759049  1.050590  0.780687  ...  1.097383  1.097421  0.193690\n",
              "Row4 -0.381669 -0.370080 -0.801308  ... -1.093423 -1.093437  0.108930\n",
              "Row5  0.056587  0.061930 -1.788912  ... -0.722441 -0.722556  1.575396\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OptqPoWBzZDD",
        "colab_type": "code",
        "outputId": "100825dd-9dac-420b-be4f-69f60637583d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "def get_data(smiles_array,target_array,start, end):\n",
        "   # Get smiles and targets\n",
        "    smiles, Y = [], []\n",
        "    for i in range(start,end):\n",
        "      smiles.append(smiles_array[i])\n",
        "      Y.append(target_array[i])\n",
        "    \n",
        "    return smiles, Y\n",
        "\n",
        "trainSmiles, trainY = get_data(AllSmiles, df[0],2000,13000)\n",
        "devSmiles, devY = get_data(AllSmiles, df[0], 1000,2000)\n",
        "testSmiles, testY = get_data(AllSmiles, df[0], 0,1000)\n",
        "\n",
        "allSmiles = trainSmiles + devSmiles + testSmiles\n",
        "\n",
        "print(f'Num Train = {len(trainSmiles):,}')\n",
        "print(f'Num Dev   = {len(devSmiles):,}')\n",
        "print(f'Num Test  = {len(testSmiles):,}')\n",
        "\n",
        "print(f'Example data point: smiles = {trainSmiles[0]}, alpha = {trainY[0]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num Train = 11,000\n",
            "Num Dev   = 1,000\n",
            "Num Test  = 1,000\n",
            "Example data point: smiles = CC1=C2NCCN2N=N1, alpha = 1.8780066871728993\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLlyXZxpzcSx",
        "colab_type": "code",
        "outputId": "d55e528d-aed1-423d-cdad-3739ec7c4ec1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "allSmiles[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'CC1=C2NCCN2N=N1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDB_QD-bzekt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class QM9Dataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "      self.X, self.Y = X, Y\n",
        "      assert len(X) == len(Y)\n",
        "\n",
        "    def __len__(self):\n",
        "       return len(self.X)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "      return np.array(self.X[i]), self.Y[i]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDB0vpZFzhHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "lr = 1e-3\n",
        "weight_decay = 1e-4\n",
        "max_len = 25\n",
        "embedding_size = 1\n",
        "hidden_size = 64\n",
        "output_size = 1  \n",
        "dropout = 0.6\n",
        "use_cuda = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUauKXcOzjoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def param_count(model):\n",
        "    return sum(param.numel() for param in model.parameters() if param.requires_grad)\n",
        "  \n",
        "def mae(targets, preds):\n",
        "    return mean_absolute_error(targets, preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMPnwgCZxBOX",
        "colab_type": "code",
        "outputId": "10dca5c1-63a7-4da2-8f02-f00d564135a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Define vocab\n",
        "vocab = {char for smiles in AllSmiles for char in smiles}\n",
        "\n",
        "print(f'Vocab = {vocab}')\n",
        "\n",
        "# Create word to index mapping\n",
        "padding_idx = 0\n",
        "char_to_index = {char: index + 1 for index, char in enumerate(vocab)}\n",
        "vocab_size = len(char_to_index) + 1\n",
        "\n",
        "print(f'Vocab size = {vocab_size:,}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab = {'(', ']', '[', '+', 'N', ')', 'O', 'F', '3', '4', 'C', 'H', '5', '-', '=', '#', '2', '1'}\n",
            "Vocab size = 19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3VwEbzLxBxY",
        "colab_type": "code",
        "outputId": "e48abc97-b9ca-4d11-f54e-2fba0d9e2418",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "char_to_index "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'#': 16,\n",
              " '(': 1,\n",
              " ')': 6,\n",
              " '+': 4,\n",
              " '-': 14,\n",
              " '1': 18,\n",
              " '2': 17,\n",
              " '3': 9,\n",
              " '4': 10,\n",
              " '5': 13,\n",
              " '=': 15,\n",
              " 'C': 11,\n",
              " 'F': 8,\n",
              " 'H': 12,\n",
              " 'N': 5,\n",
              " 'O': 7,\n",
              " '[': 3,\n",
              " ']': 2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umRvnucoxJeT",
        "colab_type": "code",
        "outputId": "2ac05685-d4b5-4c3b-bb20-43ce179fcc67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "biggest_mol_size = max([len(smiles) for smiles in allSmiles])\n",
        "print(\"Total number of smiles= \", len(AllSmiles))\n",
        "print(\"size of largest molecule = \", biggest_mol_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of smiles=  13000\n",
            "size of largest molecule =  27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVfCw7TKxOtf",
        "colab_type": "code",
        "outputId": "3ccf0389-af15-4781-c355-42b192339f54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "trainX = [[char_to_index[char] for char in smiles] for smiles in trainSmiles]\n",
        "devX =   [[char_to_index[char] for char in smiles] for smiles in devSmiles]\n",
        "testX =  [[char_to_index[char] for char in smiles] for smiles in testSmiles]\n",
        "\n",
        "print(f'Smiles string = {trainSmiles[0]}')\n",
        "print(f'Indices of first train SMILES = {trainX[0]}')\n",
        "print(f'Last five indices = {trainX[0][-5:]}')\n",
        "\n",
        "\n",
        "print(f'Smiles string = {trainSmiles[2]}')\n",
        "print(f'Indices of second train SMILES = {trainX[2]}')\n",
        "print(f'Last five indices = {trainX[2][-5:]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Smiles string = CC1=C2NCCN2N=N1\n",
            "Indices of first train SMILES = [11, 11, 18, 15, 11, 17, 5, 11, 11, 5, 17, 5, 15, 5, 18]\n",
            "Last five indices = [17, 5, 15, 5, 18]\n",
            "Smiles string = CC1OC1(CO)C1CO1\n",
            "Indices of second train SMILES = [11, 11, 18, 7, 11, 18, 1, 11, 7, 6, 11, 18, 11, 7, 18]\n",
            "Last five indices = [11, 18, 11, 7, 18]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJspcAcEJHI1",
        "colab_type": "code",
        "outputId": "f89f19aa-7007-4a8c-c55b-f14ea85a166d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "#add all elemnets the pad with os at the end so that they have the same length\n",
        "trainX = [seq[:max_len] + [padding_idx] * (max_len - len(seq)) for seq in trainX]\n",
        "devX =   [seq[:max_len] + [padding_idx] * (max_len - len(seq)) for seq in devX]\n",
        "testX =  [seq[:max_len] + [padding_idx] * (max_len - len(seq)) for seq in testX]\n",
        "\n",
        "\n",
        "print(f'Smiles string = {trainSmiles[0]}')\n",
        "print(f'Indices of first train SMILES = {trainX[0]}')\n",
        "print(f'Last five indices = {trainX[0][-5:]}')\n",
        "\n",
        "\n",
        "print(f'Smiles string = {trainSmiles[2]}')\n",
        "print(f'Indices of second train SMILES = {trainX[2]}')\n",
        "print(f'Last five indices = {trainX[2][-5:]}')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Smiles string = CC1=C2NCCN2N=N1\n",
            "Indices of first train SMILES = [11, 11, 18, 15, 11, 17, 5, 11, 11, 5, 17, 5, 15, 5, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Last five indices = [0, 0, 0, 0, 0]\n",
            "Smiles string = CC1OC1(CO)C1CO1\n",
            "Indices of second train SMILES = [11, 11, 18, 7, 11, 18, 1, 11, 7, 6, 11, 18, 11, 7, 18, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Last five indices = [0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXlSshK0zofC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(model, train_loader, optimizer, epoch, std):\n",
        "    model.train()  # Set the nn.Module to train mode. \n",
        "    total_loss = 0\n",
        "    total_mae = 0\n",
        "    num_samples = len(train_loader.dataset)\n",
        "    num_batches = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):  # 1) get batch\n",
        "        # Adjust dimensions of target and cast to float\n",
        "        target = target.unsqueeze(1).float()\n",
        "      \n",
        "        # Move to cuda\n",
        "        if next(model.parameters()).is_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "      \n",
        "        # Reset gradient data to 0\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Get prediction for batch\n",
        "        output = model(data)\n",
        "        \n",
        "        # 2) Compute loss\n",
        "        loss = F.mse_loss(output, target)\n",
        "        \n",
        "        # 3) Do backprop\n",
        "        loss.backward()\n",
        "        \n",
        "        # 4) Update model\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Do book-keeping to track rmse and avg loss\n",
        "        total_loss += loss.detach()  # Don't keep computation graph \n",
        "        total_mae += mae(target.cpu().data.numpy(), output.cpu().data.numpy())\n",
        "        num_batches += 1\n",
        "    return ( total_loss/num_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYPZy-6bzsyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_epoch(model, test_loader, std):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_mae = 0\n",
        "    num_batches = 0\n",
        "    for data, target in test_loader:\n",
        "        target = target.unsqueeze(1).float()\n",
        "      \n",
        "        # Move to cuda\n",
        "        if next(model.parameters()).is_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        \n",
        "        output = model(data)\n",
        "        \n",
        "        test_loss += F.mse_loss(output, embed).item()  # sum up batch loss\n",
        "        test_mae += mae(target.cpu().data.numpy(), output.cpu().data.numpy())\n",
        "        num_batches += 1\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_mae /= num_batches\n",
        "    return test_mae*std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5XfDHgB4Dr6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build Dataset\n",
        "train = QM9Dataset(trainX, trainY)\n",
        "dev = QM9Dataset(devX, devY)\n",
        "test = QM9Dataset(testX, testY)\n",
        "\n",
        "# Build DataLoader\n",
        "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "dev_loader = DataLoader(dev, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN5UM5ie4J7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, padding_idx, embedding_size, hidden_size, output_size, dropout):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        \n",
        "        # Embedding layer\n",
        "        self.embed = nn.Embedding(vocab_size, embedding_size, padding_idx=padding_idx)\n",
        "        \n",
        "        # LSTM (RNN)\n",
        "        self.rnn_encoder = nn.LSTM(\n",
        "            input_size=embedding_size,\n",
        "            hidden_size=hidden_size,\n",
        "            batch_first=True\n",
        "        )\n",
        "        \n",
        "       # LSTM (RNN)\n",
        "        self.rnn_decoder = nn.LSTM(\n",
        "            input_size=hidden_size,\n",
        "            hidden_size=embedding_size,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        \n",
        "        # Fully connected layer\n",
        "        self.output = nn.Linear(hidden_size, output_size)\n",
        "        \n",
        "        # Dropout (regularization)\n",
        "      #  self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):  # batch_size x seq_length\n",
        "        # Embed\n",
        "        embedded = self.embed(x)  # batch_size x seq_length x embedding_size\n",
        "         \n",
        "        # Run RNN\n",
        "        o, _ = self.rnn_encoder(embedded)  # batch_size x seq_length x hidden_size\n",
        "        m, _ = self.rnn_decoder(o)  # batch_size x seq_length x hidden_size\n",
        "          \n",
        "        # Dropout\n",
        "       # o = self.dropout(o)  # batch_size x seq_length x hidden_size\n",
        "        \n",
        "        # Max pooling across sequence\n",
        "        n, _ = torch.max(o, dim=1)    # batch_size x hidden_size\n",
        "        \n",
        "        # Output layer\n",
        "        out = self.output(n)  # batch_size x output_size\n",
        "        \n",
        "        return embedded, m,n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpIoR5HG5U25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV, KFold, StratifiedKFold\n",
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\"\"\"Evaluates latent space quality via a linear regression downstream task.\"\"\"\n",
        "def linear_reg(X,Y,std):\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=101)\n",
        "  params = { 'kernel':['laplacian'],'alpha':[0.001, 0.01,0.1,1,10,100]}\n",
        "  #clf = KernelRidge(alpha=1.0, kernel='laplacian',)\n",
        "  clf = GridSearchCV(KernelRidge(), params, cv=5)\n",
        "  clf.fit(X_train, y_train)\n",
        "  y_pred=clf.predict(X_test)\n",
        "  mae = mean_absolute_error(y_test,y_pred)*std \n",
        "  return mae\n",
        "\n",
        "\n",
        "def evaluate_embedding(embeddings, labels, std):\n",
        "    xa, ya= embeddings.cuda().cpu(),labels.cuda().cpu(),\n",
        "    x,y=np.array(xa.detach().numpy()),np.array(ya.detach().numpy())\n",
        "    #print(x.shape, y.shape)\n",
        "\n",
        "    linreg_accuracies = [linear_reg(x, y, std) for _ in range(1)]\n",
        "    #print('LinReg', np.mean(linreg_accuracies))\n",
        "\n",
        "    return np.mean(linreg_accuracies)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avGyl-kUoJPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_loader, optimizer, epoch, std):\n",
        "    model.train()  # Set the nn.Module to train mode. \n",
        "    total_loss = 0\n",
        "    total_mae = 0\n",
        "    num_samples = len(train_loader.dataset)\n",
        "    num_batches = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):  # 1) get batch\n",
        "        # Adjust dimensions of target and cast to float\n",
        "        target = target.unsqueeze(1).float()\n",
        "      \n",
        "        # Move to cuda\n",
        "        if next(model.parameters()).is_cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "      \n",
        "        # Reset gradient data to 0\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Get prediction for batch\n",
        "        embed,output,n = model(data)\n",
        "        \n",
        "        # 2) Compute loss\n",
        "        loss = F.mse_loss(output, embed)\n",
        "        \n",
        "        # 3) Do backprop\n",
        "        loss.backward()\n",
        "        \n",
        "        # 4) Update model\n",
        "        optimizer.step()\n",
        "        \n",
        "        y=evaluate_embedding(n, target, std)\n",
        "        # Do book-keeping to track rmse and avg loss\n",
        "        total_loss += loss.detach()  # Don't keep computation graph \n",
        "        num_batches += 1\n",
        "    return (y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbbVrjVzmRSy",
        "colab_type": "code",
        "outputId": "6690eb25-5fe8-48ea-e1a2-682ea31022af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "model = LSTMModel(vocab_size, padding_idx, embedding_size, hidden_size, output_size, dropout)\n",
        "print(model)\n",
        "print(f'Number of parameters = {param_count(model):,}')\n",
        "\n",
        "# Move to cuda\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
        "                                                       factor=0.7, patience=5,\n",
        "                                                       min_lr=0.00001)\n",
        "best_val_error = None\n",
        "for epoch in range(1, 20):\n",
        "    mae = train(model, train_loader, optimizer, epoch,std)\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    print('Kernel Ridge Regression Mean Absolute Error : {}'.format(mae))\n",
        "\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTMModel(\n",
            "  (embed): Embedding(19, 1, padding_idx=0)\n",
            "  (rnn_encoder): LSTM(1, 64, batch_first=True)\n",
            "  (rnn_decoder): LSTM(64, 1, batch_first=True)\n",
            "  (output): Linear(in_features=64, out_features=1, bias=True)\n",
            ")\n",
            "Number of parameters = 17,504\n",
            "Epoch: 1\n",
            "Kernel Ridge Regression Mean Absolute Error : 1.2192138362052207\n",
            "Epoch: 2\n",
            "Kernel Ridge Regression Mean Absolute Error : 1.0304034572794587\n",
            "Epoch: 3\n",
            "Kernel Ridge Regression Mean Absolute Error : 1.1899304460831566\n",
            "Epoch: 4\n",
            "Kernel Ridge Regression Mean Absolute Error : 1.0866744588915118\n",
            "Epoch: 5\n",
            "Kernel Ridge Regression Mean Absolute Error : 1.0703442862259933\n",
            "Epoch: 6\n",
            "Kernel Ridge Regression Mean Absolute Error : 0.9646780925805549\n",
            "Epoch: 7\n",
            "Kernel Ridge Regression Mean Absolute Error : 1.4402072351106245\n",
            "Epoch: 8\n",
            "Kernel Ridge Regression Mean Absolute Error : 1.074954514334586\n",
            "Epoch: 9\n",
            "Kernel Ridge Regression Mean Absolute Error : 0.7850762808700198\n",
            "Epoch: 10\n",
            "Kernel Ridge Regression Mean Absolute Error : 0.8661578879164747\n",
            "Epoch: 11\n",
            "Kernel Ridge Regression Mean Absolute Error : 1.1974712276207775\n",
            "Epoch: 12\n",
            "Kernel Ridge Regression Mean Absolute Error : 0.9161815066600608\n",
            "Epoch: 13\n",
            "Kernel Ridge Regression Mean Absolute Error : 0.9291234546236142\n",
            "Epoch: 14\n",
            "Kernel Ridge Regression Mean Absolute Error : 0.9612263923411531\n",
            "Epoch: 15\n",
            "Kernel Ridge Regression Mean Absolute Error : 1.2420645137488435\n",
            "Epoch: 16\n",
            "Kernel Ridge Regression Mean Absolute Error : 1.5293509930613913\n",
            "Epoch: 17\n",
            "Kernel Ridge Regression Mean Absolute Error : 1.4593333563942237\n",
            "Epoch: 18\n",
            "Kernel Ridge Regression Mean Absolute Error : 1.1047176173268245\n",
            "Epoch: 19\n",
            "Kernel Ridge Regression Mean Absolute Error : 0.8379661546642051\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}