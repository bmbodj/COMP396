# -*- coding: utf-8 -*-
"""f-LSTM_Autoencoder_mu.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wJqIn5Ex7UjrjSzR8cvd3t5w218E1jHt
"""

import re
import sys

import math
import numpy as np
from sklearn.metrics import mean_absolute_error
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset

#Installing dependencies for RDKit
!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh
!chmod +x Miniconda3-latest-Linux-x86_64.sh
!time bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local
!time conda install -q -y -c conda-forge rdkit

import sys
sys.path.append('/usr/local/lib/python3.7/site-packages/')

from google.colab import drive

# This will prompt for authorization.
drive.mount('/content/drive/')

root = "/content/drive/My Drive/"

import csv
def get_data(split):
    data_path =root +"QM9_Smiles_.csv"
    with open(data_path) as f:
        data = csv.reader(f)
    
        # Skip header
        next(data)
        
        # Get smiles and targets
        smiles, Y = [], []
        count=0
        for row in data:
            if (count<13000):
              smiles.append(row[0])
              Y.append(row[1:13])
              count=count+1
    
    return smiles, Y

AllSmiles, All = get_data('train')

import pandas as pd
import numpy as np

dtype = [('Col1','int32'), ('Col2','float32'), ('Col3','float32'),('Col4','int32'), ('Col5','float32'), ('Col6','float32'),('Col7','int32'), ('Col8','float32'), ('Col9','float32'),('Col10','int32'), ('Col11','float32'), ('Col12','float32'),('Col13','float32'), ('Col14','float32'),('Col15','float32'), ('Col16','float32'),('Col17','float32')]
values = All
index = ['Row'+str(i) for i in range(1, len(values)+1)]

df = pd.DataFrame(values, index=index).astype(float)

df.head()

#Double check we have the right values 
s= pd.DataFrame(AllSmiles, index=index)

s.head()

len(df)

std=df[0].std()

std

# Normalize target values to have a mean of 0 and std of 1
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler() 
data_scaled=scaler.fit_transform(df)
df = pd.DataFrame(data_scaled , index=index)
df.head()

def get_data(smiles_array,target_array,start, end):
   # Get smiles and targets
    smiles, Y = [], []
    for i in range(start,end):
      smiles.append(smiles_array[i])
      Y.append(target_array[i])
    
    return smiles, Y

trainSmiles, trainY = get_data(AllSmiles, df[0],2000,13000)
devSmiles, devY = get_data(AllSmiles, df[0], 1000,2000)
testSmiles, testY = get_data(AllSmiles, df[0], 0,1000)

allSmiles = trainSmiles + devSmiles + testSmiles

print(f'Num Train = {len(trainSmiles):,}')
print(f'Num Dev   = {len(devSmiles):,}')
print(f'Num Test  = {len(testSmiles):,}')

print(f'Example data point: smiles = {trainSmiles[0]}, alpha = {trainY[0]}')

allSmiles[0]

class QM9Dataset(Dataset):
    def __init__(self, X, Y):
      self.X, self.Y = X, Y
      assert len(X) == len(Y)

    def __len__(self):
       return len(self.X)

    def __getitem__(self, i):
      return np.array(self.X[i]), self.Y[i]

batch_size = 64
lr = 1e-3
weight_decay = 1e-4
max_len = 25
embedding_size = 1
hidden_size = 64
output_size = 1  
dropout = 0.6
use_cuda = True

def param_count(model):
    return sum(param.numel() for param in model.parameters() if param.requires_grad)
  
def mae(targets, preds):
    return mean_absolute_error(targets, preds)

# Define vocab
vocab = {char for smiles in AllSmiles for char in smiles}

print(f'Vocab = {vocab}')

# Create word to index mapping
padding_idx = 0
char_to_index = {char: index + 1 for index, char in enumerate(vocab)}
vocab_size = len(char_to_index) + 1

print(f'Vocab size = {vocab_size:,}')

char_to_index

biggest_mol_size = max([len(smiles) for smiles in allSmiles])
print("Total number of smiles= ", len(AllSmiles))
print("size of largest molecule = ", biggest_mol_size)

trainX = [[char_to_index[char] for char in smiles] for smiles in trainSmiles]
devX =   [[char_to_index[char] for char in smiles] for smiles in devSmiles]
testX =  [[char_to_index[char] for char in smiles] for smiles in testSmiles]

print(f'Smiles string = {trainSmiles[0]}')
print(f'Indices of first train SMILES = {trainX[0]}')
print(f'Last five indices = {trainX[0][-5:]}')


print(f'Smiles string = {trainSmiles[2]}')
print(f'Indices of second train SMILES = {trainX[2]}')
print(f'Last five indices = {trainX[2][-5:]}')

#add all elemnets the pad with os at the end so that they have the same length
trainX = [seq[:max_len] + [padding_idx] * (max_len - len(seq)) for seq in trainX]
devX =   [seq[:max_len] + [padding_idx] * (max_len - len(seq)) for seq in devX]
testX =  [seq[:max_len] + [padding_idx] * (max_len - len(seq)) for seq in testX]


print(f'Smiles string = {trainSmiles[0]}')
print(f'Indices of first train SMILES = {trainX[0]}')
print(f'Last five indices = {trainX[0][-5:]}')


print(f'Smiles string = {trainSmiles[2]}')
print(f'Indices of second train SMILES = {trainX[2]}')
print(f'Last five indices = {trainX[2][-5:]}')

def train_epoch(model, train_loader, optimizer, epoch, std):
    model.train()  # Set the nn.Module to train mode. 
    total_loss = 0
    total_mae = 0
    num_samples = len(train_loader.dataset)
    num_batches = 0
    for batch_idx, (data, target) in enumerate(train_loader):  # 1) get batch
        # Adjust dimensions of target and cast to float
        target = target.unsqueeze(1).float()
      
        # Move to cuda
        if next(model.parameters()).is_cuda:
            data, target = data.cuda(), target.cuda()
      
        # Reset gradient data to 0
        optimizer.zero_grad()
        
        # Get prediction for batch
        output = model(data)
        
        # 2) Compute loss
        loss = F.mse_loss(output, target)
        
        # 3) Do backprop
        loss.backward()
        
        # 4) Update model
        optimizer.step()
        
        # Do book-keeping to track rmse and avg loss
        total_loss += loss.detach()  # Don't keep computation graph 
        total_mae += mae(target.cpu().data.numpy(), output.cpu().data.numpy())
        num_batches += 1
    return ( total_loss/num_samples)

def eval_epoch(model, test_loader, std):
    model.eval()
    test_loss = 0
    test_mae = 0
    num_batches = 0
    for data, target in test_loader:
        target = target.unsqueeze(1).float()
      
        # Move to cuda
        if next(model.parameters()).is_cuda:
            data, target = data.cuda(), target.cuda()
        
        output = model(data)
        
        test_loss += F.mse_loss(output, embed).item()  # sum up batch loss
        test_mae += mae(target.cpu().data.numpy(), output.cpu().data.numpy())
        num_batches += 1

    test_loss /= len(test_loader.dataset)
    test_mae /= num_batches
    return test_mae*std

# Build Dataset
train = QM9Dataset(trainX, trainY)
dev = QM9Dataset(devX, devY)
test = QM9Dataset(testX, testY)

# Build DataLoader
train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)
dev_loader = DataLoader(dev, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test, batch_size=batch_size, shuffle=True)

class LSTMModel(nn.Module):
    def __init__(self, vocab_size, padding_idx, embedding_size, hidden_size, output_size, dropout):
        super(LSTMModel, self).__init__()
        
        # Embedding layer
        self.embed = nn.Embedding(vocab_size, embedding_size, padding_idx=padding_idx)
        
        # LSTM (RNN)
        self.rnn_encoder = nn.LSTM(
            input_size=embedding_size,
            hidden_size=hidden_size,
            batch_first=True
        )
        
       # LSTM (RNN)
        self.rnn_decoder = nn.LSTM(
            input_size=hidden_size,
            hidden_size=embedding_size,
            batch_first=True
        )

        
        # Fully connected layer
        self.output = nn.Linear(hidden_size, output_size)
        
        # Dropout (regularization)
      #  self.dropout = nn.Dropout(dropout)
        
    def forward(self, x):  # batch_size x seq_length
        # Embed
        embedded = self.embed(x)  # batch_size x seq_length x embedding_size
         
        # Run RNN
        o, _ = self.rnn_encoder(embedded)  # batch_size x seq_length x hidden_size
        m, _ = self.rnn_decoder(o)  # batch_size x seq_length x hidden_size
          
        # Dropout
       # o = self.dropout(o)  # batch_size x seq_length x hidden_size
        
        # Max pooling across sequence
        n, _ = torch.max(o, dim=1)    # batch_size x hidden_size
        
        # Output layer
        out = self.output(n)  # batch_size x output_size
        
        return embedded, m,n

from sklearn.model_selection import GridSearchCV, KFold, StratifiedKFold
from sklearn.kernel_ridge import KernelRidge
from sklearn import metrics
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split

"""Evaluates latent space quality via a linear regression downstream task."""
def linear_reg(X,Y,std):

  X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=101)
  params = { 'kernel':['laplacian'],'alpha':[0.001, 0.01,0.1,1,10,100]}
  #clf = KernelRidge(alpha=1.0, kernel='laplacian',)
  clf = GridSearchCV(KernelRidge(), params, cv=5)
  clf.fit(X_train, y_train)
  y_pred=clf.predict(X_test)
  mae = mean_absolute_error(y_test,y_pred)*std 
  return mae


def evaluate_embedding(embeddings, labels, std):
    xa, ya= embeddings.cuda().cpu(),labels.cuda().cpu(),
    x,y=np.array(xa.detach().numpy()),np.array(ya.detach().numpy())
    #print(x.shape, y.shape)

    linreg_accuracies = [linear_reg(x, y, std) for _ in range(1)]
    #print('LinReg', np.mean(linreg_accuracies))

    return np.mean(linreg_accuracies)

def train(model, train_loader, optimizer, epoch, std):
    model.train()  # Set the nn.Module to train mode. 
    total_loss = 0
    total_mae = 0
    num_samples = len(train_loader.dataset)
    num_batches = 0
    for batch_idx, (data, target) in enumerate(train_loader):  # 1) get batch
        # Adjust dimensions of target and cast to float
        target = target.unsqueeze(1).float()
      
        # Move to cuda
        if next(model.parameters()).is_cuda:
            data, target = data.cuda(), target.cuda()
      
        # Reset gradient data to 0
        optimizer.zero_grad()
        
        # Get prediction for batch
        embed,output,n = model(data)
        
        # 2) Compute loss
        loss = F.mse_loss(output, embed)
        
        # 3) Do backprop
        loss.backward()
        
        # 4) Update model
        optimizer.step()
        
        y=evaluate_embedding(n, target, std)
        # Do book-keeping to track rmse and avg loss
        total_loss += loss.detach()  # Don't keep computation graph 
        num_batches += 1
    return (y)

model = LSTMModel(vocab_size, padding_idx, embedding_size, hidden_size, output_size, dropout)
print(model)
print(f'Number of parameters = {param_count(model):,}')

# Move to cuda
if use_cuda and torch.cuda.is_available():
    model = model.cuda()
    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)

optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',
                                                       factor=0.7, patience=5,
                                                       min_lr=0.00001)
best_val_error = None
for epoch in range(1, 20):
    mae = train(model, train_loader, optimizer, epoch,std)
    print('Epoch: {}'.format(epoch))
    print('Kernel Ridge Regression Mean Absolute Error : {}'.format(mae))