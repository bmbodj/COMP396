{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SMILES+LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGS2DqF1ybEh",
        "colab_type": "code",
        "outputId": "c7f249d2-d543-4ba4-8692-eb6bb470e726",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#Installing dependencies for RDKit\n",
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!time bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!time conda install -q -y -c conda-forge rdkit"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-14 07:20:32--  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.201.79, 104.18.200.79, 2606:4700::6812:c84f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.201.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - asn1crypto==1.2.0=py37_0\n",
            "    - ca-certificates==2019.10.16=0\n",
            "    - certifi==2019.9.11=py37_0\n",
            "    - cffi==1.13.0=py37h2e261b9_0\n",
            "    - chardet==3.0.4=py37_1003\n",
            "    - conda-package-handling==1.6.0=py37h7b6447c_0\n",
            "    - conda==4.7.12=py37_0\n",
            "    - cryptography==2.8=py37h1ba5d50_0\n",
            "    - idna==2.8=py37_0\n",
            "    - libedit==3.1.20181209=hc058e9b_0\n",
            "    - libffi==3.2.1=hd88cf55_4\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - ncurses==6.1=he6710b0_1\n",
            "    - openssl==1.1.1d=h7b6447c_3\n",
            "    - pip==19.3.1=py37_0\n",
            "    - pycosat==0.6.3=py37h14c3975_0\n",
            "    - pycparser==2.19=py37_0\n",
            "    - pyopenssl==19.0.0=py37_0\n",
            "    - pysocks==1.7.1=py37_0\n",
            "    - python==3.7.4=h265db76_1\n",
            "    - readline==7.0=h7b6447c_5\n",
            "    - requests==2.22.0=py37_0\n",
            "    - ruamel_yaml==0.15.46=py37h14c3975_0\n",
            "    - setuptools==41.4.0=py37_0\n",
            "    - six==1.12.0=py37_0\n",
            "    - sqlite==3.30.0=h7b6447c_0\n",
            "    - tk==8.6.8=hbc83047_0\n",
            "    - tqdm==4.36.1=py_0\n",
            "    - urllib3==1.24.2=py37_0\n",
            "    - wheel==0.33.6=py37_0\n",
            "    - xz==5.2.4=h14c3975_4\n",
            "    - yaml==0.1.7=had09818_2\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  openssl            conda-forge::openssl-1.1.1d-h516909a_0 --> pkgs/main::openssl-1.1.1d-h7b6447c_3\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  ca-certificates    conda-forge::ca-certificates-2019.11.~ --> pkgs/main::ca-certificates-2019.10.16-0\n",
            "  certifi            conda-forge::certifi-2019.11.28-py37_0 --> pkgs/main::certifi-2019.9.11-py37_0\n",
            "  conda                     conda-forge::conda-4.8.0-py37_0 --> pkgs/main::conda-4.7.12-py37_0\n",
            "\n",
            "\n",
            "Preparing transaction: | \b\bdone\n",
            "Executing transaction: - \b\b\\ \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "\n",
            "real\t0m27.092s\n",
            "user\t0m34.355s\n",
            "sys\t0m7.126s\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates    pkgs/main::ca-certificates-2019.10.16~ --> conda-forge::ca-certificates-2019.11.28-hecc5488_0\n",
            "  certifi               pkgs/main::certifi-2019.9.11-py37_0 --> conda-forge::certifi-2019.11.28-py37_0\n",
            "  conda                      pkgs/main::conda-4.7.12-py37_0 --> conda-forge::conda-4.8.0-py37_0\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  openssl              pkgs/main::openssl-1.1.1d-h7b6447c_3 --> conda-forge::openssl-1.1.1d-h516909a_0\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "\n",
            "real\t0m7.957s\n",
            "user\t0m6.841s\n",
            "sys\t0m1.137s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pRxIafZyb71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmnZPnjwycF_",
        "colab_type": "code",
        "outputId": "b2014f55-cb8b-438a-ae83-39c623f4f456",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpAkavx7ycOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "root = \"/content/drive/My Drive/dsb2/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXaovKMOycMW",
        "colab_type": "code",
        "outputId": "c4a47cb7-7a59-4651-fb2b-6df40a044ce1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "\n",
        "file_list = os.listdir(root)\n",
        "\n",
        "num_mols = len(file_list)\n",
        "print(num_mols)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4i0rVZ4ycDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_xyz(file_name):\n",
        "    with open(file_name, 'rb') as file:\n",
        "        num_atoms = int(file.readline())\n",
        "        properties = file.readline().split()[5:17] # only take the properties used in the experiments \n",
        "        properties = [num.replace(b'*^', b'e') for num in properties] \n",
        "        properties = [float(prop) for prop in properties]\n",
        "        atom_types = [0]*num_atoms\n",
        "        coords = np.array(np.zeros([num_atoms,3]))\n",
        "        for na in range(num_atoms):\n",
        "            coord_line = file.readline().split()\n",
        "            atom_types[na] = coord_line[0]\n",
        "            xyz_coords = coord_line[1:4]\n",
        "            xyz_coords = [num.replace(b'*^', b'e') for num in xyz_coords] \n",
        "            coords[na,:] = [float(num) for num in xyz_coords]  \n",
        "        vib_freqs = file.readline()\n",
        "        smiles = file.readline().split()[0]\n",
        "        inchis = file.readline()\n",
        "        \n",
        "    return smiles, properties, atom_types, coords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S80GbQpRycBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import concurrent.futures\n",
        "from concurrent.futures import ProcessPoolExecutor\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from concurrent.futures import as_completed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVklPXpJy91P",
        "colab_type": "code",
        "outputId": "f41a1210-c54b-4609-8df7-00cdac0f92c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import multiprocessing as mp\n",
        "import numpy as np\n",
        "from multiprocessing.pool import ThreadPool\n",
        "import time\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "N= mp.cpu_count()\n",
        "files = os.scandir(root)\n",
        "print (N)\n",
        "with mp.pool.ThreadPool(processes = 8) as p:\n",
        "        results= p.map(read_xyz, [root+file.name for file in files])\n",
        "      \n",
        "end = time.time()\n",
        "print(end - start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "19.752538919448853\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8ipzGswyb_9",
        "colab_type": "code",
        "outputId": "8e4289f6-1398-4458-d6d1-98e8231f9e9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(results))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xu_iAWpIyb5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def column(matrix, i):\n",
        "    return [row[i] for row in matrix]\n",
        "\n",
        "smiles =column(results,0)\n",
        "properties =column(results,1)\n",
        "atom_types =column(results,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9KFLq3Z-BnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mwo9Atjh-HEL",
        "colab_type": "code",
        "outputId": "7a0580aa-14bf-4867-d4fe-965c15c334a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "dtype = [('Col1','int32'), ('Col2','float32'), ('Col3','float32'),('Col4','int32'), ('Col5','float32'), ('Col6','float32'),('Col7','int32'), ('Col8','float32'), ('Col9','float32'),('Col10','int32'), ('Col11','float32'), ('Col12','float32'),('Col13','float32'), ('Col14','float32'),('Col15','float32'), ('Col16','float32'),('Col17','float32')]\n",
        "values = properties\n",
        "index = ['Row'+str(i) for i in range(1, len(values)+1)]\n",
        "\n",
        "df = pd.DataFrame(values, index=index)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Row1</th>\n",
              "      <td>0.3676</td>\n",
              "      <td>68.74</td>\n",
              "      <td>-0.2352</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.2417</td>\n",
              "      <td>814.7537</td>\n",
              "      <td>0.142229</td>\n",
              "      <td>-363.839405</td>\n",
              "      <td>-363.831976</td>\n",
              "      <td>-363.831032</td>\n",
              "      <td>-363.870471</td>\n",
              "      <td>29.280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row2</th>\n",
              "      <td>1.8866</td>\n",
              "      <td>64.52</td>\n",
              "      <td>-0.2485</td>\n",
              "      <td>-0.0075</td>\n",
              "      <td>0.2409</td>\n",
              "      <td>794.2784</td>\n",
              "      <td>0.129457</td>\n",
              "      <td>-383.721976</td>\n",
              "      <td>-383.714630</td>\n",
              "      <td>-383.713685</td>\n",
              "      <td>-383.753023</td>\n",
              "      <td>28.544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row3</th>\n",
              "      <td>1.7780</td>\n",
              "      <td>73.30</td>\n",
              "      <td>-0.2542</td>\n",
              "      <td>0.0838</td>\n",
              "      <td>0.3380</td>\n",
              "      <td>883.2429</td>\n",
              "      <td>0.177401</td>\n",
              "      <td>-349.011613</td>\n",
              "      <td>-349.003832</td>\n",
              "      <td>-349.002888</td>\n",
              "      <td>-349.042983</td>\n",
              "      <td>30.929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row4</th>\n",
              "      <td>1.2074</td>\n",
              "      <td>73.61</td>\n",
              "      <td>-0.2583</td>\n",
              "      <td>0.0729</td>\n",
              "      <td>0.3312</td>\n",
              "      <td>881.9664</td>\n",
              "      <td>0.177890</td>\n",
              "      <td>-349.011971</td>\n",
              "      <td>-349.004251</td>\n",
              "      <td>-349.003307</td>\n",
              "      <td>-349.043189</td>\n",
              "      <td>31.339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row5</th>\n",
              "      <td>2.1403</td>\n",
              "      <td>66.86</td>\n",
              "      <td>-0.2510</td>\n",
              "      <td>0.0868</td>\n",
              "      <td>0.3378</td>\n",
              "      <td>831.9533</td>\n",
              "      <td>0.152815</td>\n",
              "      <td>-384.933448</td>\n",
              "      <td>-384.925779</td>\n",
              "      <td>-384.924835</td>\n",
              "      <td>-384.964883</td>\n",
              "      <td>29.600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0      1       2       3   ...          8           9           10      11\n",
              "Row1  0.3676  68.74 -0.2352  0.0065  ... -363.831976 -363.831032 -363.870471  29.280\n",
              "Row2  1.8866  64.52 -0.2485 -0.0075  ... -383.714630 -383.713685 -383.753023  28.544\n",
              "Row3  1.7780  73.30 -0.2542  0.0838  ... -349.003832 -349.002888 -349.042983  30.929\n",
              "Row4  1.2074  73.61 -0.2583  0.0729  ... -349.004251 -349.003307 -349.043189  31.339\n",
              "Row5  2.1403  66.86 -0.2510  0.0868  ... -384.925779 -384.924835 -384.964883  29.600\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tn58-bMS-J-G",
        "colab_type": "code",
        "outputId": "07e310fb-f174-4ab3-853b-745d5a2815f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCEcZDax-QXj",
        "colab_type": "code",
        "outputId": "899d61ed-f40f-497f-8c6b-66e6ed18b0b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# normalize target values to have a mean of 0 and std of 1\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler() \n",
        "data_scaled=scaler.fit_transform(df)\n",
        "df = pd.DataFrame(data_scaled , index=index)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Row1</th>\n",
              "      <td>-1.497174</td>\n",
              "      <td>0.376456</td>\n",
              "      <td>0.381924</td>\n",
              "      <td>-0.143865</td>\n",
              "      <td>-0.337901</td>\n",
              "      <td>-0.570023</td>\n",
              "      <td>0.300064</td>\n",
              "      <td>-0.077239</td>\n",
              "      <td>-0.077249</td>\n",
              "      <td>-0.077249</td>\n",
              "      <td>-0.077207</td>\n",
              "      <td>0.189786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row2</th>\n",
              "      <td>-0.487877</td>\n",
              "      <td>-0.094090</td>\n",
              "      <td>-0.147182</td>\n",
              "      <td>-0.438433</td>\n",
              "      <td>-0.354346</td>\n",
              "      <td>-0.652968</td>\n",
              "      <td>-0.079868</td>\n",
              "      <td>-0.534428</td>\n",
              "      <td>-0.534445</td>\n",
              "      <td>-0.534445</td>\n",
              "      <td>-0.534387</td>\n",
              "      <td>0.027847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row3</th>\n",
              "      <td>-0.560036</td>\n",
              "      <td>0.884913</td>\n",
              "      <td>-0.373942</td>\n",
              "      <td>1.482575</td>\n",
              "      <td>1.641695</td>\n",
              "      <td>-0.292575</td>\n",
              "      <td>1.346334</td>\n",
              "      <td>0.263719</td>\n",
              "      <td>0.263720</td>\n",
              "      <td>0.263720</td>\n",
              "      <td>0.263736</td>\n",
              "      <td>0.552609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row4</th>\n",
              "      <td>-0.939170</td>\n",
              "      <td>0.919479</td>\n",
              "      <td>-0.537050</td>\n",
              "      <td>1.253233</td>\n",
              "      <td>1.501910</td>\n",
              "      <td>-0.297746</td>\n",
              "      <td>1.360880</td>\n",
              "      <td>0.263710</td>\n",
              "      <td>0.263710</td>\n",
              "      <td>0.263710</td>\n",
              "      <td>0.263732</td>\n",
              "      <td>0.642819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Row5</th>\n",
              "      <td>-0.319307</td>\n",
              "      <td>0.166829</td>\n",
              "      <td>-0.246638</td>\n",
              "      <td>1.545697</td>\n",
              "      <td>1.637584</td>\n",
              "      <td>-0.500348</td>\n",
              "      <td>0.614968</td>\n",
              "      <td>-0.562285</td>\n",
              "      <td>-0.562295</td>\n",
              "      <td>-0.562295</td>\n",
              "      <td>-0.562253</td>\n",
              "      <td>0.260194</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            0         1         2   ...        9         10        11\n",
              "Row1 -1.497174  0.376456  0.381924  ... -0.077249 -0.077207  0.189786\n",
              "Row2 -0.487877 -0.094090 -0.147182  ... -0.534445 -0.534387  0.027847\n",
              "Row3 -0.560036  0.884913 -0.373942  ...  0.263720  0.263736  0.552609\n",
              "Row4 -0.939170  0.919479 -0.537050  ...  0.263710  0.263732  0.642819\n",
              "Row5 -0.319307  0.166829 -0.246638  ... -0.562295 -0.562253  0.260194\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atMo9hSozFpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "zinc_charset = [\n",
        "    ' ', '#', ')', '(', '+', '-', '/', '1', '3', '2', '5', '4', '7', '6', '8',\n",
        "    '=', '@', 'C', 'B', 'F', 'I', 'H', 'O', 'N', 'S', '[', ']', '\\\\', 'c', 'l',\n",
        "    'o', 'n', 'p', 's', 'r'\n",
        "]\n",
        "\n",
        "\n",
        "class OneHotFeaturizer():\n",
        "  \"\"\"\n",
        "  NOTE(LESWING) Not Thread Safe in initialization of charset\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, charset=zinc_charset, padlength=60):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    charset: obj:`list` of obj:`str`\n",
        "      Each string is length 1\n",
        "    padlength: int\n",
        "      length to pad the smile strings to\n",
        "    \"\"\"\n",
        "    self.charset = charset\n",
        "    self.pad_length = padlength\n",
        "\n",
        "  def featurize(self, mols, verbose=True, log_every_n=1000):\n",
        "    \"\"\"\n",
        "    Parameters\n",
        "    ----------\n",
        "    mols: obj\n",
        "      List of rdkit Molecule Objects\n",
        "    verbose: bool\n",
        "      How much logging\n",
        "    log_every_n:\n",
        "      How often to log\n",
        "    Returns\n",
        "    -------\n",
        "    obj\n",
        "      numpy array of features\n",
        "    \"\"\"\n",
        "    from rdkit import Chem\n",
        "    smiles = [Chem.MolToSmiles(mol) for mol in mols]\n",
        "    if self.charset is None:\n",
        "      self.charset = self._create_charset(smiles)\n",
        "    return np.array([self.one_hot_encoded(smile) for smile in smiles])\n",
        "\n",
        "  def one_hot_array(self, i):\n",
        "    \"\"\"\n",
        "    Create a one hot array with bit i set to 1\n",
        "    Parameters\n",
        "    ----------\n",
        "    i: int\n",
        "      bit to set to 1\n",
        "    Returns\n",
        "    -------\n",
        "    obj:`list` of obj:`int`\n",
        "      length len(self.charset)\n",
        "    \"\"\"\n",
        "    return [int(x) for x in [ix == i for ix in range(len(self.charset))]]\n",
        "\n",
        "  def one_hot_index(self, c):\n",
        "    \"\"\"\n",
        "    TODO(LESWING) replace with map lookup vs linear scan\n",
        "    Parameters\n",
        "    ----------\n",
        "    c\n",
        "      character whose index we want\n",
        "    Returns\n",
        "    -------\n",
        "    int\n",
        "      index of c in self.charset\n",
        "    \"\"\"\n",
        "    return self.charset.index(c)\n",
        "\n",
        "  def pad_smile(self, smile):\n",
        "    \"\"\"\n",
        "    Pad A Smile String to self.pad_length\n",
        "    Parameters\n",
        "    ----------\n",
        "    smile: str\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "      smile string space padded to self.pad_length\n",
        "    \"\"\"\n",
        "\n",
        "    return smile.ljust(self.pad_length)\n",
        "\n",
        "  def one_hot_encoded(self, smile):\n",
        "    \"\"\"\n",
        "    One Hot Encode an entire SMILE string\n",
        "    Parameters\n",
        "    ----------\n",
        "    smile: str\n",
        "      smile string to encode\n",
        "    Returns\n",
        "    -------\n",
        "    object\n",
        "      np.array of one hot encoded arrays for each character in smile\n",
        "    \"\"\"\n",
        "    return np.array([\n",
        "        self.one_hot_array(self.one_hot_index(x)) for x in self.pad_smile(smile)\n",
        "    ])\n",
        "\n",
        "  def untransform(self, z):\n",
        "    \"\"\"\n",
        "    Convert from one hot representation back to SMILE\n",
        "    Parameters\n",
        "    ----------\n",
        "    z: obj:`list`\n",
        "      list of one hot encoded features\n",
        "    Returns\n",
        "    -------\n",
        "    Smile Strings picking MAX for each one hot encoded array\n",
        "    \"\"\"\n",
        "    z1 = []\n",
        "    for i in range(len(z)):\n",
        "      s = \"\"\n",
        "      for j in range(len(z[i])):\n",
        "        oh = np.argmax(z[i][j])\n",
        "        s += self.charset[oh]\n",
        "      z1.append([s.strip()])\n",
        "    return z1\n",
        "\n",
        "  def _create_charset(self, smiles):\n",
        "    \"\"\"\n",
        "    create the charset from smiles\n",
        "    Parameters\n",
        "    ----------\n",
        "    smiles: obj:`list` of obj:`str`\n",
        "      list of smile strings\n",
        "    Returns\n",
        "    -------\n",
        "    obj:`list` of obj:`str`\n",
        "      List of length one strings that are characters in smiles.  No duplicates\n",
        "    \"\"\"\n",
        "    s = set()\n",
        "    for smile in smiles:\n",
        "      for c in smile:\n",
        "        s.add(c)\n",
        "    return [' '] + sorted(list(s))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mT0y4adYzkCE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from rdkit import Chem"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoyq-HemznTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " mols = [Chem.MolFromSmiles(smile) for smile in smiles]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIPjvgGCzptr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "featurizer = OneHotFeaturizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sKgyCiH7kqv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "biggest_mol_size = max([len(atom_list) for atom_list in atom_types])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HIgYeBm7mwS",
        "colab_type": "code",
        "outputId": "9c1e7e52-2198-4fad-b360-da1cdf5af59a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "biggest_mol_size"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdLzMcYFhnAi",
        "colab_type": "code",
        "outputId": "624527b3-6e32-495e-a03e-cdf5c19196c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "torch.manual_seed(2) \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fc68dddd4b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RGG3LuIyTMT",
        "colab_type": "code",
        "outputId": "ff54807f-7436-40e9-fdd2-7054eefd8d07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(mols)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-RuX_IPXHQz",
        "colab_type": "code",
        "outputId": "a2e45261-6305-4678-cb36-bae994463a0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "featurizer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.OneHotFeaturizer at 0x7fc6e56a2710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M5pi1lLbVXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "one_hots = featurizer.featurize(mols)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQI8yD2ebaua",
        "colab_type": "code",
        "outputId": "9169fdb5-267e-447c-8fd6-3b6bdaac44cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "one_hots.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13000, 60, 35)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FK0og7j_mSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_mu=df[df.columns[0]]\n",
        "y=y_mu\n",
        "y_mu=torch.FloatTensor(y_mu)\n",
        "y=y.to_numpy()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6bfsEdVitFh",
        "colab_type": "code",
        "outputId": "82615479-6e86-4a7d-d355-8ef1db08e9ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05b7E06wi3Of",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m=y.reshape((13000,1)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvbYFuodnIKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Data(object):\n",
        "  def __init__(self, x=None,y=None):\n",
        "        self.x = x\n",
        "        self.y = y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgnFUdO7ndnf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_list=[]\n",
        "for i in range(13000):\n",
        "  data = Data(x=torch.FloatTensor(one_hots[i]),y=torch.FloatTensor(m[i]))\n",
        "  input_list.append(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aJ62UA8FrDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_list2=[]\n",
        "for i in range(13000):\n",
        " inputs = (torch.LongTensor(one_hots[i]),torch.LongTensor(m[i]))\n",
        " input_list2.append(inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duAGCEhg4qQ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_list2=[]\n",
        "for i in range(13000):\n",
        "  data = [np.array(one_hots[i],dtype='float64'),np.array(m[i],dtype='float64')]\n",
        "  input_list2.append(data)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-IyENGJtwNn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = torch.cat(input_list2).view(len(input_list2), 1, -1)\n",
        "x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6Kwfr0sxhTP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset=input_list2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeJq3_apD5J1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# a simple custom collate function, just to show the idea\n",
        "def my_collate(batch):\n",
        "    data = [item[0] for item in batch]\n",
        "    target = [item[1] for item in batch]\n",
        "    return torch.FloatTensor([data, target])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XcdVGc-q4PY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "# Split datasets.\n",
        "test_dataset = dataset[:960]\n",
        "val_dataset = dataset[960:1920]\n",
        "train_dataset =dataset[1920:12000]\n",
        "test_loader = DataLoader(test_dataset, batch_size=60, shuffle=False, num_workers=4)\n",
        "val_loader = DataLoader(val_dataset, batch_size=60, shuffle=False, num_workers=4)\n",
        "train_loader = DataLoader(train_dataset, batch_size=60, shuffle=True, num_workers=8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KXGtzCGq7_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDCV7pBLiPnz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = 35\n",
        "hidden_dim = 60"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bME1rIYFaRf9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        # Hidden dimensions\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Number of hidden layers\n",
        "        self.layer_dim = layer_dim\n",
        "\n",
        "        # Building your LSTM\n",
        "        # batch_first=True causes input/output tensors to be of shape\n",
        "        # (batch_dim, seq_dim, feature_dim)\n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, layer_dim, batch_first=True)\n",
        "\n",
        "        # Readout layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "    def forward(self, x):\n",
        "        # Initialize hidden state with zeros\n",
        "        h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim,dtype=torch.float64).requires_grad_()\n",
        "\n",
        "        # Initialize cell state\n",
        "        c0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim,dtype=torch.float64).requires_grad_()\n",
        "\n",
        "        # 28 time steps\n",
        "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
        "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
        "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
        "\n",
        "        # Index hidden state of last time step\n",
        "        # out.size() --> 100, 28, 100\n",
        "        # out[:, -1, :] --> 100, 100 --> just want last time step hidden states! \n",
        "        out = self.fc(out[:, -1, :]) \n",
        "        # out.size() --> 100, 10\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACIl5Sg6mn-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvrWvgeVdR-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = LSTMModel(input_dim=35, hidden_dim=60, layer_dim=60, output_dim=1)\n",
        "model=model.double()\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
        "                                                       factor=0.7, patience=5,\n",
        "                                                       min_lr=0.00001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlBb6uJGFKVf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hbe3aiMWNRwf",
        "colab_type": "code",
        "outputId": "f3d50487-3fbf-4aaf-9604-4fcbf0ff9cd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Train the model\n",
        "\n",
        "\n",
        "def train(epoc):\n",
        "    itera=0\n",
        "    model.train()\n",
        "    loss_all=0\n",
        "    for data, target in train_loader:\n",
        "        #data, target=data.to(device), target.to(device)\n",
        "        #data, target=data.cuda(), target.cuda()\n",
        "        outputs=model(data)\n",
        "        loss = F.mse_loss(outputs,target)\n",
        "        #print('Iter: {:03d}, Loss: {:.7f}'.format(itera, lr, loss)) \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_all+=loss.item()\n",
        "        itera=itera+1\n",
        "    return loss_all / len(train_loader.dataset)\n",
        "\n",
        "\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "# Test the model\n",
        "#with torch.no_grad():\n",
        "    error = 0\n",
        "    total = 0\n",
        "    for data, target in loader:\n",
        "         #data, target=data.to(device), target.to(device)\n",
        "         #data, target=data.cuda(), target.cuda()\n",
        "         outputs=model(data)\n",
        "         error+=(outputs-target).abs().sum().item()\n",
        "    return error / len(loader.dataset)\n",
        "\n",
        "\n",
        "best_val_error = None\n",
        "for epoch in range(1, 301):\n",
        "    lr = scheduler.optimizer.param_groups[0]['lr']\n",
        "    loss = train(epoch)\n",
        "    val_error = test(val_loader)\n",
        "    scheduler.step(val_error)\n",
        "\n",
        "    if best_val_error is None or val_error <= best_val_error:\n",
        "        test_error = test(test_loader)\n",
        "        best_val_error = val_error\n",
        "\n",
        "    print('Epoch: {:03d}, LR: {:7f}, Loss: {:.7f}, Validation MAE: {:.7f}, '\n",
        "          'Test MAE: {:.7f}'.format(epoch, lr, loss, val_error, test_error))    \n",
        "    #print('Test Accuracy of the model on the test smiles : {} %'.format(100 * correct / total)) \n",
        "\n",
        "# Save the model checkpoint\n",
        "#torch.save(model.state_dict(), 'model.ckpt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 001, LR: 0.001000, Loss: 1.0392415, Validation MAE: 0.7307579, Test MAE: 0.7586130\n",
            "Epoch: 002, LR: 0.001000, Loss: 1.0390482, Validation MAE: 0.7312262, Test MAE: 0.7586130\n",
            "Epoch: 003, LR: 0.001000, Loss: 1.0391751, Validation MAE: 0.7308318, Test MAE: 0.7586130\n",
            "Epoch: 004, LR: 0.001000, Loss: 1.0388677, Validation MAE: 0.7304512, Test MAE: 0.7563305\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}